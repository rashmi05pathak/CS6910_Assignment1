{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "EE20S051_CS21M050.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rashmi05pathak/CS6910_Assignment1/blob/main/EE20S051_CS21M050.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVL_ojcrRDm6",
        "outputId": "3b943465-4310-4a75-b65f-19f8d41143e3"
      },
      "source": [
        "#****PLease mount the drive according to your PRML folder location\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTSit1RFIXgg"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "from keras.datasets import fashion_mnist"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "(trainX, trainy), (testX, testy) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlJQpCpvZfCk",
        "outputId": "926baead-493c-4df7-fac3-4dfd446057b4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize loaded dataset\n",
        "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
        "print('Test: X=%s, y=%s' % (testX.shape, testy.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlF1QxYXZzn4",
        "outputId": "391c0b8d-00e9-4740-9380-7a920b1a2188"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: X=(60000, 28, 28), y=(60000,)\n",
            "Test: X=(10000, 28, 28), y=(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Searching classes 0 to 9 from trainy\n",
        "list_of_index = {}\n",
        "for i in range(60000):\n",
        "    if(list_of_index.get(trainy[i]) != True):\n",
        "      list_of_index[trainy[i]] = i #class item train[i] found at index i  \n",
        " #CLass 0 to 9 is stored in the list_of_index dictionary "
      ],
      "metadata": {
        "id": "chQsm5d8Z4Nl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmEuLRK0iGOM",
        "outputId": "21baae47-e366-4f38-ef2f-fb1ecfdc5962"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1,\n",
              " 1: 59996,\n",
              " 2: 59993,\n",
              " 3: 59997,\n",
              " 4: 59990,\n",
              " 5: 59999,\n",
              " 6: 59988,\n",
              " 7: 59992,\n",
              " 8: 59994,\n",
              " 9: 59978}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q1. Plotting fashion Mnist Dataset\n",
        "# create figure\n",
        "fig = pyplot.figure(figsize=(10, 7))\n",
        "# setting values to rows and column variables\n",
        "rows = 2\n",
        "columns = 5\n",
        "for i in range(10):\n",
        "\t# Adds a subplot at the 2nd position\n",
        "    fig.add_subplot(rows, columns, i+1)\n",
        "    j = list_of_index.get(i)\n",
        "    # showing image\n",
        "    pyplot.imshow(trainX[j],cmap = 'gray')\n",
        "    pyplot.axis('off')\n",
        "    pyplot.title(\"class\"+ str(i))\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "5A0XLAVbbxVn",
        "outputId": "845dd2c3-e49a-46f1-ecf6-61245eee46a5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAFOCAYAAACCDcfNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debxdVX3///cCZBASCAmEgExJmEFGBUEok5QqQosUlWKxOFBs+Vosij8U/cKvIC0K5aeVWvx9KZMPfqCAhVZAW+iDoUwJgwQSIIEMBBLCEAiTDPv3x71u3utD9uLcm3tzbvZ5PR+PPB7rZJ2zzz5nD2fd9fmstVJVVQIAAGizlbq9AwAAAMONBg8AAGg9GjwAAKD1aPAAAIDWo8EDAABajwYPAABovRWqwZNS+nxK6dZu7weGBsezPTiW7cGxbBeO5ztWqAbPcEsprZZS+j8ppRdTSk+nlL7W7X3C4KWUjkwp3Z5SeiWldHO39weDl1L6fkrp0ZTSSyml6SmlP+/2PmFwUkr/kFKa23+fnZ1SOqXb+4Rll1JaN6X0zEhuXK3S7R0YYf63pC0kbSppA0k3pZQeqqrq+q7uFQbrOUn/KGlrSft3eV+wbF6W9ElJj0j6kKTrU0qPVVV1e3d3C4Pw/0o6raqql1NKG0m6MaU0vaqqq7q9Y1gmfy/pYY3gjpQRu2MppY1TSlf1txifTSn9aCnPOc/+UpiSUtrb6j6cUrqnv25BSumc/v9fPaV0af82X0gp3Z1SGt//smMk/d9VVT1fVdXDki6Q9Pnl8HFbrxvHs6qq31RVdYWk+cvtg/aALh3L71ZVNb2qqrerqrpT0i2SPrK8PnNbdelYzqiq6mV7i7clTR7uz9oLuvS7qZTSnpK2l3Th8vicgzUiGzwppZUlXSdptqTNJG0k6fKlPPVuSTtJWlfSzyRdmVJavb/uPEnnVVU1WtIkSVf0//8xktaWtLGksZL+UtKrKaUxkiZIut+2f7+k7Ybsg/WobhzPYfkgGBHHMqW0hvp6eaYNyYfqUd08limlb6aUlkiaJ2nN/u1iGXTrePa/748k/bWkEb1W1Yhs8Ej6sKQNJX29qqqXq6p6raqqd8UFq6q6tKqqZ6uqerOqqh9IWk3SVv3Vb0ianFIaV1XVkqqq7rD/HytpclVVb1VVNaWqqhclrdVfv9jeYrGkUcPw+XpNN44nhsdIOJb/rL4/Rm4Y6g/XY7p2LKuqOkt999ZdJF2i/L6LwenW8fxfku6sqmrKsH66ITBSGzwbS5pdVdWbpSellE5KKT2cUlqcUnpBfS3Qcf3VX5C0paTp/d1vh/T//yXqu1FenlKan/oS6N4naUl//Wh7i9GSXhqiz9TLunE8MTy6eixTSmerr+v8yIqVj5dVV49l1ede9fUUnDaEn6tXLffjmVLaUH0Nnm8NyycaalVVjbh/6ovNL5S0Svj/z0u6tb+8d/9zdpC0Uv//PS/pwPCalSQdIek1SWuGus0kPSTpC/2P50v6mNWfLunybn8fK/q/bh1P+/8vSrq5299DG/5181iq70fxQUlju/09tOFft69Lq/+2pF92+/tY0f9143hK+uP+5zzd/2+xpN/1l1fu9ncS/43UHp67JD0l6ayU0pr9CVN7heeMkvSmpGckrZJS+o6sdyaldHRKab2qqt6W9EL/f7+dUtovpbRDf9zxRfV11b3dX3+xpG+nlMaklLaW9CVJ/zpMn7GXdOV4ppRW7o9NryJppf73pfdn2XTrWP5fko5S34352eH8gD1kuR/LlNJKKaXj+u+xKaX0YUl/Jek/h/ej9oRuXJu/Ul8DaKf+f9+RdK+knaqqemu4PuhgjcgGT/8X9Un1Ze7PUV9i26fD026QdL36hqnOVl8rc67VHyxpWn9i3HmSPlNV1avqG27+c/UdtIcl/bf6uusk6buSZvZv778lnV0xJH2ZdfF4fk593eXnq+8vm1fVN/IOg9TFY3mmpE0kPZZSWtL/j/lblkEXj+WfqO8++5KkSyX9sP8flkE3jmdVVa9XVfX07/+pr4fnjf7yiJP6u6gAAABaa0T28AAAAAwlGjwAAKD1aPAAAIDWo8EDAABajwYPAABoveJq6SmlZR7ClVLKHg92VNjWW29dl3/0o3w9tCuvvLIu33vvvXX5d7/7Xfa8N954oy5vv/32Wd2f/Mmf1OWZM2dmdWeffXZdfuGFF7Q8VVWV3vtZnRmK4zlU1l577bp80kknZXUPPvhgXV599dXr8kor5e1zr3vllVeyunHjxtXleB788IfdGwE7VMdzJB3LklGj3lmZ5e23367Lr732Wva8t94acVN2vKe2XJvve18+NdX73//+urx48dCv+LDVVlvV5RkzZgz59gdrRb02/Te29Pv63e9+N3u85ppr1uXHHnusLq+22mrZ8yZMmFCX43U7a9asunzppZd2uMfDr+lY0sMDAABarzgPT6ct1cH24uy0007Z48985jN1+VOf+lRW538BestUktZYY426PHbs2I7eO3rkkUfqsv8lKuV/kSxYsCCru+GGd9Yv/P73v5/VeU/FYLXlr8jogAMOqMv+HUrSM888U5c32GCDxm34eRb/Eh09+p0l0ebNm5fVbbrppgPb2SG0ov4VWfKlL32pLh955JFZ3VprrVWX/ZgsWbIke94qq7zT2fzii/l6oVdccUVdPv/887O6Tv+6HQ4r8rW5117vTMD7s5/lC5W//vrrS32eJP35n/95XT788MPrsvcQSNLf/M3f1OWvfe1rjXUPPPBAVuc97QsXLmz+AMNgRb02vec7/nb5/fP000/P6jbffPO6vNtuu9XlKVPyNUD9Xn3BBfm8rX6unHDCCY37WGojDFUUKGyDHh4AANCbaPAAAIDWo8EDAABarzhKq1OlmJvH7SXp4osvrssf/OAHszqPRb700ktZnWeHP/fcc1md5/f4iAMfCSRJL7/8cl2Osc7SZ7j77rvrso8MkqQ999yzLl933XVZ3S233FKXP/e5zzVuvxcdc8wxdTnmbPhIOM/1iKMHPMYf48Arr7xyXY45O/549uzZA9ltLMWhhx5alz0XQJIWLVpUlz1PZ/LkydnzPBfAR3ZFMYeHtQAHx+9NceSNj2Z94oknsrpddtmlLn/gAx+oy9OmTcued9NNN9XlHXbYIaubP39+Xd5jjz2yujvvvLMue44Jmvl98dVXX83qDjzwwLocR0I+//zzdfnqq6+uy5dffnn2vFVXXbUuz5kzJ6vbcMMN63LMrfXfW7/2pfwcW57o4QEAAK1HgwcAALTekIS0Sq666qrssYcT4rBDDzPFLrA333yzLsfwhT/X67w7XcrDHFGc1K5J7DL07uDYvb7PPvvUZZ84UZKmT5/e0fu11b777luX/dhK+fdYGnLpQ57jOeHHKR73j370o3WZkNbSxevBv/sYin7yySfrsocrpPzY+vXoQ82lfLK7zTbbLKvzsEqprrTPvS5+Nz71Q5x40O9pMYTv961TTjmlLl977bXZ83wqiBjO/+QnP1mXYzjbQ5t4R2n6hfib5DykFUP7HoLyUOL48eOz53noK4ab/Xh9/OMfz+p8QuBSCGt5hqXp4QEAAK1HgwcAALQeDR4AANB6w5LDs+uuu9blGDdsGqYq5bkWMXa80UYb1WWP90t5fNpjhXH7Piwv5nx4HDvmlPgQ+bhMQXxu0/t98YtfzOrigpm9xoe0eg6IlB9P/w5jrNePb8zX8HMpTmPgQ2Evu+yygex2zyjlv/i1KEl/8Ad/UJc9r0PK8wQ83u/5V1I+hcRvfvObrG7//fevyx/60IeyOs/hIWenWRwyvP7669flmOvo98I4ZP3ZZ5+ty2eeeeZSy1K+APNf//VfZ3W+5E5c0DLe23vVQJZb8CWa9t5776xuvfXWa9ymL8fjCyz7Uk2SNHHixLocc/R88dD99tsvq/Nz7pe//GVW53lByxM9PAAAoPVo8AAAgNYblpCWd23F2XH9cSkMEYcnnnzyyXU5dqt5mMlnfnzqqaey53moxLvw4n7F7nafXTSuCFsK0fnnO+KII7K6XgtpjRs3Lnvs3aulsKDXxeGz3mUaV9/2cykO24xDm/Fu8Xj5bLk+u7gk3XPPPXU5Dn/20KWHreIM7P68GGLx7u+tttoqq/N7jc+ILr37nOhlO+64Y2NdnLahlBbg9zS/78aQi6cy/OpXv8rqjj322KVuT5LGjh1bl2NopTT8um1KIawTTzwxezxhwoS6HIf5+yr28dr04eceGo7X5o033ti4jVdeeaUux2lm/JqO++wzcXtZKg/BX1b08AAAgNajwQMAAFqPBg8AAGi9Ycnh8XyVmJ/h8eK4eqsPRfchc5J0wQUX1OWDDjooq/McmwsvvLAuH3fccdnzfDjkuuuu27hfCxYsyOrOPffcuvyVr3wlq/MYdxxK7/HNuLTElltuWZcfeeQRtV3My3ClIZhejvF+z7vyqQPi6+KQXJ9GHe/wc/LUU0/N6nwF+7gcx9y5c+uyx+2l/Pr36yGeD56f4e8l5feJmEPw2c9+ti5/+tOfzuq+/vWv1+V4fvSa0srjvqq1lOdaxXu05z56Tl08Lj7VxCabbJLVeZ7lXXfdldX5FAfxHh2nr+glnrvmw8Sld0+V4jyHJ+atei5saekm30bMf/R8rzj9h/+mxqUlfPh8zOEZzqUm6OEBAACtR4MHAAC03rCEtHwIpHd3S3nXZxyy7uLQOHf99ddnj71Ldtttt63Lcej31VdfXZd9xV4pD01NnTo1q/OZo2OIzsMlsfvXQzBz5szJ6j7ykY/U5V4IaUVNXeNSfjz9O4yzsPqw1VVXXTWr89fFkNa0adMGscft96d/+qd1OYacHn/88cbXeRd4nE7Ch8n6NVaa6TxOC9G0PSk/lh4qkaRPfOITdfnyyy9v3GYviOEh90//9E/ZY58VPoYwfKblOGTdeTgjHmtfcfvmm2/O6jyk5cOtpd4Oafkwfw85StLTTz9dlz1sLOXXo18PUv6b5NuI15/Pth2PuV+38b39fh1f55/BQ+nS8P4e0sMDAABajwYPAABoPRo8AACg9YYkh2f77bfPHj/zzDN1uTQsPcZ2PSfDY8Xv9X4ep/S47xlnnJE9z98vDpPzOs+vieKyFr5ydCmHJ06L7sPyLrroosb3aysf6ugr+kr58fS6++67L3uerxIc83R8WYE4df699947iD1uPz+X47Isfm3Ga9rP7Thk3XNAPC8v5m15rl/MAyotOeNLEcT9ilNB9LJSDk/MWfRpAeI92u9xnebwRJ5vd//99zc+b5111mms6zX+mxSnEfCV7+MQdb9u4xQAfix9SpU4LNyfF3P7/JqOv9l+HvkyFlJ+rU6aNCmrI4cHAABgGdDgAQAArTckIS1fyVzKu9HiisXePRZXw/Xhb7F7erfddqvL3o0t5d213lUeu9E8jOXvJeXdrLEr1WdwHTNmTFbn3flxuKDXxWHT/nl60axZs+pynJ3Xpy7w7tpLL7208XkHH3xwVlcKq/rKwL1s8uTJ2WO/VuOsrB6ejeEonxX9kEMOyeqmT5++1G3G+4JfD3Flb18t/ec//3lW5/eCOJuyd7d7uE7qvSHO8d7kHnjggezxQw89VJd9So7I76cxRSA+dj6VgK/EHZVmh+41Piw9TnESQ0LOQ1xxBYGmaSJi2Niv9/i76ddYXB0hXsfOw3Jx6oPhRA8PAABoPRo8AACg9WjwAACA1huSHJ7bb789e7zBBhvU5Zgn4DG/OJT40UcfrctxiPcdd9xRl+Oq2f7YXxeHRpamti+tyOy5AXHInE+fHd/PtxOHs19zzTXqZT4MOR4L58fMh7JLeXw6bsO/+7gcAfocffTR2WOPz8drzHMy4tTzHo+PuTJ+zPwai9e35/TE5QY8ZyHm1/l2Std0ry9TUBqW7ssKSO9eDsj59Thu3Li6XPruIx/aXJp+JJ5LvcyvsZiT6Es0xePs00vE/FPPqfPrPV77Lh7XmOvnPDcz5vf454nTkgwnengAAEDr0eABAACtNyQhrfPPP7/xcexG22KLLery8ccfn9X5SrnPPfdcVvfggw/WZZ/BUcqHzZVm+CzxLtkY0vKu/ji804d0/tmf/dmg3rsXebd5PGZ+LLw8ZcqU7Hm+gnfsUvfHcRVf9PGh+1Ieno3hZh+qGmcN9xDXddddl9X5tenhkLh9n6E5dqn76tpxOLsPS/f9j/tZGpbdC+JK8iWbbLJJY52HH2699da6/Fd/9VfZ84444oi6fOqpp2Z1++67b13+5S9/2fhePhS713iYSsqvlzgTstfFKVs8TSTeIz005r95cQbtOEzd+bXqU4hI+e9mDEV7ioenuQw3engAAEDr0eABAACtR4MHAAC03pDk8JT4tPBSvmJrjA3uv//+dTnGKX1phhj/9xyQ0pC6ptyQ+LoYP/Whd76qrPTuIfnojOdoxaGOHk8uDVn3oY7xXPLjWZrmvpeVvpeYD+PXX8yv8+d6vo2UX8d+TOJw1nhdOT8/4n3Bc3Pi8i2ew1Malt0LNt54446fe9hhh9Xls88+O6v7xje+sdTXnHjiidljn/IgHjPPdYyvc9ttt91772xLxdxXv1bj75NPuxHzW/23Ml5zfr14XRz27s+L+T1eF3NfOxU/j+f9DfW9mx4eAADQejR4AABA6w1LSMvDEHFlZe86i12d3jUXhyqXurWb3rv0vIEoDXWPXYhNr4uhtqHatxWVf28xbOXfTel78tk6S9uIw6jRJw4H9WszDm/17zfOzOvD0uPx8i5wr4vd5q50zGMX9xprrLHUspQPfY1d8b0mhg1K37EPYf/gBz+Y1d122211ec8992zcht+vYwjUh7b7bM1SPu3A8pyBd6SJ34sP8Y6/RzNmzKjLceV0DznFa86vab8+4vP8/hnvGaVUkFmzZtXl8ePHZ3U+TD2+n99PYkrMsqKHBwAAtB4NHgAA0HrD0s/r3aWlLOuZM2dmjz2kFbugS4uU+ft1GtIqjf6J7xXDcq60MKVnrZcW0+tFCxcurMsx3Fc6Ns67eeMx82146AvviF3Jfp77zMdS/v3Gbm3v8i6Fjvz94nv7tRJHe/i1E0dbPfTQQ3V5xx13zOp89NhgR5C0RZw92a+POILLF2uN/J66YMGCuhyvPw9vlMKXEydOzB77MRvI7NBtE8N5/jsaRzR66CgeS78e429QU0grjnb0uhhO8/Mhjuz0hWF9AW4pv4f4fVzKR6gR0gIAABggGjwAAKD1aPAAAIDWG/axmqV4fBwu7HHgOMTN48AxT6Apb6e0gnbcL39dnLXXY5OlFWfROV8tPeZ5NQ1ljjwPKB4HP8/I4emMn+cxdu7XxOabb57V+VDimCfgx6WUh+d5XPH69ms15hf40POYJ9DreTvujjvuyB7feOONdTmuZu78+5Xy79RzvmJuh98nS8d9m222yR6fddZZdXmnnXZqfF3bxTw5v45iHpvnypRy6OJvlx8zv27j8fL3jnk6/ro4LYTf4+O1OGHChLocc3j883l+0lDgjgAAAFqPBg8AAGi9YQ9plUIScThyaTZlf1zqqvZtlmZIjt17vs343r7NUigs6vXZlEt84c/S8OhSyNBncB3I7LzoE8NPPty1NGy8NGVEpzMtlxb5jXV+/GKXuu9XvN5L79FrSrMiX3vttdnjUvpA0/EspQ+U7LHHHtnj448/vqPXtV0pdBTTPZ544om6HBfW9tB0Kezfafg3XmM+Y77PnizlUyH4PkrSLrvsUpdjSCt+hqFEDw8AAGg9GjwAAKD1aPAAAIDWG1FLCG+00UZ1OQ6L9dhhzBPw+GOnseOSGM/0HILS0D50rtMlQEp5GL6sR2kbvb5SdpM4xLtpmKqU5w2UXlfKBfAcglIOXSkXJ77Oh8uXcsHQzIcIS/m1FM+Dwdzv4rXpOV9cm0sXc3j8NygeEx/+feihh2Z1p59+el2O33XTPbPTazjuZ/zNPvjgg+vyj3/846yudP8fzuuWHh4AANB6NHgAAEDrdXVYelQaguzd6KVVX5vKcV9inXebxy417zYfSPcbw9Kb+Szb8XvybvNSF3oMrTRtg+OwdHFGVf/OYp3Pohq7vEuhqibxefGadt4VH7vlvau/NKPvUIS62yoOJ/Zj0en3VrrG4jBq36YPa45K9++2iyui+/XnoXwpD0nGKTg8zBRXUvfvs3QN+/GLx9KvuTjTue9nnIW5NH1MfI+hRA8PAABoPRo8AACg9WjwAACA1htRYwI9VybG9TzGWBq26nHJ+LzBTIEvSa+88krjPsf4Nzrjx2YguVZu1KhRS32NlOeZsKL90sUcqNL0Dl4Xpwrw7zfmHvhxLi3xUXpeacmZ0jaHerqKtorfYelYDyaPJm7Dj8WiRYsaX9fLOTwx58V/n5588smsbq+99qrL06ZNy+p82HjMcWuaEmDJkiXZ47Fjx9blmLPqxyTeT/x3M55ja6+9dl2O9wyGpQMAACwDGjwAAKD1RlRIq9PVjTvt6ozDZ0vd2qUwStPwPendXY+d7BfyIYyxu7O0Or0rhao6ncm5l8XrrTQ03MWucO+SLoXCSmFjF+tK58OYMWM62g7nQLOFCxdmj7fYYou6HM8R//5L32lpehDfxmOPPdbRNnpNvMY8NDVv3rysbp999qnLcWh46f7ZtIJAfI2Hn2K4q2l7krTWWmvV5e222y6r83MuDkMfztUL6OEBAACtR4MHAAC0Hg0eAADQeiMqh6cUb3SdxuMHm8MTX1fK4Ymr2qIzni+yePHirK6UF+U8ZhyPmcfA41TsWLrSchx+3se8jk6nGOhUHJZaui/4c0vTVTA1QbNnn322sS4ONe70eJamB/HrdubMmR1tr9fE87WU1zJ+/Pi6XJoCIOYF+Xv48Yq/aX79+dQxcfvxXHn00Ucb99/3pdPf/aFADw8AAGg9GjwAAKD1RtRq6W4gQ9M6nZm3tM3SfnqXWxy6O5xD6HpF7FLfZJNN6nKpu9OHQ8fj4l2mM2bMWNZdbKX43ZZCWqXryr/70iypXtfpFBRSHgKJ15sPb/XzRsqHxfbyEGepHGp8+OGHs7pDDz10UNt0pdWwfWjz448/3tF79Zp4HfmsxT5MPD6ePXt2Vlf6ffL3KK1y4Er32dLKBuuuu27jdkozvg81engAAEDr0eABAACtR4MHAAC03rDn8AxkmKrH/AYy3LspXhyH9g3FcgMDyeFhOvvOxHPEc3NK36EPXy8Nff2f//mfZd3FVorfu0/xHoefvvbaa3X51Vdfzepefvnluty0AvN78Ws4rurs7x1XVvbnxukMSkPWe03pPhyXKijl5gwmF6q0HEickgJ9Yl6L/5aNGjUqq3v66afrcpyCw39H4720aemV0nIt8fj79R7vGf4Zpk6dmtXtsccedbk0ZH2o0cMDAABajwYPAABovRE107KL3aAeSiqtvttUlvJu805nXV7adlyvd5V3qnQszjrrrKzusssuq8vTpk1r3KYPwYzDnOfMmVOXb7/99oHtbI+Iqxv7SstxqgBfkdlX05akCRMm1OU4nLbpmivN5BxD0R62Wm+99bI638+4zz5cN37WXlO6/jwk8l6a7pulcElpBuySgUxd0DYxrOthnnh9eEh5zz33zOp8So44PYeHu/y4xnQSn0YghtM8vB3PMZ8WIobJ/HqMaSLDedzp4QEAAK1HgwcAALQeDR4AANB6I2ppifnz59flLbfcMqsrrdbsj0vT1/vjuF8eRywNi4uvY1j6srv55puzxz4MedGiRY2v8+G0PvW69O4p1vFucYp6v+YeeOCBrG6//farywsWLMjqRo8e3fgefg00rc4s5ddt6drceuuts7p77723Lsf8nokTJ9blOCy215TuRXF5B/++Y16GH0OvG8iSPp0u9dLL98+YC+dDvGOu2pNPPlmXDz/88Kxu+vTpdXns2LFZnf/Oec5Q/N304xCHy/u1H6cY8KVerr/++qzO8/7WXHPNxvcbavTwAACA1qPBAwAAWm9EDUtfZ5116nLs5vLut3HjxmV1TUPRSys3R96NG7tg586dW5fjkL1JkyY1btP3pZeHWErlbso4c68fi9L362JXKzO4vjefWVnKQ0CTJ0/O6n7yk5/UZb9OJem5556ry6UQr18D8XooXSs+LDaGpm677ba6fOqpp2Z1u+++e12+6qqrGverF5Sm+YghEj+G8X7ndX6c4vY7nR0bSxfDs36txtDUaaedVpf//d//PavzcFecCdl/U/18iPdq/y2OdX5s4/Z9uLzfIyTp+OOPr8txWoQ49H0o0cMDAABajwYPAABoPRo8AACg9UbUauk+xPShhx7K6l544YW6XMrN8Viyx/7je8f9Kg1795hznCL7rrvuatyXXs/bGaxLLrmkLsfh5k3isMc41B3vds8992SPPTdn1qxZWd1FF120XPZpWdx5553ZY5/SYObMmct7d0aUOH2/8xxFSfrpT39al7fZZpuszpcL8PMl3k991W7P55Gkr371qx3scW/zpXGkfDkXn74litf0UIj5N0Phvvvuq8vxN3XhwoVD/n6/Rw8PAABoPRo8AACg9VIvz2YJAAB6Az08AACg9WjwAACA1qPBAwAAWo8GDwAAaD0aPAAAoPVo8AAAgNajwQMAAFqPBg8AAGg9GjwAAKD1aPAAAIDWo8EDAABajwYPAABoPRo8AACg9WjwAACA1qPBAwAAWo8GDwAAaD0aPAAAoPVo8AAAgNajwQMAAFqPBg8AAGg9GjwAAKD1aPAAAIDWo8EDAABajwYPAABoPRo8AACg9WjwAACA1qPBAwAAWo8GDwAAaD0aPAAAoPVo8AAAgNajwQMAAFqPBg8AAGg9GjwAAKD1aPAAAIDWo8EDAABajwYPAABoPRo8AACg9WjwAACA1qPBAwAAWo8GDwAAaD0aPAAAoPVo8AAAgNajwQMAAFqPBg8AAGg9GjwAAKD1aPAAAIDWo8EDAABajwYPAABoPRo8AACg9WjwAACA1qPBAwAAWo8GDwAAaD0aPAAAoPVo8AAAgNajwQMAAFqPBg8AAGg9GjwAAKD1aPAAAIDWo8EDAABajwYPAABoPRo8AACg9WjwAPgYOtcAACAASURBVACA1qPBAwAAWo8GDwAAaD0aPAAAoPVo8AAAgNajwQMAAFqPBg8AAGg9GjwAAKD1aPAAAIDWo8EDAABajwYPAABoPRo8AACg9WjwAACA1qPBAwAAWo8GDwAAaD0aPAAAoPVo8AAAgNajwQMAAFqPBg8AAGg9GjwAAKD1aPAAAIDWo8EDAABajwYPAABoPRo8AACg9WjwAACA1qPBAwAAWo8GDwAAaD0aPAAAoPVo8AAAgNajwQMAAFqPBg8AAGg9GjwAAKD1aPAAAIDWo8EDAABab4Vq8KSUPp9SurXb+4GhwfFsD45le3As24Xj+Y4VqsEz3FJK/5pS+l1KaYn9W7nb+4XBSykdmFKamlJ6OaU0L6V0ZLf3CQOXUpoWrss3U0rXdnu/MHAppXVTSv9fSunZlNKilNJlKaXR3d4vDE5KaaOU0i9TSs/132P/stv71IQGz7v9Q1VVa9m/t7q9QxiclNK2kn4m6VuS1pa0o6QpXd0pDEpVVdv9/pqUNErSXElXdnm3MDh/J2mMpM0lTZI0XtL/7uYOYZlcKulx9R3HT0g6M6W0X3d3aelGbIMnpbRxSumqlNIz/X8J/GgpzzkvpTQ3pfRiSmlKSmlvq/twSume/roFKaVz+v9/9ZTSpf3bfCGldHdKafzy/Gy9qEvH89uSflJV1a+qqnqzqqpnq6qauXw+cXuNgGtzH0njJP1i2D5kj+jSsdxc0jVVVb1YVdViSVdL2m55fN62W97HM6W0lqR9JZ1RVdUbVVXdL+nnko5dTh95QEZkgyf1hZGukzRb0maSNpJ0+VKeereknSStq76/5K9MKa3eX3eepPOqqhqtvr8iruj//2PU99f+xpLGSvpLSa/aNr/S3zU3JaX0qaH8XL2qi8dzj/73/21K6an+C3bdof10vaXL16bseb+oqurlIfhIPauLx/KfJB2SUhqTUhoj6VOSfjWkH64Hdel4pt+/ve+KpO2H5EMNsRHZ4JH0YUkbSvp6VVUvV1X1WlVV70q6qqrq0v6/2t+squoHklaTtFV/9RuSJqeUxlVVtaSqqjvs/8dKmlxV1VtVVU2pqurF/rr/R9IWktaXdKqkf00p7TV8H7NndOt4fkDS59R3Q91C0hqSfjhsn7I3dOtYSpJSSu+XdISkfx2ej9dTunUsp0paVdKz/f/ekvTjYfuUvWO5H8+qql6SdJukU/t7gXZR3/32/cP8WQdlpDZ4NpY0u6qqN0tPSimdlFJ6OKW0OKX0gvpaoOP6q78gaUtJ0/u73w7p//9LJN0g6fKU0vyU0j+klN4nSVVVTbUT4T8kXSbp8GH4fL2mK8dTfX+BXFhV1SNVVS2RdKakjw/xZ+s13TqWv3e4pOck/fdQfaAe1q1jeYWkR9SXizVa0kz15YFg2XTreP6Z+sKUcyWdr75jOW9IP9lQqapqxP2T9BFJCyWtEv7/85Ju7S/v3f+cHSSt1P9/z0s6MLxmJfX9RfiapDVD3WaSHpL0hYb9OF/SOd3+Plb0f906npJukfQdq99F0vPd/j5W5H/dvjYl/VrS6d3+Htrwr4vX5RJJO1r9TpKWdPv7WNH/dfvatPqfSfpet7+Ppf0bqT08d0l6StJZKaU1+7vKYmhplKQ3JT0jaZWU0nfU99eCJCmldHRKab2qqt6W9EL/f7+dUtovpbRDf7zzRfV11b3d/5ojUkprpZRWSikdJOloSf82nB+0R3TleEq6UNJfpJQm9odCvqm+GDcGr1vHUimlD0jaT9JFw/Xheky3juXdkr6YUlojpbSGpC9LemC4PmQP6dbv5jYppVEppVVTSkdLOkjSOcP5QQdrRDZ4qr6h4J+UNFnSHPV1j306PO0GSderr2t0tvpaonOt/mBJ01JKS9SXiPWZqqpelbSB+rLIX5T0sPq6xi/pf81XJT2pvgN9tqQvVVV18xB/vJ7TreNZVdX/kXSxpDv7t/m6pP819J+wd3Tx2pT68rH+p2Kk3ZDo4rE8Vn29BPPUd7+dqL6kWCyDLh7PP5Q0S309RX8p6eCqqp4Z6s83FFJ/FxQAAEBrjcgeHgAAgKFEgwcAALQeDR4AANB6NHgAAEDr0eABAACtt0qpMqXEEK4uq6oqvfezOrO8j2dKaallSXr77Xp6FY0dOzarO/bYd9ade+mll5ZalqTRo+vpI7Txxhtndaeccsqg9stHLcYRjP7cwY5uHKrjybXZfSvytYl3a/u1Ge91brD3s912260uH354vijBCy+8UJffeOONrO7hhx+uy9dff33H77fSSu/00fhvSNR0LOnhAQAArVfs4QGkcs9Gp381lP6C+MIXvpA9PuCAA+ryqFGj6vK4ceOy5/k2Fy9enNVdd907Eyrffvvtg9ov/2tCKv9FAQAj2WB7cdZZZ526/LWvfS2r+4u/+Iu6/OKL2Tq/WQ/P+PHjs7pJkybVZb9XS9KXv/zluvzUU09ldX4PLvXON6GHBwAAtB4NHgAA0Ho0eAAAQOsV19IaqdnmvWQkjAQZbHa/j6I69NBDs7rDDjusLr/vfe/L6l5++eW6vOGGG9blddddN3verFmz6nKMH6+xxhqN+3jTTTfV5VtvvTWre/DBB9WEUVpwI+HaxNBpw7U5mLyW6GMf+1j2+B//8R/rsuflSNIqq7yTBvy73/0uq/ORWauttlpW5/fneF/3+/9Pf/rTrO7cc89t3G//7G+//TajtAAAQG+iwQMAAFqPkNYINxK6zTsN5ZxzzjnZY58M0Ls+Jen111+vy6+++mpW50PR11tvvbr8wAMPZM+bMGFCXV511VWzuvnz5ze+t3evxq5WD2mdfvrpajLYIett6DZHn25cm6Xw8kD4+fvWW281Pi+GmzfaaKO6vOmmm9bltdZaK3veyiuvXJcXLlyY1T3zzDN1eebMmR3u8buvOVcaruxK96+2X5ulcNeBBx5Yl08++eTseX5/jtvYZJNN6nIMd62++up12c+HuJ147/bzMU5K+61vfasuX3zxxWrCxIMAAKBn0eABAACtR4MHAAC0Hjk8I9xIyOEp+fa3v12X995776xuzpw5/t5ZncfcS/k9HvuN2/DY8ptvvpnVebw/xo/9cXzdmDFj6vKiRYuyuhNPPFHLqu15Ar1kuK7NeJ779RHP18FOj+BiHpvnRqy//vpZ3b777rvUbcTFIWPuj/PP8POf/zyrmzt3bl3+xje+0biNwYr5Ir7fTUOZB2okXZulxTYnT55cly+//PK6/Oyzz2bP8yk/1lxzzazOzz/P2ZHy4xzPW3/vmJvlz/XfAimfpuSkk07K6vy8JYcHAAD0LBo8AACg9VgtHQMSw0PbbrttXX7++eezOu/Wjl3e3rUcZ+j0Lv1S+Mm74kthgNhl6sMe4+fxoZVxBlBfrT2Gu4BlUZr6IV47Q82nj5Ckm2++uS6ff/75WZ0PE46hj6FwySWXDPk2XbzXtF1pugyfdsPTD+L90u97cZh46dz0UNj73//+rM7DX/H9nnvuucY6D3H5kPhO0cMDAABajwYPAABoPRo8AACg9cjhwYB4PFfKY7NxinrPsfG4rJTHYuNQUc/VKQ2rdDHW6zkRMW5fGkrp21lnnXWyup133rku//rXv27cFwytP/qjP6rLjzzySFZXWppgsEsMdLqUylAqvY+fh6eddlpW50s6xHw0v65KeWxxCLlfm37Ox9f59V3KjYnXre9XvGf49fiTn/wkqysdF/98camaHXfcsS5///vfz+quvfbaxv1eEcUpPvxeOmnSpKzOvzM/fr58iCS99tprdXnevHlZnZ+bviSQlC/9M3r06Kzuqaeeqss+1FzKcyd95XQpP5euvPJKDRQ9PAAAoPVo8AAAgNYjpIUBGT9+fPbYQ1qx69qHLMauVu/Kjq/zbljvuo5DIpcsWVKXY9eni9353n0bu/M9ZBe72zfffPPG92g7/w7fY8Xp7HGn4aHPfOYzdfkTn/hEVvfd7363Lsfw5wc+8IG6HLvbOw1bRf660grTw+WAAw7IHnvY5eGHH87q4lQQzvc1Tungj0shp/XWWy+r82vCr+94jfl1FetKYWoPp8UQTGlFdP+s8Rj5veeoo47K6k444QS1SWlF+ThLsoeufAi531el/PuMYX4Pqca0hTXWWKMuxxmT/dzxkJmUH6+4zx4KmzFjhgaKHh4AANB6NHgAAEDr0eABAACt14ocnqY8gRjnPeigg+ry7bffntWVVt5ueq/4fr1gm222yR6XVjP3+OvTTz+d1XmMvzRs3OO7MbZcGgrrMeKYp7N48eK6vP3222d1fh7EvKC4cnQv8fyJUp5AvB46vT7233//uvyHf/iHWd1vf/vbuhyHSXtuQMwF8CUSrrnmmqwuPrdJN67vOITXP0fMI3vllVfqcsyT8JyKuEyKf66YF+XHOuax+bGPrxuMuFK7532UzqW4X6VcMa+L01D4UhYf+9jHOt3tEat0vsbvzH/n/F4apzfw+2f8bfR7fDwf/NyM55+fYzGPq7T0TzzHB4oeHgAA0Ho0eAAAQOu1IqTVZO+9984eexjrpZdeyuomTpxYl2fNmtW4zYF0cfvwui233DKrW7BgQV0ejlWHh0tcobbUlezd07Fr0r+b2NXqj72bNIaYSjPJ+vZL+xW7Yf09YigsDsnsJZ0O4y4NQfbu8M997nPZ8zxU9b3vfS+r+8pXvlKX77jjjqzunnvuqcu77LJLVuczNH/2s5/N6u6+++66fPbZZ2d1y9ptvqxiuO2YY46py/55pXefo86PWXxeaUi5i9NJ+HPjNd303qU0gNJw+ZL4eZruGVI+dUa873tI6+KLL+7ovVdU8T7bdBziMfCwY0wrWLRoUV2O54NPmbD22ms3vrcPbZfyYxRnzS7Ntt8JengAAEDr0eABAACtR4MHAAC0XqtzeLbddtvsscd2f/Ob32R1Y8aMqcuTJ0/O6jymHmOKPrW9rw4r5cswxKGmU6dOrcu33Xbb0j/ACBSHF5ZyeDw2G2Pu/tyYJ9A0pDxOM+7DHktDG+NQVH8cV+r1HB7fvvTuY9hLSlP3l5adaMrJ+PCHP5w9nj9/fl2Ox8uvxyuuuCKr82ssXpueUxD3y+8NceV7zy+K59XcuXM13GKu2DPPPFOXYw7dnDlz6nL8rktTCfh3XMrPinkZ/lzfZmmYeNxG6bi4+N37c2Nd6Rz0Or/Pt1Hp+4w5kP7Y78Hx+vPzMW7Dp/iI92ffZpxCxK9VzwOS8vM95rN5Xm5c5sjzYpvQwwMAAFqPBg8AAGi9QYe0Ol0FudPhrMvyuqbt/PM//3P2+Ic//GFd3m+//bK6888/vy7H0IV3Fcfuvh133LEux67badOm1eXtttsuq4tdwK403LPb4mzDvq9xv314YZxp2bvmYzdp02zZpWGVpa5373aV8q7WOEzV6zy0JrW/O3ywSkNF99prr7r8zW9+sy5feeWV2fN8aoYYfvFZmD/0oQ9ldTvttFNdjuFJP7YvvPBCVufnRDz/TjrppLp83nnnaXk47bTT6vJ3vvOdrG7mzJmNr/NrIN6bfDXs0tQP8V5bCkf5sfHpHeK14ffM0gzp8Rorhcn8PCutiF6agX3cuHGNdW1Quhbjd+3nh4dGS+I55tdtPF4+HUC8xnwW8JjS4Mc2rsD+xBNP1OUTTzwxq/P7SxN6eAAAQOvR4AEAAK1HgwcAALReMYen0zydd23UYnKdThUeDSS/p2nl3xjLPeuss+ry0UcfndX5NPQXXnhhVuerN8+YMSOr+8///M+6HIfaHnLIIXX5sccey+riFPluWafPHk5x6KEfiziluw9Lj8esdI40TUsf82083h+/s9KyEz5Veoxd+xTo8RwsTeO/vA322hzu94vnx1FHHVWXPY8mxt/9WvXcECmP43tegCQ98sgjdfmhhx7K6jbddNO67NNHSNKoUaPq8sKFCxs/Q8xZGC733ntvY91dd91Vl+N57kOG4zXWtKxHrIvXR2k4uz/2a8VXtJfynJ4NNtggq/PjWRqyXroPxv0qvc6v9zjVRNuUjmU8B6ZMmVKXPbcprmDvuTkx38avjziE3K/jeE2X2gV+Hsd8Wh+y/vGPfzyrI4cHAABANHgAAEAPKIa0SiGDUrd2qbvqjDPOqMuxq9NXRY5dWT4bY+m9S0MSn3zyybr893//91nd8ccfX5d/8IMfZHU+E7IPi5PysFUceu5D3Z966qnG/YqWR4hisGIXv3dxxq5QDz/E4+KP43BGr/P3i92iPswydueXhrB6uCsez49+9KN1udQ9HEM3cdjlcBvslA6dbrMUNo78u/DVpyVp1113rcsexj3uuOOy53l39P3335/V+ays8fzzY7neeutldX4eeehLysMx8bzy8MinPvWprO7BBx/UcNhmm206et6LL76YPfZrLJ6vXhevzcEea38PD1nH68jrYjjRv/vSSu3xd6S0z/5+Dz/8cFbnU2IM5D7cNqXQoh+jeI2Vphjw+3/pWMYh8b6d119/vXGbpRn6PSwtSZMmTWp8/3of3/MZAAAAKzgaPAAAoPWKIa3SbMAl3kXsMxFLefd3nH33lFNOqcux+81DULNmzcrqmmYmjvvvz4t1V199dV3+4z/+48bXffGLX8zqvMvt7/7u75a6H0sz2BmoRxrv7oxd197NHbviY7a/axr5FcNifgxjt6h355e67O+5556szkfkxe5Uf//YffrAAw+oWwYSwmpa/FHKj2XpHDziiCOyxz76MYYhfCbWiRMn1uUYErzhhhvqcuw232KLLepyDM34vSYuHloKd3kX+/PPP5/VeZf+Pvvso+Xh4IMPbqzbfvvt63KcMdrDQ/H68O8qhhRKI7H8uorbjNfZ78UFl31G9jgKzj/D2LFjl7q9pfH7cDzn/fPFBVY93BUXP26D0mz0zs8jKT93/Fzxa1bKr9U4Esu3Ec8N304cwev7GUNTLo7KdPG82njjjRuf+3v08AAAgNajwQMAAFqPBg8AAGi9jmdajkqr2vrsn1/60peyOo/XxZlzPcYY83JifN51mmtUep6vHBtXaPWYfswvuPTSSzt672hFytPx7yZOT1BaSd6HIcfv3nN4YuzXc2f8HIx5QP68uF9NszVLeV6CT1Ug5TkhMV/Ez9e4avzyNtiZlv25A5nRe+rUqY2v85yMadOmZXW33HJLXfYh3TG3z/MsSsPEI78PxTwBf13MRfHPEM9NnzU47stuu+3WuC/LonRv8jyJmG/kdfG4eF5L3L5fq/H68OuqlOfl3/eWW27ZuP/xO/T3jvvl52fMO/JjGPfLr804m7K/bkW67w61nXfeOXvclAMZc3hK+ZalqWv8Nzvm4my44YaN2/TzozQL//jx47O6TvLB6OEBAACtR4MHAAC0XjGkVer+K3XB+myW3/ve97K63XffvS5fdtlljds48sgjG7dZ4sMj99hjj6zOh7fG4YlXXXVVXY6zPPvw6jj07Re/+EVdnj59elbn4S/vepby7r7FixdndaXvpRs222yzuhyPu3c5xmHct99+e13eYYcdGl8Xu9SbQqmlrtXSfsWQiG8nhkr9dXEIpnf7loZSLg+lWWe9+zgO//Zws5elvCvZF96U8tBfXOjSF9SdN29eVudd1wcccEDjPvv3HrumfWHDGObwcEk8zn5OxKksfBHCyL+XeF7FbvShUpqp+0c/+lFdjuGh2bNn1+UY8vVtLliwIKvze1MM9/mxKNX5dxPDiaVFhUvhNL+u4jXm2/EQqJSH+mKdD1Mf7CzkI5l/phhW8gWt/TqS8jCg30/iPcPPlRia8usx3p89JaCUthC3GffT+W9xTD2J6QlLQw8PAABoPRo8AACg9WjwAACA1ivm8PjQ25if4fkNY8aMyeo8RrvVVltldR6Dizk2HiucOXNmVuerMMccG48r+xDquHSFxzpjnNLFaeg9Fh5zCDz+GFc89vcoDYuNbrrppsa6bvDvOw4TLK1Y7qsWx2nNS69rEvMXPC5cygmJOQQ+lLKUp1NarTmeI8ubx8ePP/74rM6/i3i+Nj1Pyr+XGB8/55xz6nI8dz3fZ++9987qmqaGj1NS+OeJ+W6eGxDzBDyPJB5Lv/7jlAk+XUbM57nrrrsa9z/eB4dKadoNz4OKq5L75/JcOyk/nvH6Ky1H4Od5p3Ux37O04rXnWpWmHBjI0kb33XdfXY5L3Pi+dPu6HQ6l3xLPme00J7e0bEfMNfPXxekA/HHMq/K2RczV8vfzKSKkPBcv/t7Ge9bS0MMDAABajwYPAABovWJI67DDDqvLZ555Zlbn4Yo4VNtDD3EY57HHHluX42qn3jV3+OGHZ3X/9m//VpfPOOOMrK5pVe7YxV2aTXnu3Ll1Oc5mOn/+/LrsXYRSPsPonDlzsrr4/s7fI846GUM33ebDdGPXu4ft4uyn/h2XPlOnXa1xaKOfLzFk4a+LYRB/HEON3uUdwy7e/V5axXd58BDQz372s6zOr8fNN988q/Pu49jN7J8pziS9yy671OUY6vMQVAxRNIWR4zHx8yOuCO73kNhtXupu91CKT0kh5ddmDHlusMEGdTmG14YrpLVo0aLGOr+nxfPOP3MMDfh3VQo5xbrSquReV5qRuRSmLs1yXXpdaVoKvx7ivvjjeDxXxNXT43fkxy+eH34viPduP5Z+b433xFJY3I9ffJ5/135NSfn9esqUKVmdT6EQw3V+vOL17r/TTejhAQAArUeDBwAAtB4NHgAA0HrFHJ4LL7ywLsflD3zIZ8xV8Xh0jAf69PJxaLjH0n26eimPMf7t3/5t4+t8X0rT/8c4qOf3xNwGz4OIMfxvfetbdTlO3+6x9xg/9aGwMY7dyfC65cnjwjFu6jHVeKx91d248njMx3H+fXQ6XLI0vDW+l+9zPM88DyvmDPgx7HaelS/VEYdV+5QOcfXy0uriHnMvXTvxuy49t2ll7Hg++PNiLoDnosS60uraHv/3KS+k/FqN9yHfl5jzEVeSHipx+K3znKk4JYd/N52uai3l31Up5yUea68r5d6V6nwb8b39mJW2UcrLKw3TjlOVTJgwofG5I1Xpe4lLMvn3Eu8Tnjvq97b43fpvXvz9K+X37Lrrro11F1xwQV3+yEc+ktXFfEzn+xbz+eI1vjT08AAAgNajwQMAAFqvGNLyrtQrrrhiSN7woosuGpLtYPkpdTN7mCmu1lxaTdm3E8MbHhrzLvUYevD9imFV73qNoTbvRo/hRJ+eIIatfLh07Ipf3qZPn16X45BrD9nF78X3O4apS7Omlma99eH78Tj7+5e6quMxcn6OxSHxfg7E7nbv/o6v8+kHYpjIz824zeEaxuwzyf/4xz/O6nwm+xjW9f2LoRyvi2EKP06loecxFO/fTVM5brMUMisp7ddAVkv3xzEkPxyrp5e22en3UgpbxTCSr4i+8847Z3Xz5s2ry3EVct8X/25L98vSaulxehV3wgknZI+vueaaunzbbbc1vi7ui1/H/tk6RQ8PAABoPRo8AACg9WjwAACA1ivm8ABSHsONuRBeF1drdjGu7tuJw8abhk7HpUg6XWk55giVhu/6MiVjx45t3Ga3+fDoOFTaY/O+LIiUH4eYb+Px+Zhf4N9Z/N493yDmL3h+TKfLMpSmzo/5C76fMYeldN4O5P1dzHsaKj6kNq6I7udvzKHwlcFjjtRg81N86HbMefFj7993PF9K+T2ulM9TWvIiLj/i53J8nR/7WBeXERpq8f38cWn4fElcyunTn/50XY7D7j1XLQ7BjzmXv1e69uPQ9k033bQux/yho446qi7feOONS30v6d35gn5s473G8yp95fRO0cMDAABajwYPAABoPUJaeE/eNV4K65S6GGPXpA9Xjl27TSs5x9CXd2PH7ftzY10ppOVDHb27VsqHX3d7WHqJf2exy364u/AxOBMnTqzLMZTqQ8NjSM2vnXh9lGbPLYUCfRj8+uuvn9X5e5SGUXc6C/NAQj5Nw6glaccdd1zq86Q8DBi/o1JYfLBKn91DyuPHj8/qfFbveA74+eEz/0v5ygYxbOxhqzitR9Pz4jH34xD32cOtX/3qV7O6UhjLxXtpDKM2PXfq1KkdbT97/YBfAQAAsIKhwQMAAFqPBg8AAGg9cnjwnkrTobsHH3ywsa40BDMOGfahh54zFGPQHisvLaEQhzKX4vaew+O5DFI+7De+H7AsZs+eXZcfffTRrG6TTTapyzG/orRcR4nn98QlVP7jP/6jLt95551Znee1lVZc92ss5tSUVmP3azrmC3pdXOLD83RiHsvjjz9el5977rmsbs6cORpOxx13XPbYh4nH792PZZwywpdYiNNz+OeN90ifliJOaeD5RD6cPZ5/22yzzVJfI+VLRFx22WUajHgOe15QXFrCzzk/rp2ihwcAALQeDR4AANB6hLTwnkozqno36X/91381biO+zru5S6sil7rNfb/ibMo+e2fsNo8hLuehhfg6f/840yuwLDx8s+uuu2Z1fm4fdNBBWZ2HA+LQc39dDJ94yCSuiP4v//Ivne42lmLSpEl1OYaRfFqBeD9rmvlYykPoMazpYab4fh7uikPyfZu+L6Xt33PPPVndueee27jPpakPXJxqwfczhtD83r1gwYLGbTbu04BfAQAAsIKhwQMAAFqPBg8AAGg9cnjwnkqrXHsOwZQpUxqfF4ee+3DDGMtuWtk6TjnuOQsxRuzbiNsvLY/x29/+ti7HoeedrvYNDCXPabj22mu7uCfohOdOxWHivrp9aamHyO918b7k97q4dIzf++L9y1/n0w3E5SOeffbZunzyySd3tI9RKYcnDrP33MmYm+nLaDT9TpTQwwMAAFqPBg8AAGg9Qlp4Tz7TaxxC7uGhJ554onEbcWbU0mrmvmqwD6cdNWpU9rzSTMs+w2js5i3NPuphs7jqsT83zoQKAJL00EMP1eXHHnssq9t5553r8u67757VTZ48PJXkowAAAS5JREFUuS576EvKw0xxqLbf+5YsWZLV+fQc0YQJE+rySy+9VJdnzpyZPe/LX/5yXY73RA+ZxVSB0oz2Hv4qPW/06NHZ4xj+Gih6eAAAQOvR4AEAAK1HgwcAALQeOTx4T1OnTq3LMY/G81qmT5/euI1f//rX2WMfphiXevDhkz7s3ePMUufDIOPrPA4cp9V3cTXeGTNm1OVp06Y1vg5A7/I8x7jat68+H1eiL/G8nTFjxmR122+/fV3eeuutszq/D44dOzaru/vuu+vyjTfeWJfvuOOOxv2IU3zEnB5Xmv7Dh5T7sHcpzzuKy23ccsstjdvsBD08AACg9WjwAACA1kulLikAAIA2oIcHAAC0Hg0eAADQejR4AABA69HgAQAArUeDBwAAtB4NHgAA0Hr/P9LZMuy7/ndpAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x504 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape dataset to have a single channel\n",
        "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "testX = testX.reshape((testX.shape[0], 28, 28, 1))"
      ],
      "metadata": {
        "id": "baFyt6n1k1fI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8ht0HobrTkj",
        "outputId": "e323358f-811e-4f03-f4eb-7da3017ca770"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5RiEJEyNQ7c"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSw5xqa3NQ7e"
      },
      "source": [
        "#dataset_training1 = pd.read_csv(str_path+'PRML/IITM/Question1/Train_Dataset1.csv',header = None)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQYHUxe5NQ7g"
      },
      "source": [
        "#dataset_training2 = pd.read_csv(str_path+'PRML/IITM/Question1/Train_Dataset2.csv',header = None)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvfVl5PQNQ7h"
      },
      "source": [
        "#dataset_training1_arr = dataset_training1.to_numpy()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyWen5GENQ7h"
      },
      "source": [
        "#dataset_training2_arr = dataset_training2.to_numpy()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I42MWfsFNQ7i"
      },
      "source": [
        "#dataset_training1_arr.shape"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTXz9qnCNQ7k"
      },
      "source": [
        "#Q1(a)****Plotting dataset 1********#\n",
        "#plt.scatter(dataset_training1_arr[:,0], dataset_training1_arr[:,1], color = \"g\",marker = \"o\", s = 30)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rMwX3FMNQ7l"
      },
      "source": [
        "#Q1(b)Plotting Dataset2********# \n",
        "#plt.scatter(dataset_training2_arr[:,0],dataset_training2_arr[:,1],color = \"g\",marker = \"o\", s = 30)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjwSZTyvNQ7m"
      },
      "source": [
        "#Test data\n",
        "#dataset_testing1 = pd.read_csv(str_path+'PRML/IITM/Question1/Test_Dataset1.csv',header = None)\n",
        "#dataset_testing2 = pd.read_csv(str_path+'PRML/IITM/Question1/Test_Dataset2.csv',header = None)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD8H6pQmNQ7m"
      },
      "source": [
        "#dataset_testing1_arr = dataset_testing1.to_numpy()\n",
        "#dataset_testing2_arr = dataset_testing2.to_numpy()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPx1DJN_7NJt"
      },
      "source": [
        "#dataset_training2_arr.shape"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmoOkRqANQ7q"
      },
      "source": [
        "def sigmoid(x):\n",
        "    s = 1/(1+np.exp(-x))\n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUnoe7vVNQ7q"
      },
      "source": [
        "#Initialize the model’s parameters\n",
        "def initialize_parameters(X, n_h, n_y):\n",
        "    np.random.seed(2) # we set up a seed so that output matches\n",
        "    #Weight and bias \n",
        "    n_x = int(X[0].shape)\n",
        "    W1 = np.random.randn(n_h,n_x) * 0.01\n",
        "    b1 = np.zeros((n_h,1))\n",
        "    W2 = np.random.randn(n_y,n_h)* 0.01\n",
        "    b2 = np.zeros((n_y,1))\n",
        "    #print(W1,b1,W2,b2)\n",
        "    parameters = {\"W1\": W1,\"b1\": b1,\"W2\": W2,\"b2\": b2}\n",
        "    return parameters"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDcMGtvENQ7r"
      },
      "source": [
        "def forward_propagation(X, parameters): \n",
        "    # Retrieve each parameter from the dictionary \"parameters\" \n",
        "    W1 = parameters[\"W1\"]\n",
        "    b1 = parameters[\"b1\"]\n",
        "    W2 = parameters[\"W2\"]\n",
        "    b2 = parameters[\"b2\"]\n",
        "    # Implement Forward Propagation to calculate A2\n",
        "    Z1 = np.dot(W1,X)+b1\n",
        "    A1 = sigmoid(Z1)\n",
        "    Z2 = np.dot(W2,A1)+b2 \n",
        "    A2 = Z2\n",
        "    cache = {\"Z1\": Z1,\"A1\": A1,\"Z2\": Z2,\"A2\": A2}\n",
        "    return A2, cache"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeUl4PQaNQ7s"
      },
      "source": [
        "#implement mean squared error as output is real number\n",
        "def mean_squared_error(y_true,y_pred):\n",
        "    length = y_pred.shape[0]\n",
        "    sum_error = 0\n",
        "    for i in range(length):\n",
        "        sum_error = sum_error + ((y_pred[i] - y_true[i])**2)\n",
        "    return sum_error/length"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4jfb_XdNQ7s"
      },
      "source": [
        "#Notation used meaning is as below\n",
        "#dW1 = ∂J/∂W1\n",
        "#db1 = ∂J/∂b1\n",
        "#dW2 = ∂J/∂W2\n",
        "#db2 = ∂J/∂b2\n",
        "#A1*(1 - A1) is differentiation of sigmoid function\n",
        "# Implementing backward_propagation\n",
        "def backward_propagation(parameters, cache, X, Y):\n",
        "   # m = 1 #one dimensional data\n",
        "    # First, retrieve W1 and W2 from the dictionary \"parameters\". \n",
        "    W1 = parameters[\"W1\"]\n",
        "    W2 = parameters[\"W2\"]\n",
        "    A1 = cache[\"A1\"]\n",
        "    A2 = cache[\"A2\"]\n",
        "    # Backward propagation: calculate dW1, db1, dW2, db2.\n",
        "    dZ2 = A2-Y\n",
        "    dW2 = np.dot(dZ2,A1.T)\n",
        "    db2 = np.sum(dZ2,axis=1,keepdims=True)\n",
        "    dZ1 = np.dot(W2.T,dZ2)*A1*(1 - A1) #sigmoid as activation function at hidden layer\n",
        "    dW1 = np.dot(dZ1,X.T)\n",
        "    db1 = np.sum(dZ1,axis=1,keepdims=True)\n",
        "    grads = {\"dW1\": dW1,\"db1\": db1,\"dW2\": dW2,\"db2\": db2}\n",
        "    return grads"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulawqQFK9ukM"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-rSOh2jNQ7s"
      },
      "source": [
        "def update_parameters(parameters, grads, learning_rate): \n",
        "    W1 = parameters[\"W1\"]\n",
        "    b1 = parameters[\"b1\"]\n",
        "    W2 = parameters[\"W2\"]\n",
        "    b2 = parameters[\"b2\"]\n",
        "    dW1 = grads[\"dW1\"]\n",
        "    db1 = grads[\"db1\"]\n",
        "    dW2 = grads[\"dW2\"] \n",
        "    db2 = grads[\"db2\"]\n",
        "    W1 = W1-learning_rate*dW1\n",
        "    b1 = b1-learning_rate*db1\n",
        "    W2 = W2-learning_rate*dW2\n",
        "    b2 = b2-learning_rate*db2\n",
        "    parameters = {\"W1\": W1,\"b1\": b1,\"W2\": W2,\"b2\": b2}\n",
        "    return parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RukkvmsNQ7t"
      },
      "source": [
        "#****Neural Network method***********#\n",
        "def nn_model(X, Y, n_h, num_iterations,learning_rate): \n",
        "    np.random.seed(3)\n",
        "    parameters = initialize_parameters(X, n_h, 10) \n",
        "    W1 = parameters[\"W1\"]\n",
        "    b1 = parameters[\"b1\"]\n",
        "    W2 = parameters[\"W2\"]\n",
        "    b2 = parameters[\"b2\"] \n",
        "    # Loop (gradient descent)\n",
        "    for i in range(0, num_iterations):\n",
        "        for x,y in zip(X,Y):\n",
        "            A2, cache = forward_propagation(x, parameters)\n",
        "            #grads = backward_propagation(parameters, cache, x, y)\n",
        "            # Gradient descent parameter update.\n",
        "            #parameters = update_parameters(parameters, grads,learning_rate) \n",
        "    return parameters"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbpPoPKwyetQ",
        "outputId": "6adba41b-5763-49ab-eb48-09b98c3f4470"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameters1 = nn_model(trainX,trainy,1,100,0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "73HoD9jqoaht",
        "outputId": "58196526-2da4-435c-e57d-3cfab867a61c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-75bb9ef475c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparameters1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-87a234475235>\u001b[0m in \u001b[0;36mnn_model\u001b[0;34m(X, Y, n_h, num_iterations, learning_rate)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mW1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"W1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"b1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-5a49f4dfac0a>\u001b[0m in \u001b[0;36minitialize_parameters\u001b[0;34m(X, n_h, n_y)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# we set up a seed so that output matches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#Weight and bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mn_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mW1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_h\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_h\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'tuple'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6xwdpiQNQ7u"
      },
      "source": [
        "def predict(parameters,X):\n",
        "    W1 = parameters[\"W1\"]\n",
        "    b1 = parameters[\"b1\"]\n",
        "    W2 = parameters[\"W2\"]\n",
        "    b2 = parameters[\"b2\"] \n",
        "    A2, cache = forward_propagation(X, parameters)\n",
        "    return A2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dq3PCUDUvOK",
        "outputId": "63cc1286-5172-47d3-d6e9-ea630e612226"
      },
      "source": [
        "#*****Commenting the code as it's running time is approx. 20 min after that it will give the best parameter for minimum loss\n",
        "#******Tuning Hidden layer and learning rate for Dataset1 ***********************#\n",
        "#hidden_layer_sizes = [x for x in range(1,50)]\n",
        "#learning_rate = [0.001,0.01,0.1,1.0]\n",
        "#best_result = []\n",
        "#min_loss = 10#Assuming minimum loss to start with\n",
        "#for i, n_h in enumerate(hidden_layer_sizes):\n",
        "  #for j,lr in enumerate(learning_rate):\n",
        "      #parameters = nn_model(dataset_training1_arr[:,0], dataset_training1_arr[:,1], n_h, 100,lr) \n",
        "      #length = dataset_training1_arr.shape[0]\n",
        "      #output_prediction_arr = np.zeros(length)\n",
        "      #for i in range(length):\n",
        "          #output_prediction_arr[i] = predict(parameters,dataset_training1_arr[i,0])\n",
        "      #loss = mean_squared_error(dataset_training1_arr[:,1],output_prediction_arr)\n",
        "      #if(loss<min_loss):\n",
        "        #min_loss = loss\n",
        "        #best_result.clear()\n",
        "        #best_result.append(\"Loss for {} hidden units {} learning rate: {} %\".format(n_h,lr,loss))\n",
        "      #print (\"Loss for {} hidden units {} learning rate: {} %\".format(n_h,lr,loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for 1 hidden units 0.001 learning rate: 0.1588531121822333 %\n",
            "Loss for 1 hidden units 0.01 learning rate: 0.07251820982537349 %\n",
            "Loss for 1 hidden units 0.1 learning rate: 0.06671285862166351 %\n",
            "Loss for 1 hidden units 1.0 learning rate: 0.3698348908112 %\n",
            "Loss for 2 hidden units 0.001 learning rate: 0.17624835389694843 %\n",
            "Loss for 2 hidden units 0.01 learning rate: 0.03872547441218037 %\n",
            "Loss for 2 hidden units 0.1 learning rate: 0.036100924545429784 %\n",
            "Loss for 2 hidden units 1.0 learning rate: 0.13041488649218916 %\n",
            "Loss for 3 hidden units 0.001 learning rate: 0.18407410882595457 %\n",
            "Loss for 3 hidden units 0.01 learning rate: 0.022029201187955507 %\n",
            "Loss for 3 hidden units 0.1 learning rate: 0.00024698152955478534 %\n",
            "Loss for 3 hidden units 1.0 learning rate: 0.4540550447814892 %\n",
            "Loss for 4 hidden units 0.001 learning rate: 0.1822856655932304 %\n",
            "Loss for 4 hidden units 0.01 learning rate: 0.022095689389607535 %\n",
            "Loss for 4 hidden units 0.1 learning rate: 0.0006372851591981716 %\n",
            "Loss for 4 hidden units 1.0 learning rate: 0.423629407423319 %\n",
            "Loss for 5 hidden units 0.001 learning rate: 0.18685872691282596 %\n",
            "Loss for 5 hidden units 0.01 learning rate: 0.02466548988473411 %\n",
            "Loss for 5 hidden units 0.1 learning rate: 0.00017106949826036343 %\n",
            "Loss for 5 hidden units 1.0 learning rate: 0.39833474591670526 %\n",
            "Loss for 6 hidden units 0.001 learning rate: 0.18820313530550148 %\n",
            "Loss for 6 hidden units 0.01 learning rate: 0.023427741109242235 %\n",
            "Loss for 6 hidden units 0.1 learning rate: 0.0010656859476847456 %\n",
            "Loss for 6 hidden units 1.0 learning rate: 0.37697854950752463 %\n",
            "Loss for 7 hidden units 0.001 learning rate: 0.18737882589686014 %\n",
            "Loss for 7 hidden units 0.01 learning rate: 0.016725254643645417 %\n",
            "Loss for 7 hidden units 0.1 learning rate: 0.0014976082672714594 %\n",
            "Loss for 7 hidden units 1.0 learning rate: 0.35876384411858253 %\n",
            "Loss for 8 hidden units 0.001 learning rate: 0.1882041187297197 %\n",
            "Loss for 8 hidden units 0.01 learning rate: 0.019809354836626634 %\n",
            "Loss for 8 hidden units 0.1 learning rate: 0.001052830198381297 %\n",
            "Loss for 8 hidden units 1.0 learning rate: 0.3430840796709249 %\n",
            "Loss for 9 hidden units 0.001 learning rate: 0.18886529100955116 %\n",
            "Loss for 9 hidden units 0.01 learning rate: 0.021330693369774546 %\n",
            "Loss for 9 hidden units 0.1 learning rate: 0.0016643446606156688 %\n",
            "Loss for 9 hidden units 1.0 learning rate: 0.32949257936127596 %\n",
            "Loss for 10 hidden units 0.001 learning rate: 0.18900718399447122 %\n",
            "Loss for 10 hidden units 0.01 learning rate: 0.027635129261374416 %\n",
            "Loss for 10 hidden units 0.1 learning rate: 0.005291991869950668 %\n",
            "Loss for 10 hidden units 1.0 learning rate: 0.3176510676656425 %\n",
            "Loss for 11 hidden units 0.001 learning rate: 0.18926822077274993 %\n",
            "Loss for 11 hidden units 0.01 learning rate: 0.02228683887475104 %\n",
            "Loss for 11 hidden units 0.1 learning rate: 0.002783175872103397 %\n",
            "Loss for 11 hidden units 1.0 learning rate: 0.30729375611461096 %\n",
            "Loss for 12 hidden units 0.001 learning rate: 0.18945559294928585 %\n",
            "Loss for 12 hidden units 0.01 learning rate: 0.1052614146077473 %\n",
            "Loss for 12 hidden units 0.1 learning rate: 0.0016721413574307615 %\n",
            "Loss for 12 hidden units 1.0 learning rate: 0.1274591411855757 %\n",
            "Loss for 13 hidden units 0.001 learning rate: 0.18943708749419025 %\n",
            "Loss for 13 hidden units 0.01 learning rate: 0.029225132686763265 %\n",
            "Loss for 13 hidden units 0.1 learning rate: 0.0019875225052429476 %\n",
            "Loss for 13 hidden units 1.0 learning rate: 0.12219179643413934 %\n",
            "Loss for 14 hidden units 0.001 learning rate: 0.18957897098526072 %\n",
            "Loss for 14 hidden units 0.01 learning rate: 0.07699884873455864 %\n",
            "Loss for 14 hidden units 0.1 learning rate: 0.0010767058748851765 %\n",
            "Loss for 14 hidden units 1.0 learning rate: 0.3121639915712664 %\n",
            "Loss for 15 hidden units 0.001 learning rate: 0.18934473413112057 %\n",
            "Loss for 15 hidden units 0.01 learning rate: 0.02465882268835732 %\n",
            "Loss for 15 hidden units 0.1 learning rate: 0.000770305544704545 %\n",
            "Loss for 15 hidden units 1.0 learning rate: 0.25723058641718716 %\n",
            "Loss for 16 hidden units 0.001 learning rate: 0.1898229970941729 %\n",
            "Loss for 16 hidden units 0.01 learning rate: 0.11462654746278886 %\n",
            "Loss for 16 hidden units 0.1 learning rate: 0.001980491493745554 %\n",
            "Loss for 16 hidden units 1.0 learning rate: 0.24847893174876265 %\n",
            "Loss for 17 hidden units 0.001 learning rate: 0.18994731123151845 %\n",
            "Loss for 17 hidden units 0.01 learning rate: 0.17036732994845788 %\n",
            "Loss for 17 hidden units 0.1 learning rate: 0.0025419564595868726 %\n",
            "Loss for 17 hidden units 1.0 learning rate: 0.07967268605799414 %\n",
            "Loss for 18 hidden units 0.001 learning rate: 0.18978784989821015 %\n",
            "Loss for 18 hidden units 0.01 learning rate: 0.062305851170758736 %\n",
            "Loss for 18 hidden units 0.1 learning rate: 0.001378773939425358 %\n",
            "Loss for 18 hidden units 1.0 learning rate: 0.07986649275254036 %\n",
            "Loss for 19 hidden units 0.001 learning rate: 0.189858819961532 %\n",
            "Loss for 19 hidden units 0.01 learning rate: 0.13446446703188195 %\n",
            "Loss for 19 hidden units 0.1 learning rate: 0.003117930181118054 %\n",
            "Loss for 19 hidden units 1.0 learning rate: 0.2428013525302213 %\n",
            "Loss for 20 hidden units 0.001 learning rate: 0.18993831752604137 %\n",
            "Loss for 20 hidden units 0.01 learning rate: 0.17377447279801225 %\n",
            "Loss for 20 hidden units 0.1 learning rate: 0.007408738447692176 %\n",
            "Loss for 20 hidden units 1.0 learning rate: 0.10219769206031935 %\n",
            "Loss for 21 hidden units 0.001 learning rate: 0.19001325790103113 %\n",
            "Loss for 21 hidden units 0.01 learning rate: 0.046832187682579435 %\n",
            "Loss for 21 hidden units 0.1 learning rate: 0.0009196107862997047 %\n",
            "Loss for 21 hidden units 1.0 learning rate: 0.13153290607492435 %\n",
            "Loss for 22 hidden units 0.001 learning rate: 0.1900612069667175 %\n",
            "Loss for 22 hidden units 0.01 learning rate: 0.16969866229382577 %\n",
            "Loss for 22 hidden units 0.1 learning rate: 0.00043382373860014004 %\n",
            "Loss for 22 hidden units 1.0 learning rate: 0.13524744477793654 %\n",
            "Loss for 23 hidden units 0.001 learning rate: 0.19011885331715078 %\n",
            "Loss for 23 hidden units 0.01 learning rate: 0.16750234306867623 %\n",
            "Loss for 23 hidden units 0.1 learning rate: 0.0015133309365530103 %\n",
            "Loss for 23 hidden units 1.0 learning rate: 0.13092448355396458 %\n",
            "Loss for 24 hidden units 0.001 learning rate: 0.19001979259402824 %\n",
            "Loss for 24 hidden units 0.01 learning rate: 0.08295996659921145 %\n",
            "Loss for 24 hidden units 0.1 learning rate: 0.0009318912999322728 %\n",
            "Loss for 24 hidden units 1.0 learning rate: 0.1308868023296024 %\n",
            "Loss for 25 hidden units 0.001 learning rate: 0.19020110733268025 %\n",
            "Loss for 25 hidden units 0.01 learning rate: 0.17884333524287876 %\n",
            "Loss for 25 hidden units 0.1 learning rate: 0.004334679610795536 %\n",
            "Loss for 25 hidden units 1.0 learning rate: 0.3146102250738141 %\n",
            "Loss for 26 hidden units 0.001 learning rate: 0.19023149099538664 %\n",
            "Loss for 26 hidden units 0.01 learning rate: 0.1833565546171698 %\n",
            "Loss for 26 hidden units 0.1 learning rate: 0.0006192710394874151 %\n",
            "Loss for 26 hidden units 1.0 learning rate: 0.8320666066309554 %\n",
            "Loss for 27 hidden units 0.001 learning rate: 0.1902351469883335 %\n",
            "Loss for 27 hidden units 0.01 learning rate: 0.13119102944893302 %\n",
            "Loss for 27 hidden units 0.1 learning rate: 0.0007034998683678849 %\n",
            "Loss for 27 hidden units 1.0 learning rate: 0.839670875797247 %\n",
            "Loss for 28 hidden units 0.001 learning rate: 0.19024192753799865 %\n",
            "Loss for 28 hidden units 0.01 learning rate: 0.1820783373352288 %\n",
            "Loss for 28 hidden units 0.1 learning rate: 0.0004331941647566766 %\n",
            "Loss for 28 hidden units 1.0 learning rate: 0.8219960885342839 %\n",
            "Loss for 29 hidden units 0.001 learning rate: 0.19023766038814927 %\n",
            "Loss for 29 hidden units 0.01 learning rate: 0.11724824123100722 %\n",
            "Loss for 29 hidden units 0.1 learning rate: 0.0007050325313421784 %\n",
            "Loss for 29 hidden units 1.0 learning rate: 0.3328889441726309 %\n",
            "Loss for 30 hidden units 0.001 learning rate: 0.1903486600378092 %\n",
            "Loss for 30 hidden units 0.01 learning rate: 0.18563275303990817 %\n",
            "Loss for 30 hidden units 0.1 learning rate: 0.04336443170485106 %\n",
            "Loss for 30 hidden units 1.0 learning rate: 0.842466722342009 %\n",
            "Loss for 31 hidden units 0.001 learning rate: 0.19039458815404034 %\n",
            "Loss for 31 hidden units 0.01 learning rate: 0.16973649482139877 %\n",
            "Loss for 31 hidden units 0.1 learning rate: 0.00027117007554663426 %\n",
            "Loss for 31 hidden units 1.0 learning rate: 0.8432528213072612 %\n",
            "Loss for 32 hidden units 0.001 learning rate: 0.19038893889705216 %\n",
            "Loss for 32 hidden units 0.01 learning rate: 0.18382874050002324 %\n",
            "Loss for 32 hidden units 0.1 learning rate: 0.01869949550139769 %\n",
            "Loss for 32 hidden units 1.0 learning rate: 0.8446165471518696 %\n",
            "Loss for 33 hidden units 0.001 learning rate: 0.19035026097322316 %\n",
            "Loss for 33 hidden units 0.01 learning rate: 0.06031095167990949 %\n",
            "Loss for 33 hidden units 0.1 learning rate: 0.00037963785054483427 %\n",
            "Loss for 33 hidden units 1.0 learning rate: 0.8444766792207653 %\n",
            "Loss for 34 hidden units 0.001 learning rate: 0.19064331520823002 %\n",
            "Loss for 34 hidden units 0.01 learning rate: 0.18766730819509553 %\n",
            "Loss for 34 hidden units 0.1 learning rate: 0.04573848752903055 %\n",
            "Loss for 34 hidden units 1.0 learning rate: 0.8452553081725084 %\n",
            "Loss for 35 hidden units 0.001 learning rate: 0.19048027945227478 %\n",
            "Loss for 35 hidden units 0.01 learning rate: 0.18509904936826357 %\n",
            "Loss for 35 hidden units 0.1 learning rate: 0.0005141904856897561 %\n",
            "Loss for 35 hidden units 1.0 learning rate: 0.8448683361623673 %\n",
            "Loss for 36 hidden units 0.001 learning rate: 0.1905081431785708 %\n",
            "Loss for 36 hidden units 0.01 learning rate: 0.179465916587732 %\n",
            "Loss for 36 hidden units 0.1 learning rate: 0.0003409363416306202 %\n",
            "Loss for 36 hidden units 1.0 learning rate: 0.8451033718065515 %\n",
            "Loss for 37 hidden units 0.001 learning rate: 0.19052196739799823 %\n",
            "Loss for 37 hidden units 0.01 learning rate: 0.1839821912946676 %\n",
            "Loss for 37 hidden units 0.1 learning rate: 0.0006364937631819298 %\n",
            "Loss for 37 hidden units 1.0 learning rate: 0.8452178545319885 %\n",
            "Loss for 38 hidden units 0.001 learning rate: 0.19076040950189296 %\n",
            "Loss for 38 hidden units 0.01 learning rate: 0.18688366524202274 %\n",
            "Loss for 38 hidden units 0.1 learning rate: 0.04097853331113228 %\n",
            "Loss for 38 hidden units 1.0 learning rate: 0.8445665221847284 %\n",
            "Loss for 39 hidden units 0.001 learning rate: 0.19059340600723448 %\n",
            "Loss for 39 hidden units 0.01 learning rate: 0.1840972535422245 %\n",
            "Loss for 39 hidden units 0.1 learning rate: 0.0006869707412702886 %\n",
            "Loss for 39 hidden units 1.0 learning rate: 0.8453447970867002 %\n",
            "Loss for 40 hidden units 0.001 learning rate: 0.19055858153261104 %\n",
            "Loss for 40 hidden units 0.01 learning rate: 0.18417890594247846 %\n",
            "Loss for 40 hidden units 0.1 learning rate: 0.0013260475223843035 %\n",
            "Loss for 40 hidden units 1.0 learning rate: 0.8455142940039913 %\n",
            "Loss for 41 hidden units 0.001 learning rate: 0.19062704535180364 %\n",
            "Loss for 41 hidden units 0.01 learning rate: 0.18229400104619162 %\n",
            "Loss for 41 hidden units 0.1 learning rate: 0.0003070912374103859 %\n",
            "Loss for 41 hidden units 1.0 learning rate: 0.8454782331309254 %\n",
            "Loss for 42 hidden units 0.001 learning rate: 0.1908048592729161 %\n",
            "Loss for 42 hidden units 0.01 learning rate: 0.18703842959741743 %\n",
            "Loss for 42 hidden units 0.1 learning rate: 0.03386961924102292 %\n",
            "Loss for 42 hidden units 1.0 learning rate: 0.8450573320891565 %\n",
            "Loss for 43 hidden units 0.001 learning rate: 0.19068868058082916 %\n",
            "Loss for 43 hidden units 0.01 learning rate: 0.18380690545290398 %\n",
            "Loss for 43 hidden units 0.1 learning rate: 0.0007626939564907242 %\n",
            "Loss for 43 hidden units 1.0 learning rate: 0.8448660250847999 %\n",
            "Loss for 44 hidden units 0.001 learning rate: 0.19075999269861751 %\n",
            "Loss for 44 hidden units 0.01 learning rate: 0.17777984751448755 %\n",
            "Loss for 44 hidden units 0.1 learning rate: 0.0007277981278485193 %\n",
            "Loss for 44 hidden units 1.0 learning rate: 0.8438637786293243 %\n",
            "Loss for 45 hidden units 0.001 learning rate: 0.19092251084906087 %\n",
            "Loss for 45 hidden units 0.01 learning rate: 0.1828146484916726 %\n",
            "Loss for 45 hidden units 0.1 learning rate: 0.00022824850770839314 %\n",
            "Loss for 45 hidden units 1.0 learning rate: 0.8446158248353707 %\n",
            "Loss for 46 hidden units 0.001 learning rate: 0.19085088862086083 %\n",
            "Loss for 46 hidden units 0.01 learning rate: 0.18726322595369413 %\n",
            "Loss for 46 hidden units 0.1 learning rate: 0.04666934887574858 %\n",
            "Loss for 46 hidden units 1.0 learning rate: 0.8431775844101458 %\n",
            "Loss for 47 hidden units 0.001 learning rate: 0.19083976655991453 %\n",
            "Loss for 47 hidden units 0.01 learning rate: 0.1858078198444786 %\n",
            "Loss for 47 hidden units 0.1 learning rate: 0.0019901343806692 %\n",
            "Loss for 47 hidden units 1.0 learning rate: 0.8409881860877253 %\n",
            "Loss for 48 hidden units 0.001 learning rate: 0.19076966091677702 %\n",
            "Loss for 48 hidden units 0.01 learning rate: 0.18445365806797107 %\n",
            "Loss for 48 hidden units 0.1 learning rate: 0.0010033493617848598 %\n",
            "Loss for 48 hidden units 1.0 learning rate: 0.8404877151249246 %\n",
            "Loss for 49 hidden units 0.001 learning rate: 0.19102004171546097 %\n",
            "Loss for 49 hidden units 0.01 learning rate: 0.189097010463566 %\n",
            "Loss for 49 hidden units 0.1 learning rate: 0.048558775657011034 %\n",
            "Loss for 49 hidden units 1.0 learning rate: 0.8393159677872298 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ngii1zLaVjF",
        "outputId": "1ad9efdb-64ee-4261-ec82-e0d83c2bbcaa"
      },
      "source": [
        "#best_result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Loss for 5 hidden units 0.1 learning rate: 0.00017106949826036343 %']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isVtEz_ENQ7u"
      },
      "source": [
        "#parameters1 = nn_model(dataset_training1_arr[:,0], dataset_training1_arr[:,1],41,100,0.1)\n",
        "parameters1 = nn_model(dataset_training1_arr[:,0], dataset_training1_arr[:,1],5,100,0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83_fC1FaNQ7u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39bde6ef-bcca-4d69-d89b-d64b7e36e175"
      },
      "source": [
        "#Q1(d)Training loss\n",
        "length = dataset_training1_arr.shape[0]\n",
        "output_prediction_train = np.zeros(length)\n",
        "for i in range(length):\n",
        "    output_prediction_train[i] = predict(parameters1,dataset_training1_arr[i,0])\n",
        "mean_squared_error(dataset_training1_arr[:,1],output_prediction_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00017106949826036343"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWj_vxU2NQ7v"
      },
      "source": [
        "length = dataset_testing1_arr.shape[0]\n",
        "output_prediction_arr1 = np.zeros(length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDHHLzB7NQ7v"
      },
      "source": [
        "for i in range(length):\n",
        "    output_prediction_arr1[i] = predict(parameters1,dataset_testing1_arr[i,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHpuhjTVNQ7w"
      },
      "source": [
        "#output_prediction_arr\n",
        "#output_prediction_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utX8DgiONQ7w"
      },
      "source": [
        "#Q1(d) Dataset1 Test loss\n",
        "loss1 = mean_squared_error(dataset_testing1_arr[:,1],output_prediction_arr1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voZuIfrDNQ7w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "933cc98a-2688-494a-f5ad-9cbd686da783"
      },
      "source": [
        "loss1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00016598034303931655"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "8jqH18vI2b07",
        "outputId": "09161005-aec0-4dea-ebef-ae538f41f5ed"
      },
      "source": [
        "  # Q1(b)plotting regression curve\n",
        "# plotting the actual points as scatter plot\n",
        "plt.scatter(dataset_testing1_arr[:,0], dataset_testing1_arr[:,1],marker = \"o\", s = 30)\n",
        "# plotting the regression line\n",
        "plt.scatter(dataset_testing1_arr[:,0], output_prediction_arr1)\n",
        "# putting labels\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y: actual output')\n",
        "# function to show plot\n",
        "plt.legend(['test_data','predicted_output'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgEP_i2lNQ7x"
      },
      "source": [
        "#output_prediction_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYBtuAihNQ7x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "778d9569-691e-4acd-d6bc-969bbd452837"
      },
      "source": [
        "#COmmenting the code as the runtime of this section is approx. 25 min, it is used for hyperparameter tuning\n",
        "#******Tuning Hidden layer and learning rate for Dataset2 ***********************#\n",
        "#plt.figure(figsize=(16, 32))\n",
        "#hidden_layer_sizes = [x for x in range(1,50)]\n",
        "#learning_rate = [(0.1*x) for x in range(1,10)]\n",
        "#best_result2 = []\n",
        "#min_loss2 = 10\n",
        "#for i, n_h in enumerate(hidden_layer_sizes):\n",
        "    #for j,lr in enumerate(learning_rate):\n",
        "        #parameters = nn_model(dataset_training2_arr[:,0], dataset_training2_arr[:,1], n_h, 100,lr) \n",
        "        #length = dataset_training2_arr.shape[0]\n",
        "        #output_prediction_arr = np.zeros(length)\n",
        "        #for i in range(length):\n",
        "            #output_prediction_arr[i] = predict(parameters,dataset_training2_arr[i,0])\n",
        "        #loss = mean_squared_error(output_prediction_arr,dataset_training2_arr[:,1])\n",
        "       # if(loss<min_loss2):\n",
        "          # min_loss2 = loss\n",
        "           #best_result2.clear()\n",
        "          # best_result2.append(\"Loss for {} hidden units {} learning rate: {} %\".format(n_h,lr,loss))\n",
        "       # print (\"Loss for {} hidden units {} learning rate: {} %\".format(n_h,lr,loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for 1 hidden units 0.1 learning rate: 0.10177648067413682 %\n",
            "Loss for 1 hidden units 0.2 learning rate: 0.11408144280250901 %\n",
            "Loss for 1 hidden units 0.30000000000000004 learning rate: 0.12376470907296219 %\n",
            "Loss for 1 hidden units 0.4 learning rate: 0.13314243810219964 %\n",
            "Loss for 1 hidden units 0.5 learning rate: 0.14694012790519537 %\n",
            "Loss for 1 hidden units 0.6000000000000001 learning rate: 0.1749776272172159 %\n",
            "Loss for 1 hidden units 0.7000000000000001 learning rate: 0.24178689540826065 %\n",
            "Loss for 1 hidden units 0.8 learning rate: 0.3411600549189607 %\n",
            "Loss for 1 hidden units 0.9 learning rate: 0.5104988116066785 %\n",
            "Loss for 2 hidden units 0.1 learning rate: 0.027905875023281495 %\n",
            "Loss for 2 hidden units 0.2 learning rate: 0.019602901375063552 %\n",
            "Loss for 2 hidden units 0.30000000000000004 learning rate: 0.01755291500102019 %\n",
            "Loss for 2 hidden units 0.4 learning rate: 0.01959630927966033 %\n",
            "Loss for 2 hidden units 0.5 learning rate: 0.02420354510564637 %\n",
            "Loss for 2 hidden units 0.6000000000000001 learning rate: 0.13884639792873132 %\n",
            "Loss for 2 hidden units 0.7000000000000001 learning rate: 0.17702297225694896 %\n",
            "Loss for 2 hidden units 0.8 learning rate: 0.23443569990876298 %\n",
            "Loss for 2 hidden units 0.9 learning rate: 1.4365412284095707 %\n",
            "Loss for 3 hidden units 0.1 learning rate: 0.03326882622013678 %\n",
            "Loss for 3 hidden units 0.2 learning rate: 0.02384453371517087 %\n",
            "Loss for 3 hidden units 0.30000000000000004 learning rate: 0.019368825222170018 %\n",
            "Loss for 3 hidden units 0.4 learning rate: 0.01752015512886133 %\n",
            "Loss for 3 hidden units 0.5 learning rate: 0.019150440097298153 %\n",
            "Loss for 3 hidden units 0.6000000000000001 learning rate: 0.024721651930468914 %\n",
            "Loss for 3 hidden units 0.7000000000000001 learning rate: 0.034293084926774235 %\n",
            "Loss for 3 hidden units 0.8 learning rate: 0.34107994678894193 %\n",
            "Loss for 3 hidden units 0.9 learning rate: 1.4365844259952971 %\n",
            "Loss for 4 hidden units 0.1 learning rate: 0.037752224068287814 %\n",
            "Loss for 4 hidden units 0.2 learning rate: 0.027141718772246966 %\n",
            "Loss for 4 hidden units 0.30000000000000004 learning rate: 0.0222739479047666 %\n",
            "Loss for 4 hidden units 0.4 learning rate: 0.019077695964172605 %\n",
            "Loss for 4 hidden units 0.5 learning rate: 0.017641238950230335 %\n",
            "Loss for 4 hidden units 0.6000000000000001 learning rate: 0.019839099026728233 %\n",
            "Loss for 4 hidden units 0.7000000000000001 learning rate: 0.027908017517331733 %\n",
            "Loss for 4 hidden units 0.8 learning rate: 0.34050819304237456 %\n",
            "Loss for 4 hidden units 0.9 learning rate: 1.4366120524222872 %\n",
            "Loss for 5 hidden units 0.1 learning rate: 0.03648061829251433 %\n",
            "Loss for 5 hidden units 0.2 learning rate: 0.026790910409022543 %\n",
            "Loss for 5 hidden units 0.30000000000000004 learning rate: 0.02245953973163448 %\n",
            "Loss for 5 hidden units 0.4 learning rate: 0.019871310007246568 %\n",
            "Loss for 5 hidden units 0.5 learning rate: 0.018285412110538506 %\n",
            "Loss for 5 hidden units 0.6000000000000001 learning rate: 0.018806245192580468 %\n",
            "Loss for 5 hidden units 0.7000000000000001 learning rate: 0.021483338400477125 %\n",
            "Loss for 5 hidden units 0.8 learning rate: 0.093457785295959 %\n",
            "Loss for 5 hidden units 0.9 learning rate: 1.4366299009563919 %\n",
            "Loss for 6 hidden units 0.1 learning rate: 0.03418128650146732 %\n",
            "Loss for 6 hidden units 0.2 learning rate: 0.025921146030354437 %\n",
            "Loss for 6 hidden units 0.30000000000000004 learning rate: 0.022788189350426407 %\n",
            "Loss for 6 hidden units 0.4 learning rate: 0.0208316163795854 %\n",
            "Loss for 6 hidden units 0.5 learning rate: 0.019254902005604816 %\n",
            "Loss for 6 hidden units 0.6000000000000001 learning rate: 0.018900895601674524 %\n",
            "Loss for 6 hidden units 0.7000000000000001 learning rate: 0.018083186874999015 %\n",
            "Loss for 6 hidden units 0.8 learning rate: 0.0335054491309854 %\n",
            "Loss for 6 hidden units 0.9 learning rate: 1.4365927927255289 %\n",
            "Loss for 7 hidden units 0.1 learning rate: 0.034659571017532094 %\n",
            "Loss for 7 hidden units 0.2 learning rate: 0.02682320503270043 %\n",
            "Loss for 7 hidden units 0.30000000000000004 learning rate: 0.024278725217806225 %\n",
            "Loss for 7 hidden units 0.4 learning rate: 0.022928571220204044 %\n",
            "Loss for 7 hidden units 0.5 learning rate: 0.02180275499796815 %\n",
            "Loss for 7 hidden units 0.6000000000000001 learning rate: 0.01991807323418358 %\n",
            "Loss for 7 hidden units 0.7000000000000001 learning rate: 0.020735545451928374 %\n",
            "Loss for 7 hidden units 0.8 learning rate: 0.020969374184504116 %\n",
            "Loss for 7 hidden units 0.9 learning rate: 0.13264757211417935 %\n",
            "Loss for 8 hidden units 0.1 learning rate: 0.044207304510282805 %\n",
            "Loss for 8 hidden units 0.2 learning rate: 0.0334875145530841 %\n",
            "Loss for 8 hidden units 0.30000000000000004 learning rate: 0.028809738620955185 %\n",
            "Loss for 8 hidden units 0.4 learning rate: 0.025893519993032056 %\n",
            "Loss for 8 hidden units 0.5 learning rate: 0.023916922176943665 %\n",
            "Loss for 8 hidden units 0.6000000000000001 learning rate: 0.02415885125008627 %\n",
            "Loss for 8 hidden units 0.7000000000000001 learning rate: 0.018319557884212113 %\n",
            "Loss for 8 hidden units 0.8 learning rate: 0.019750054775744458 %\n",
            "Loss for 8 hidden units 0.9 learning rate: 0.027785927936725612 %\n",
            "Loss for 9 hidden units 0.1 learning rate: 0.03213657763674174 %\n",
            "Loss for 9 hidden units 0.2 learning rate: 0.025374390316458363 %\n",
            "Loss for 9 hidden units 0.30000000000000004 learning rate: 0.023526705978356297 %\n",
            "Loss for 9 hidden units 0.4 learning rate: 0.023027933735181822 %\n",
            "Loss for 9 hidden units 0.5 learning rate: 0.022932411083267153 %\n",
            "Loss for 9 hidden units 0.6000000000000001 learning rate: 0.03618963941682238 %\n",
            "Loss for 9 hidden units 0.7000000000000001 learning rate: 0.026377853712503504 %\n",
            "Loss for 9 hidden units 0.8 learning rate: 0.019012278029447056 %\n",
            "Loss for 9 hidden units 0.9 learning rate: 0.026760405173501693 %\n",
            "Loss for 10 hidden units 0.1 learning rate: 0.038884341752282454 %\n",
            "Loss for 10 hidden units 0.2 learning rate: 0.03075230418081686 %\n",
            "Loss for 10 hidden units 0.30000000000000004 learning rate: 0.027834341051639372 %\n",
            "Loss for 10 hidden units 0.4 learning rate: 0.026093919208103965 %\n",
            "Loss for 10 hidden units 0.5 learning rate: 0.024954035676163815 %\n",
            "Loss for 10 hidden units 0.6000000000000001 learning rate: 0.029192463663978263 %\n",
            "Loss for 10 hidden units 0.7000000000000001 learning rate: 0.02514636563130962 %\n",
            "Loss for 10 hidden units 0.8 learning rate: 0.022893896575534985 %\n",
            "Loss for 10 hidden units 0.9 learning rate: 0.02526642620468699 %\n",
            "Loss for 11 hidden units 0.1 learning rate: 0.03357274502748948 %\n",
            "Loss for 11 hidden units 0.2 learning rate: 0.026489496708506626 %\n",
            "Loss for 11 hidden units 0.30000000000000004 learning rate: 0.02488279974459456 %\n",
            "Loss for 11 hidden units 0.4 learning rate: 0.02472927784359925 %\n",
            "Loss for 11 hidden units 0.5 learning rate: 0.02510758522156543 %\n",
            "Loss for 11 hidden units 0.6000000000000001 learning rate: 0.031043254871105083 %\n",
            "Loss for 11 hidden units 0.7000000000000001 learning rate: 0.02601945461020297 %\n",
            "Loss for 11 hidden units 0.8 learning rate: 0.025066854868923225 %\n",
            "Loss for 11 hidden units 0.9 learning rate: 0.0244311617845184 %\n",
            "Loss for 12 hidden units 0.1 learning rate: 0.041766764890782154 %\n",
            "Loss for 12 hidden units 0.2 learning rate: 0.033133332071070554 %\n",
            "Loss for 12 hidden units 0.30000000000000004 learning rate: 0.03009918007229973 %\n",
            "Loss for 12 hidden units 0.4 learning rate: 0.028529950849121233 %\n",
            "Loss for 12 hidden units 0.5 learning rate: 0.028298183912913125 %\n",
            "Loss for 12 hidden units 0.6000000000000001 learning rate: 0.03132501163673328 %\n",
            "Loss for 12 hidden units 0.7000000000000001 learning rate: 0.02999555563303825 %\n",
            "Loss for 12 hidden units 0.8 learning rate: 0.029014881525803133 %\n",
            "Loss for 12 hidden units 0.9 learning rate: 0.02744659685638684 %\n",
            "Loss for 13 hidden units 0.1 learning rate: 0.03322095032210771 %\n",
            "Loss for 13 hidden units 0.2 learning rate: 0.026471676625740265 %\n",
            "Loss for 13 hidden units 0.30000000000000004 learning rate: 0.025337270298126414 %\n",
            "Loss for 13 hidden units 0.4 learning rate: 0.025970964480743583 %\n",
            "Loss for 13 hidden units 0.5 learning rate: 0.027529200030253522 %\n",
            "Loss for 13 hidden units 0.6000000000000001 learning rate: 0.03530552130537219 %\n",
            "Loss for 13 hidden units 0.7000000000000001 learning rate: 0.030321375458287742 %\n",
            "Loss for 13 hidden units 0.8 learning rate: 0.03281929508382007 %\n",
            "Loss for 13 hidden units 0.9 learning rate: 0.02568407045910569 %\n",
            "Loss for 14 hidden units 0.1 learning rate: 0.03858783699525445 %\n",
            "Loss for 14 hidden units 0.2 learning rate: 0.030721019628889356 %\n",
            "Loss for 14 hidden units 0.30000000000000004 learning rate: 0.028725214518348096 %\n",
            "Loss for 14 hidden units 0.4 learning rate: 0.02846589931021002 %\n",
            "Loss for 14 hidden units 0.5 learning rate: 0.02961708396990276 %\n",
            "Loss for 14 hidden units 0.6000000000000001 learning rate: 0.0374306372599497 %\n",
            "Loss for 14 hidden units 0.7000000000000001 learning rate: 0.04441436435010054 %\n",
            "Loss for 14 hidden units 0.8 learning rate: 0.03582324343489208 %\n",
            "Loss for 14 hidden units 0.9 learning rate: 0.05834537142804622 %\n",
            "Loss for 15 hidden units 0.1 learning rate: 0.03405640663759915 %\n",
            "Loss for 15 hidden units 0.2 learning rate: 0.028011569126266185 %\n",
            "Loss for 15 hidden units 0.30000000000000004 learning rate: 0.027888151431466373 %\n",
            "Loss for 15 hidden units 0.4 learning rate: 0.02969574087584788 %\n",
            "Loss for 15 hidden units 0.5 learning rate: 0.032395891400124166 %\n",
            "Loss for 15 hidden units 0.6000000000000001 learning rate: 0.0365695165200138 %\n",
            "Loss for 15 hidden units 0.7000000000000001 learning rate: 0.030598720673030485 %\n",
            "Loss for 15 hidden units 0.8 learning rate: 0.038121297595795196 %\n",
            "Loss for 15 hidden units 0.9 learning rate: 0.02232029845361922 %\n",
            "Loss for 16 hidden units 0.1 learning rate: 0.03540657649205866 %\n",
            "Loss for 16 hidden units 0.2 learning rate: 0.028266373143308 %\n",
            "Loss for 16 hidden units 0.30000000000000004 learning rate: 0.027140590961402544 %\n",
            "Loss for 16 hidden units 0.4 learning rate: 0.02898270769818741 %\n",
            "Loss for 16 hidden units 0.5 learning rate: 0.03375962795564557 %\n",
            "Loss for 16 hidden units 0.6000000000000001 learning rate: 0.03463208190377929 %\n",
            "Loss for 16 hidden units 0.7000000000000001 learning rate: 0.027811268006168188 %\n",
            "Loss for 16 hidden units 0.8 learning rate: 0.037150190795380365 %\n",
            "Loss for 16 hidden units 0.9 learning rate: 0.25092580838073836 %\n",
            "Loss for 17 hidden units 0.1 learning rate: 0.030750556678446502 %\n",
            "Loss for 17 hidden units 0.2 learning rate: 0.025170541648839032 %\n",
            "Loss for 17 hidden units 0.30000000000000004 learning rate: 0.0253703620151257 %\n",
            "Loss for 17 hidden units 0.4 learning rate: 0.030296012978781935 %\n",
            "Loss for 17 hidden units 0.5 learning rate: 0.03819365041181569 %\n",
            "Loss for 17 hidden units 0.6000000000000001 learning rate: 0.0442077684362672 %\n",
            "Loss for 17 hidden units 0.7000000000000001 learning rate: 0.0348617154031966 %\n",
            "Loss for 17 hidden units 0.8 learning rate: 0.03251344616580027 %\n",
            "Loss for 17 hidden units 0.9 learning rate: 0.018785154105626423 %\n",
            "Loss for 18 hidden units 0.1 learning rate: 0.03068374593924304 %\n",
            "Loss for 18 hidden units 0.2 learning rate: 0.024354579982824396 %\n",
            "Loss for 18 hidden units 0.30000000000000004 learning rate: 0.024239436515833653 %\n",
            "Loss for 18 hidden units 0.4 learning rate: 0.02939692051181414 %\n",
            "Loss for 18 hidden units 0.5 learning rate: 0.03951825137255871 %\n",
            "Loss for 18 hidden units 0.6000000000000001 learning rate: 0.036459338123378204 %\n",
            "Loss for 18 hidden units 0.7000000000000001 learning rate: 0.04347425896425233 %\n",
            "Loss for 18 hidden units 0.8 learning rate: 0.021385622473520625 %\n",
            "Loss for 18 hidden units 0.9 learning rate: 0.024598487333449028 %\n",
            "Loss for 19 hidden units 0.1 learning rate: 0.031415039372265065 %\n",
            "Loss for 19 hidden units 0.2 learning rate: 0.024881190483086704 %\n",
            "Loss for 19 hidden units 0.30000000000000004 learning rate: 0.025412590774616106 %\n",
            "Loss for 19 hidden units 0.4 learning rate: 0.03274467416223279 %\n",
            "Loss for 19 hidden units 0.5 learning rate: 0.038746101687626336 %\n",
            "Loss for 19 hidden units 0.6000000000000001 learning rate: 0.022543175989555964 %\n",
            "Loss for 19 hidden units 0.7000000000000001 learning rate: 0.03666854912408456 %\n",
            "Loss for 19 hidden units 0.8 learning rate: 0.5016991719271552 %\n",
            "Loss for 19 hidden units 0.9 learning rate: 0.023160773515044617 %\n",
            "Loss for 20 hidden units 0.1 learning rate: 0.0413052461563219 %\n",
            "Loss for 20 hidden units 0.2 learning rate: 0.033355765154842204 %\n",
            "Loss for 20 hidden units 0.30000000000000004 learning rate: 0.031190099972751965 %\n",
            "Loss for 20 hidden units 0.4 learning rate: 0.03351280351208471 %\n",
            "Loss for 20 hidden units 0.5 learning rate: 0.03966480612214624 %\n",
            "Loss for 20 hidden units 0.6000000000000001 learning rate: 0.02497222304924469 %\n",
            "Loss for 20 hidden units 0.7000000000000001 learning rate: 0.03140569776942094 %\n",
            "Loss for 20 hidden units 0.8 learning rate: 0.49779278813803784 %\n",
            "Loss for 20 hidden units 0.9 learning rate: 0.020187836498988573 %\n",
            "Loss for 21 hidden units 0.1 learning rate: 0.030992628511921794 %\n",
            "Loss for 21 hidden units 0.2 learning rate: 0.024253059499781498 %\n",
            "Loss for 21 hidden units 0.30000000000000004 learning rate: 0.024218836680859765 %\n",
            "Loss for 21 hidden units 0.4 learning rate: 0.032088544366107655 %\n",
            "Loss for 21 hidden units 0.5 learning rate: 0.043681765246712224 %\n",
            "Loss for 21 hidden units 0.6000000000000001 learning rate: 0.04501571981504354 %\n",
            "Loss for 21 hidden units 0.7000000000000001 learning rate: 0.025305988797138572 %\n",
            "Loss for 21 hidden units 0.8 learning rate: 0.022282369053261943 %\n",
            "Loss for 21 hidden units 0.9 learning rate: 0.02173393877854989 %\n",
            "Loss for 22 hidden units 0.1 learning rate: 0.03655985206183406 %\n",
            "Loss for 22 hidden units 0.2 learning rate: 0.030611024901182126 %\n",
            "Loss for 22 hidden units 0.30000000000000004 learning rate: 0.030871241613083793 %\n",
            "Loss for 22 hidden units 0.4 learning rate: 0.03843852934061637 %\n",
            "Loss for 22 hidden units 0.5 learning rate: 0.0481148449617183 %\n",
            "Loss for 22 hidden units 0.6000000000000001 learning rate: 0.04782848157318465 %\n",
            "Loss for 22 hidden units 0.7000000000000001 learning rate: 0.029307105544491084 %\n",
            "Loss for 22 hidden units 0.8 learning rate: 0.04094586868796084 %\n",
            "Loss for 22 hidden units 0.9 learning rate: 0.019238701093080957 %\n",
            "Loss for 23 hidden units 0.1 learning rate: 0.03290968480593356 %\n",
            "Loss for 23 hidden units 0.2 learning rate: 0.026327737487727692 %\n",
            "Loss for 23 hidden units 0.30000000000000004 learning rate: 0.02756752616965049 %\n",
            "Loss for 23 hidden units 0.4 learning rate: 0.03584682744551728 %\n",
            "Loss for 23 hidden units 0.5 learning rate: 0.028470542925762406 %\n",
            "Loss for 23 hidden units 0.6000000000000001 learning rate: 0.04306053402495519 %\n",
            "Loss for 23 hidden units 0.7000000000000001 learning rate: 0.3913475855740339 %\n",
            "Loss for 23 hidden units 0.8 learning rate: 0.02613212565675604 %\n",
            "Loss for 23 hidden units 0.9 learning rate: 0.024434847533811015 %\n",
            "Loss for 24 hidden units 0.1 learning rate: 0.034254679008050196 %\n",
            "Loss for 24 hidden units 0.2 learning rate: 0.02730414974014675 %\n",
            "Loss for 24 hidden units 0.30000000000000004 learning rate: 0.02856326433955236 %\n",
            "Loss for 24 hidden units 0.4 learning rate: 0.03365732043607756 %\n",
            "Loss for 24 hidden units 0.5 learning rate: 0.023227532032509542 %\n",
            "Loss for 24 hidden units 0.6000000000000001 learning rate: 0.032016207171656264 %\n",
            "Loss for 24 hidden units 0.7000000000000001 learning rate: 0.02977027938813688 %\n",
            "Loss for 24 hidden units 0.8 learning rate: 0.019831693606131164 %\n",
            "Loss for 24 hidden units 0.9 learning rate: 0.024927407850886554 %\n",
            "Loss for 25 hidden units 0.1 learning rate: 0.03173946729541126 %\n",
            "Loss for 25 hidden units 0.2 learning rate: 0.025316261826348708 %\n",
            "Loss for 25 hidden units 0.30000000000000004 learning rate: 0.026058340480243063 %\n",
            "Loss for 25 hidden units 0.4 learning rate: 0.038295377729121415 %\n",
            "Loss for 25 hidden units 0.5 learning rate: 0.03365180933509223 %\n",
            "Loss for 25 hidden units 0.6000000000000001 learning rate: 0.024056142383658122 %\n",
            "Loss for 25 hidden units 0.7000000000000001 learning rate: 0.20899982293145544 %\n",
            "Loss for 25 hidden units 0.8 learning rate: 0.017812638369438243 %\n",
            "Loss for 25 hidden units 0.9 learning rate: 0.03641937951263155 %\n",
            "Loss for 26 hidden units 0.1 learning rate: 0.027933854609069785 %\n",
            "Loss for 26 hidden units 0.2 learning rate: 0.021452389157553087 %\n",
            "Loss for 26 hidden units 0.30000000000000004 learning rate: 0.02224499180945159 %\n",
            "Loss for 26 hidden units 0.4 learning rate: 0.031630859295319884 %\n",
            "Loss for 26 hidden units 0.5 learning rate: 0.05181278235528222 %\n",
            "Loss for 26 hidden units 0.6000000000000001 learning rate: 0.01761075395222504 %\n",
            "Loss for 26 hidden units 0.7000000000000001 learning rate: 1.2334607218999984 %\n",
            "Loss for 26 hidden units 0.8 learning rate: 0.01735167907887393 %\n",
            "Loss for 26 hidden units 0.9 learning rate: 0.04106631094410687 %\n",
            "Loss for 27 hidden units 0.1 learning rate: 0.02934683017208243 %\n",
            "Loss for 27 hidden units 0.2 learning rate: 0.023055370117744292 %\n",
            "Loss for 27 hidden units 0.30000000000000004 learning rate: 0.02870869943943092 %\n",
            "Loss for 27 hidden units 0.4 learning rate: 0.04636887526728207 %\n",
            "Loss for 27 hidden units 0.5 learning rate: 0.05850333310525622 %\n",
            "Loss for 27 hidden units 0.6000000000000001 learning rate: 0.04342306978376643 %\n",
            "Loss for 27 hidden units 0.7000000000000001 learning rate: 1.2341630379239767 %\n",
            "Loss for 27 hidden units 0.8 learning rate: 0.017430094630748072 %\n",
            "Loss for 27 hidden units 0.9 learning rate: 0.04594186339392757 %\n",
            "Loss for 28 hidden units 0.1 learning rate: 0.027537049937084224 %\n",
            "Loss for 28 hidden units 0.2 learning rate: 0.020992507483497302 %\n",
            "Loss for 28 hidden units 0.30000000000000004 learning rate: 0.022528200649974902 %\n",
            "Loss for 28 hidden units 0.4 learning rate: 0.056280205409433806 %\n",
            "Loss for 28 hidden units 0.5 learning rate: 0.053854185781627886 %\n",
            "Loss for 28 hidden units 0.6000000000000001 learning rate: 0.236950499143584 %\n",
            "Loss for 28 hidden units 0.7000000000000001 learning rate: 0.06787220542554505 %\n",
            "Loss for 28 hidden units 0.8 learning rate: 0.023222967480418102 %\n",
            "Loss for 28 hidden units 0.9 learning rate: 0.05865453042146094 %\n",
            "Loss for 29 hidden units 0.1 learning rate: 0.028409260073998233 %\n",
            "Loss for 29 hidden units 0.2 learning rate: 0.022473816637280233 %\n",
            "Loss for 29 hidden units 0.30000000000000004 learning rate: 0.02977239989485596 %\n",
            "Loss for 29 hidden units 0.4 learning rate: 0.051950500185649874 %\n",
            "Loss for 29 hidden units 0.5 learning rate: 0.051511686010367 %\n",
            "Loss for 29 hidden units 0.6000000000000001 learning rate: 0.23369798287292023 %\n",
            "Loss for 29 hidden units 0.7000000000000001 learning rate: 0.0237046108243993 %\n",
            "Loss for 29 hidden units 0.8 learning rate: 0.02871486631835236 %\n",
            "Loss for 29 hidden units 0.9 learning rate: 0.05260696046213215 %\n",
            "Loss for 30 hidden units 0.1 learning rate: 0.027162392487263286 %\n",
            "Loss for 30 hidden units 0.2 learning rate: 0.020644729226119252 %\n",
            "Loss for 30 hidden units 0.30000000000000004 learning rate: 0.02229244193023392 %\n",
            "Loss for 30 hidden units 0.4 learning rate: 0.02856536432339849 %\n",
            "Loss for 30 hidden units 0.5 learning rate: 0.029822844051387375 %\n",
            "Loss for 30 hidden units 0.6000000000000001 learning rate: 0.03766039142421075 %\n",
            "Loss for 30 hidden units 0.7000000000000001 learning rate: 0.02046985101479914 %\n",
            "Loss for 30 hidden units 0.8 learning rate: 0.037861420378592234 %\n",
            "Loss for 30 hidden units 0.9 learning rate: 0.043874539920170104 %\n",
            "Loss for 31 hidden units 0.1 learning rate: 0.02858734517379685 %\n",
            "Loss for 31 hidden units 0.2 learning rate: 0.02207137628013541 %\n",
            "Loss for 31 hidden units 0.30000000000000004 learning rate: 0.030083766741054074 %\n",
            "Loss for 31 hidden units 0.4 learning rate: 0.024016891717425572 %\n",
            "Loss for 31 hidden units 0.5 learning rate: 0.026189348362598463 %\n",
            "Loss for 31 hidden units 0.6000000000000001 learning rate: 1.1634987513243031 %\n",
            "Loss for 31 hidden units 0.7000000000000001 learning rate: 0.017949069442827325 %\n",
            "Loss for 31 hidden units 0.8 learning rate: 0.04881366553438501 %\n",
            "Loss for 31 hidden units 0.9 learning rate: 0.04036042100578308 %\n",
            "Loss for 32 hidden units 0.1 learning rate: 0.03207269793996083 %\n",
            "Loss for 32 hidden units 0.2 learning rate: 0.024985149803184666 %\n",
            "Loss for 32 hidden units 0.30000000000000004 learning rate: 0.04041660654769804 %\n",
            "Loss for 32 hidden units 0.4 learning rate: 0.022238970762284593 %\n",
            "Loss for 32 hidden units 0.5 learning rate: 0.02010763260320866 %\n",
            "Loss for 32 hidden units 0.6000000000000001 learning rate: 1.163790703726628 %\n",
            "Loss for 32 hidden units 0.7000000000000001 learning rate: 0.016828776762951785 %\n",
            "Loss for 32 hidden units 0.8 learning rate: 0.05751205651615686 %\n",
            "Loss for 32 hidden units 0.9 learning rate: 0.03515277585337451 %\n",
            "Loss for 33 hidden units 0.1 learning rate: 0.03696778096073994 %\n",
            "Loss for 33 hidden units 0.2 learning rate: 0.03217512167168966 %\n",
            "Loss for 33 hidden units 0.30000000000000004 learning rate: 0.03761629325106026 %\n",
            "Loss for 33 hidden units 0.4 learning rate: 0.02544234348018198 %\n",
            "Loss for 33 hidden units 0.5 learning rate: 0.016064252569915092 %\n",
            "Loss for 33 hidden units 0.6000000000000001 learning rate: 1.1638836712377094 %\n",
            "Loss for 33 hidden units 0.7000000000000001 learning rate: 0.01582702140122677 %\n",
            "Loss for 33 hidden units 0.8 learning rate: 0.06497943946137791 %\n",
            "Loss for 33 hidden units 0.9 learning rate: 0.02723533588460981 %\n",
            "Loss for 34 hidden units 0.1 learning rate: 0.032066357054107604 %\n",
            "Loss for 34 hidden units 0.2 learning rate: 0.023878612017620864 %\n",
            "Loss for 34 hidden units 0.30000000000000004 learning rate: 0.027900272773322403 %\n",
            "Loss for 34 hidden units 0.4 learning rate: 0.047755609660019016 %\n",
            "Loss for 34 hidden units 0.5 learning rate: 0.015616073633121995 %\n",
            "Loss for 34 hidden units 0.6000000000000001 learning rate: 1.1639647550049936 %\n",
            "Loss for 34 hidden units 0.7000000000000001 learning rate: 0.01583726829116733 %\n",
            "Loss for 34 hidden units 0.8 learning rate: 0.0622564851241246 %\n",
            "Loss for 34 hidden units 0.9 learning rate: 0.022809637163876496 %\n",
            "Loss for 35 hidden units 0.1 learning rate: 0.02957388439621207 %\n",
            "Loss for 35 hidden units 0.2 learning rate: 0.02249040947475153 %\n",
            "Loss for 35 hidden units 0.30000000000000004 learning rate: 0.03034095828655507 %\n",
            "Loss for 35 hidden units 0.4 learning rate: 0.06795731806912615 %\n",
            "Loss for 35 hidden units 0.5 learning rate: 0.13482423607223826 %\n",
            "Loss for 35 hidden units 0.6000000000000001 learning rate: 1.1639284853747585 %\n",
            "Loss for 35 hidden units 0.7000000000000001 learning rate: 0.01934929476385665 %\n",
            "Loss for 35 hidden units 0.8 learning rate: 0.06850105843448358 %\n",
            "Loss for 35 hidden units 0.9 learning rate: 0.029341371894268248 %\n",
            "Loss for 36 hidden units 0.1 learning rate: 0.0292755078085322 %\n",
            "Loss for 36 hidden units 0.2 learning rate: 0.023245691742481714 %\n",
            "Loss for 36 hidden units 0.30000000000000004 learning rate: 0.04773489049483098 %\n",
            "Loss for 36 hidden units 0.4 learning rate: 0.0725994457328103 %\n",
            "Loss for 36 hidden units 0.5 learning rate: 0.13355151088904935 %\n",
            "Loss for 36 hidden units 0.6000000000000001 learning rate: 1.1638920199231109 %\n",
            "Loss for 36 hidden units 0.7000000000000001 learning rate: 0.017817772207458903 %\n",
            "Loss for 36 hidden units 0.8 learning rate: 0.06762440981247864 %\n",
            "Loss for 36 hidden units 0.9 learning rate: 0.023552133021770054 %\n",
            "Loss for 37 hidden units 0.1 learning rate: 0.0292744106404448 %\n",
            "Loss for 37 hidden units 0.2 learning rate: 0.023593336765696672 %\n",
            "Loss for 37 hidden units 0.30000000000000004 learning rate: 0.036591005424349454 %\n",
            "Loss for 37 hidden units 0.4 learning rate: 0.0708395454009114 %\n",
            "Loss for 37 hidden units 0.5 learning rate: 0.13245898742946793 %\n",
            "Loss for 37 hidden units 0.6000000000000001 learning rate: 1.16379066617258 %\n",
            "Loss for 37 hidden units 0.7000000000000001 learning rate: 0.024242072699772153 %\n",
            "Loss for 37 hidden units 0.8 learning rate: 0.06578662455488585 %\n",
            "Loss for 37 hidden units 0.9 learning rate: 0.01921665829006485 %\n",
            "Loss for 38 hidden units 0.1 learning rate: 0.03007893835345366 %\n",
            "Loss for 38 hidden units 0.2 learning rate: 0.025008111320963342 %\n",
            "Loss for 38 hidden units 0.30000000000000004 learning rate: 0.03681349687597718 %\n",
            "Loss for 38 hidden units 0.4 learning rate: 0.0634080028128731 %\n",
            "Loss for 38 hidden units 0.5 learning rate: 0.027961728212837825 %\n",
            "Loss for 38 hidden units 0.6000000000000001 learning rate: 1.1634758773169898 %\n",
            "Loss for 38 hidden units 0.7000000000000001 learning rate: 0.04150739996340525 %\n",
            "Loss for 38 hidden units 0.8 learning rate: 0.04994315672209061 %\n",
            "Loss for 38 hidden units 0.9 learning rate: 0.25234175286825355 %\n",
            "Loss for 39 hidden units 0.1 learning rate: 0.029841618575826546 %\n",
            "Loss for 39 hidden units 0.2 learning rate: 0.025074553022134245 %\n",
            "Loss for 39 hidden units 0.30000000000000004 learning rate: 0.061580744843586485 %\n",
            "Loss for 39 hidden units 0.4 learning rate: 0.06608141761600707 %\n",
            "Loss for 39 hidden units 0.5 learning rate: 0.02977191363013808 %\n",
            "Loss for 39 hidden units 0.6000000000000001 learning rate: 1.1634211639467107 %\n",
            "Loss for 39 hidden units 0.7000000000000001 learning rate: 0.043375291097886313 %\n",
            "Loss for 39 hidden units 0.8 learning rate: 0.049439564835823194 %\n",
            "Loss for 39 hidden units 0.9 learning rate: 0.07004306778576412 %\n",
            "Loss for 40 hidden units 0.1 learning rate: 0.028064962964822502 %\n",
            "Loss for 40 hidden units 0.2 learning rate: 0.02249865548665636 %\n",
            "Loss for 40 hidden units 0.30000000000000004 learning rate: 0.06643423031699522 %\n",
            "Loss for 40 hidden units 0.4 learning rate: 0.044492145527509123 %\n",
            "Loss for 40 hidden units 0.5 learning rate: 0.02784195174755426 %\n",
            "Loss for 40 hidden units 0.6000000000000001 learning rate: 1.163267643432306 %\n",
            "Loss for 40 hidden units 0.7000000000000001 learning rate: 0.053908212200538624 %\n",
            "Loss for 40 hidden units 0.8 learning rate: 0.04299634851777085 %\n",
            "Loss for 40 hidden units 0.9 learning rate: 0.055536002042678376 %\n",
            "Loss for 41 hidden units 0.1 learning rate: 0.030834457974400254 %\n",
            "Loss for 41 hidden units 0.2 learning rate: 0.0309902645237595 %\n",
            "Loss for 41 hidden units 0.30000000000000004 learning rate: 0.07479078864332867 %\n",
            "Loss for 41 hidden units 0.4 learning rate: 0.04370317097485794 %\n",
            "Loss for 41 hidden units 0.5 learning rate: 1.1177085741628447 %\n",
            "Loss for 41 hidden units 0.6000000000000001 learning rate: 1.1626379335126442 %\n",
            "Loss for 41 hidden units 0.7000000000000001 learning rate: 0.06210772638845385 %\n",
            "Loss for 41 hidden units 0.8 learning rate: 0.03616003877013005 %\n",
            "Loss for 41 hidden units 0.9 learning rate: 1.4140325803977376 %\n",
            "Loss for 42 hidden units 0.1 learning rate: 0.028749673633632452 %\n",
            "Loss for 42 hidden units 0.2 learning rate: 0.022663558640355262 %\n",
            "Loss for 42 hidden units 0.30000000000000004 learning rate: 0.05805245986322395 %\n",
            "Loss for 42 hidden units 0.4 learning rate: 0.02055073686289543 %\n",
            "Loss for 42 hidden units 0.5 learning rate: 1.1178552129228334 %\n",
            "Loss for 42 hidden units 0.6000000000000001 learning rate: 0.03461502430591318 %\n",
            "Loss for 42 hidden units 0.7000000000000001 learning rate: 0.06959811556695249 %\n",
            "Loss for 42 hidden units 0.8 learning rate: 0.022612102884036853 %\n",
            "Loss for 42 hidden units 0.9 learning rate: 1.4361479906505332 %\n",
            "Loss for 43 hidden units 0.1 learning rate: 0.02903066849239988 %\n",
            "Loss for 43 hidden units 0.2 learning rate: 0.024917910291117455 %\n",
            "Loss for 43 hidden units 0.30000000000000004 learning rate: 0.035140219125067776 %\n",
            "Loss for 43 hidden units 0.4 learning rate: 0.021505349048517152 %\n",
            "Loss for 43 hidden units 0.5 learning rate: 1.1179072721911805 %\n",
            "Loss for 43 hidden units 0.6000000000000001 learning rate: 0.019269867181438763 %\n",
            "Loss for 43 hidden units 0.7000000000000001 learning rate: 0.07361238214031075 %\n",
            "Loss for 43 hidden units 0.8 learning rate: 0.021447829972429035 %\n",
            "Loss for 43 hidden units 0.9 learning rate: 1.4363966749526034 %\n",
            "Loss for 44 hidden units 0.1 learning rate: 0.027229021711276707 %\n",
            "Loss for 44 hidden units 0.2 learning rate: 0.02168847140907508 %\n",
            "Loss for 44 hidden units 0.30000000000000004 learning rate: 0.028230910048663613 %\n",
            "Loss for 44 hidden units 0.4 learning rate: 0.01724001097547608 %\n",
            "Loss for 44 hidden units 0.5 learning rate: 1.1179127441158263 %\n",
            "Loss for 44 hidden units 0.6000000000000001 learning rate: 0.016431723071272348 %\n",
            "Loss for 44 hidden units 0.7000000000000001 learning rate: 0.07910552781497965 %\n",
            "Loss for 44 hidden units 0.8 learning rate: 0.023459579517854042 %\n",
            "Loss for 44 hidden units 0.9 learning rate: 1.4364700330775058 %\n",
            "Loss for 45 hidden units 0.1 learning rate: 0.02982007722930236 %\n",
            "Loss for 45 hidden units 0.2 learning rate: 0.02589352957757082 %\n",
            "Loss for 45 hidden units 0.30000000000000004 learning rate: 0.023012519518536317 %\n",
            "Loss for 45 hidden units 0.4 learning rate: 0.017508602094585008 %\n",
            "Loss for 45 hidden units 0.5 learning rate: 1.117904194817837 %\n",
            "Loss for 45 hidden units 0.6000000000000001 learning rate: 0.01676464158912946 %\n",
            "Loss for 45 hidden units 0.7000000000000001 learning rate: 0.07855746287257925 %\n",
            "Loss for 45 hidden units 0.8 learning rate: 0.02870555713054342 %\n",
            "Loss for 45 hidden units 0.9 learning rate: 1.4364811663062362 %\n",
            "Loss for 46 hidden units 0.1 learning rate: 0.039626743706835506 %\n",
            "Loss for 46 hidden units 0.2 learning rate: 0.028073101824442982 %\n",
            "Loss for 46 hidden units 0.30000000000000004 learning rate: 0.02016103932607537 %\n",
            "Loss for 46 hidden units 0.4 learning rate: 0.01595985433232717 %\n",
            "Loss for 46 hidden units 0.5 learning rate: 1.1177715381110263 %\n",
            "Loss for 46 hidden units 0.6000000000000001 learning rate: 0.017363847706419473 %\n",
            "Loss for 46 hidden units 0.7000000000000001 learning rate: 0.07826459540343483 %\n",
            "Loss for 46 hidden units 0.8 learning rate: 0.02075006641181042 %\n",
            "Loss for 46 hidden units 0.9 learning rate: 1.4364898250180334 %\n",
            "Loss for 47 hidden units 0.1 learning rate: 0.027389833191924434 %\n",
            "Loss for 47 hidden units 0.2 learning rate: 0.022921472553004897 %\n",
            "Loss for 47 hidden units 0.30000000000000004 learning rate: 0.030194209941886707 %\n",
            "Loss for 47 hidden units 0.4 learning rate: 0.018528576936650446 %\n",
            "Loss for 47 hidden units 0.5 learning rate: 1.1175389239467388 %\n",
            "Loss for 47 hidden units 0.6000000000000001 learning rate: 0.01805879740611611 %\n",
            "Loss for 47 hidden units 0.7000000000000001 learning rate: 0.07292478405968764 %\n",
            "Loss for 47 hidden units 0.8 learning rate: 0.02836442741158357 %\n",
            "Loss for 47 hidden units 0.9 learning rate: 1.4364914412967116 %\n",
            "Loss for 48 hidden units 0.1 learning rate: 0.027615213065612522 %\n",
            "Loss for 48 hidden units 0.2 learning rate: 0.02728192946477577 %\n",
            "Loss for 48 hidden units 0.30000000000000004 learning rate: 0.035534624341632785 %\n",
            "Loss for 48 hidden units 0.4 learning rate: 0.0776296250154261 %\n",
            "Loss for 48 hidden units 0.5 learning rate: 1.11729984052656 %\n",
            "Loss for 48 hidden units 0.6000000000000001 learning rate: 0.02388477151794946 %\n",
            "Loss for 48 hidden units 0.7000000000000001 learning rate: 0.06882712862697937 %\n",
            "Loss for 48 hidden units 0.8 learning rate: 0.22271321715483888 %\n",
            "Loss for 48 hidden units 0.9 learning rate: 1.4364916911808234 %\n",
            "Loss for 49 hidden units 0.1 learning rate: 0.02829857717766109 %\n",
            "Loss for 49 hidden units 0.2 learning rate: 0.03603201609411466 %\n",
            "Loss for 49 hidden units 0.30000000000000004 learning rate: 0.07564207161021065 %\n",
            "Loss for 49 hidden units 0.4 learning rate: 0.42807471587496027 %\n",
            "Loss for 49 hidden units 0.5 learning rate: 1.1170171509160864 %\n",
            "Loss for 49 hidden units 0.6000000000000001 learning rate: 0.04889062170516637 %\n",
            "Loss for 49 hidden units 0.7000000000000001 learning rate: 0.05150572041423335 %\n",
            "Loss for 49 hidden units 0.8 learning rate: 1.3252322430751273 %\n",
            "Loss for 49 hidden units 0.9 learning rate: 1.436491796111337 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAUUKWgLc-WC",
        "outputId": "9a7adaf0-1ca4-489c-c9ca-12b04d7c7987"
      },
      "source": [
        "#best_result2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Loss for 34 hidden units 0.5 learning rate: 0.015616073633121995 %']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6ir7W_Hwlro"
      },
      "source": [
        "#From tuning of parameters got number of hidden layers as 6, learning rate as 0.2\n",
        "parameters2 = nn_model(dataset_training2_arr[:,0], dataset_training2_arr[:,1], 34, 100,0.5) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UB-sXRaeXP_h",
        "outputId": "332187f0-2ae9-4659-d46d-ccf09c6b6b08"
      },
      "source": [
        "#Q1(d)Training loss for Dataset2\n",
        "length = dataset_training2_arr.shape[0]\n",
        "output_prediction_train2 = np.zeros(length)\n",
        "for i in range(length):\n",
        "    output_prediction_train2[i] = predict(parameters2,dataset_training2_arr[i,0])\n",
        "mean_squared_error(dataset_training2_arr[:,1],output_prediction_train2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.015616073633121995"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04xMVOd7xIhP"
      },
      "source": [
        "length = dataset_testing2_arr.shape[0]\n",
        "output_prediction_arr2 = np.zeros(length)\n",
        "#plot_decision_boundary(lambda x: predict(parameters, x.T), X, Y) \n",
        "for i in range(length):\n",
        "    output_prediction_arr2[i] = predict(parameters2,dataset_testing2_arr[i,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaScd-Il3JOv",
        "outputId": "d459f33e-1b73-4372-9a2d-7c6b9f29a07f"
      },
      "source": [
        "#Q1(d) Test loss for dataset2\n",
        "mean_squared_error(dataset_testing2_arr[:,1],output_prediction_arr2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0007775946848879148"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1-gJZsKNQ7x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "288127af-0064-49db-9a6d-39302a67fed9"
      },
      "source": [
        "  #Q1(C)plotting regression curve\n",
        "# plotting the actual points as scatter plot\n",
        "plt.scatter(dataset_testing2_arr[:,0], dataset_testing2_arr[:,1],marker = \"o\", s = 30)\n",
        "# plotting the regression line\n",
        "plt.scatter(dataset_testing2_arr[:,0], output_prediction_arr2)\n",
        "# putting labels\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y: actual output')\n",
        "plt.legend(['test_data','predicted_output'])\n",
        "# function to show plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}