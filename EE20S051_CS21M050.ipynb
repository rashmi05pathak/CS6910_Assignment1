{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "EE20S051_.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rashmi05pathak/CS6910_Assignment1/blob/main/EE20S051_CS21M050.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "83KWY6TcNQ7X"
      },
      "source": [
        "Q1 [ANN] In this Question, you will code a single layer ANN with Sigmoid Activation function and appropriate loss function from scratch. Train the ANN for the Dataset1 and Dataset2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVL_ojcrRDm6",
        "outputId": "05adf2c4-9cc7-4d3b-fcf8-0f4e6a00e0e8"
      },
      "source": [
        "#****PLease mount the drive according to your PRML folder location\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTSit1RFIXgg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5RiEJEyNQ7c"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSw5xqa3NQ7e"
      },
      "source": [
        "dataset_training1 = pd.read_csv(str_path+'PRML/IITM/Question1/Train_Dataset1.csv',header = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQYHUxe5NQ7g"
      },
      "source": [
        "dataset_training2 = pd.read_csv(str_path+'PRML/IITM/Question1/Train_Dataset2.csv',header = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvfVl5PQNQ7h"
      },
      "source": [
        "dataset_training1_arr = dataset_training1.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyWen5GENQ7h"
      },
      "source": [
        "dataset_training2_arr = dataset_training2.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I42MWfsFNQ7i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4afc4b3-d709-4ceb-f636-4eabe577eae7"
      },
      "source": [
        "dataset_training1_arr.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTXz9qnCNQ7k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "6ba2f9f4-088b-4279-8485-ea214942d425"
      },
      "source": [
        "#Q1(a)****Plotting dataset 1********#\n",
        "plt.scatter(dataset_training1_arr[:,0], dataset_training1_arr[:,1], color = \"g\",marker = \"o\", s = 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f265595f6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df3RU9Z038Pcn/EgEJBDJskomoMA2ul2r2UhAbLsqKo2QgIIBKQ3dYS1tYdfHZ4lW1qdrWThucg5lH/HI+iRVqhSCwZBBU11Btq38mCWwKiJBA9VMqD9SlSDKbz7PH3PTHcLce2cykztzZ96vc+Ykcz/fmXxSy3xyvz9FVUFEROkrI9EJEBFRYrEQEBGlORYCIqI0x0JARJTmWAiIiNJc30Qn0BPDhg3TUaNGJToNIiJX2bNnzx9VNbf7dVcWglGjRqG5uTnRaRARuYqIfBDuOruGiIjSHAsBEVGaYyEgIkpzLARERGmOhYCIKM3FZdaQiPwCwBQAn6jq18PEBcC/ASgB8BWAeaq614hVAPgno+m/qOqaeORE0fO1+DC3YS6OnT5m2iYnKwdPlz2N0oJSBzMjot4Ur+mjzwBYBeCXJvHvABhrPIoBPAmgWERyAPwUQBEABbBHRHyq+nmc8iILS7YuwfLXl0f1ms9OfoayurILrl015Cr86u5foTivOJ7pEZFD4lIIVPW3IjLKokkZgF9qcM/rXSIyREQuB/A3AF5V1c8AQEReBTAZwLp45EUX87X4UF5fjpPnTsbtPQ8fPYzxteNZEIhcyqkxghEAAiHP241rZtcvIiL3iUiziDR3dHT0WqKpbMnWJSirK4trEQjVVRDkUUH19upe+RlEFH+uGSxW1adUtUhVi3JzL1ohTSaqt1dDHhXIoxJ1N1AsKrdUsiAQuYRTheAIAE/I8zzjmtl1ipG/3Y8/q/ozVG6pTGgelVsqkfFoBmr31iY0DyIy51Qh8AH4ngSNB9Cpqh8CeAXA7SIyVESGArjduEYxqN5ejfG149FxIjm60BSK+ZvnY2bdzESnQkRhxGv66DoEB36HiUg7gjOB+gGAqq4G0ITg1NFWBKePft+IfSYiSwHsNt7qZ10Dx9QzPZkJ1N2AvgOw7u51F00R9bX4MOeFOTh+5niP3re+pR5F/16EhlkN8GR77F9ARI4QNx5eX1RUpNx99EKBzgDKny/HziM7o35tVp8s1M2oi2ptgK/Fh+83fh+fnexZ3W4sb+RaBCKHicgeVS266DoLgfvV7q3F/M3zo3pNTz78zVRvr+7RWASLAZGzzAqBa2YNUXiLmhZFXQSqJlXhxD+diNuH8OKJi6E/VdRMrYnqdWV1ZVjUtCguORBRz7nyYBoKuuWZW7Dtg20Rtc1ABnZ4d/TqYi9voRe3j74dFQ0VEee1avcqfHHqCzwz/Zley4uIrPGOwKXmNcyL+MO2cHgh3r//fUdW/HqyPXht3mtR3R2seWsN1xsQJRALgQv5WnxY81Zke/NVTarCngV7HJ+l4y30ou3+NhQOL4yofeWWSizZuqSXsyKicFgIXKZrm4hINJY3YvHExb2ckTlPtgd7FuzBwhsWRtR++evLeWdAlAAsBC6yqGlRxGsEkmlGzuMlj0fcVVS5pZLFgMhhLAQusWTrEqzavcq2XR/0wS7vrqQpAl28hV40ljdG1JbFgMhZLAQuUL29OqI7gb7oi9/f//uk3Qa6tKAUu7y7kBHB/+04ZkDkHBaCJFe7tzaixVr5g/Nx+P7DSb91Q3FeMd6//30Mu2SYbdvlry9nMSByAAtBEluydUlEi8UykIHX//b1pC8CXTzZHuz9wV5k9c2ybbv89eXcuZSol7EQJKnavbURdQcJBDu8O1xTBLp4sj14d+G7uDHvRtu28zfPh7/d70BWROmJhSBJLXhxQUTtdnp3Ju2YgB1PtgfbvdtRNanKtu09z9/jQEZE6YmFIAkt2boEZ/WsbbvG8kbXFoFQiycuRuGfWy88azvWBl+Lz6GMiNILC0GSibRLqGZqTdJNEY3FplmbbNvMeH4GAp0B23ZEFB0WgiTib/dHNDhcNakK3kKvAxk5x5PtsV10dub8GVz9xNUsBkRxFpdCICKTReSgiLSKyENh4j8XkTeMx7sicjQkdi4kltb3/vfU2/eDJ3rbiN4UyaKzL898ifLnyx3KiCg9xFwIRKQPgCcAfAfANQBmi8g1oW1U9X+p6nWqeh2AxwG8EBI+0RVT1dTp64hS9fZqtHW2WbZJte6gcEoLSm2Lwc4jO3mOAVEcxeOOYByAVlU9rKqnAawHYLUr2mwA6+Lwc1NGJIvGHr7p4ZTrDjJTWlCK/MH5lm1W7V7FxWZEcRKPQjACQGinbbtx7SIiMhLAlQBeC7mcJSLNIrJLRKaZ/RARuc9o19zR0RGHtJPHgpesp4qOGDQCy25d5lA2yWHDzA22bZa/vpwziYjiwOnB4lkA6lX1XMi1kcYZmvcCWCkio8O9UFWfUtUiVS3Kzc11IldHLNm6BGfPW08V3Vi+0aFskkdxXnFEm9TNeWGOA9kQpbZ4FIIjAEKXteYZ18KZhW7dQqp6xPh6GMB/Arg+Djm5QiTbSqfKWoGeKC0otV1sdvzMce5UShSjeBSC3QDGisiVItIfwQ/7i+7XRaQAwFAAO0OuDRWRTOP7YQAmAngnDjklvert1bbbSldNqkr5wWE7iycuRmZGpmUbbltNFJuYC4GqngWwEMArAA4A2KCq+0XkZyIS+ik2C8B6VdWQa1cDaBaRNwFsA/CYqqZ8IQh0BmwHhwf0HZCy00SjFcl4QeWWSq4vIOohufBz2R2Kioq0ubk50Wn02My6mahvqbdsk0wnjCWD6u3VtsVzwogJ2DF/h0MZEbmPiOwxxmQvwJXFDgt0BmyLwMM3Pcwi0M3iiYsjWl/AWURE0WMhcFh5vfWq2JysnLSbKhqp0oJSXNL3Ess2ZXVl3LKaKEosBA5asnUJdrbvtGzTNKfJoWzcaf3d623bcMtqouiwEDjE3+63nSpaMqYkbaeKRqq0oBQLb1ho2abtWBsHjomiwELgELsN5fpJP6yestqhbNzt8ZLHMXzgcMs2kR7sQ0QsBI6x21Dud3/7O9cdN5lIjbOsB46bWps4cEwUIRaCJDBhxAR2CUWpOK/Y9vwCDhwTRYaFwCGX9r/UNFY3s87BTFKHt9CLkdkjLdtwLyIieywEvczX4sNl/3oZjp8+HjZeM7WGXUIxqJthXUQPfX6IA8dENlgIepGvxYeyujJ8dvIzKC5cwZ2TlYPG8sa0OWOgt0SyS+mCzRw4JrLCQtBL/O1+TKsLf7xCTlYOPn3wU64ejpPSglKUjCkxjTcd4sAxkRUWgl7gb/djfO34i+4Cuhw9eTTsdeo5u6m30+ums4uIyAQLQS8oW2d1UicwJGuIQ5mkD0+2BzOunmEaP4/zeOCVBxzMiMg9WAjizNfiw8dffWzZ5umypx3KJr2suGOFZbz+QD2nkxKFwUIQZ3MarKcr5g/O59hAL/Fke1Ay2nysAOA+REThsBDEkb/dbzpNtEskh6xQz62euhoD+w00jbcda+PAMVE3cSkEIjJZRA6KSKuIPBQmPk9EOkTkDeMxPyRWISLvGY+KeOSTKPduvNcyfsWlV3AFcS/zZHtw4McHLNtwxTHRhWIuBCLSB8ATAL4D4BoAs0XkmjBN61T1OuNRY7w2B8BPARQDGAfgpyIyNNacEiHQGcDho4ct27xwzwsOZZPePNkejB462rKN3SaAROkkHncE4wC0quphVT0NYD0A62kz/+MOAK+q6meq+jmAVwFMjkNOjrPb7bKxvJF3Aw5ae9day3hbJ7eqJuoSj0IwAkDov6h241p3d4vIWyJSLyJdeypE+lqIyH0i0iwizR0dHXFIO35q99aiqdX8QJmSMSUcIHZYcV6x5SIzALjt2dscyoYouTk1WLwZwChVvRbBv/rXRPsGqvqUqhapalFubm7cE+wpf7sf8zfPN40LhOcMJIjd/+4HPz3IgWMixKcQHAEQumtannHtT1T1U1U9ZTytAfDXkb422d1Vd5dl/O6Cu7mpXIJ4sj22+xDN2jjLoWyIklc8CsFuAGNF5EoR6Q9gFoAL/swSkctDnpYC6JrW8QqA20VkqDFIfLtxzRX87X784fgfTOMZyMCKydaLnKh32XXJnTh7gncFlPZiLgSqehbAQgQ/wA8A2KCq+0XkZyLS9a/w70Vkv4i8CeDvAcwzXvsZgKUIFpPdAH5mXHOFsvXWY+IN5Q28G0gCVZOqLONzG+Y6lAlRchLV8BujJbOioiJtbm5OaA5dG8uZGTFoBNr/d7uDGZGVglUFOPjpQdP4Lu8uzuqilCcie1S1qPt1rizuIbu7gY3lGx3KhCLx6txXLeNTfjXFoUyIkg8LQQ/U7q3Fx1+abyw3oN8A/nWZZDzZHsszjv944o9YsnWJgxkRJQ8WgigFOgOW00UBYN1d6xzKhqLhLfQiPzvfNL789eUOZkOUPFgIomS3p/3wAcO5eCyJbZjBTf+IumMhiJLvoPVUw8bZ1vPWKbHsuuy4GR2lIxaCKPjb/Th9/rRpvGpSFccGXKBweKFp7NvPfJt7EFHaYSGIQsUm812yr7j0CiyeuNjBbKinNs3eZBo7de4UHniZR1pSemEhiFCgM4B3P33XNM4tpt3Dk+1BxTfMi3p9Sz1XG1NaYSGIQKAzgK+t+hoU4RffZWZkskvIZZbevBSZfTJN49PqprGLiNIGC0EEyp8vx4mzJ0zjU7821cFsKB482R78Zt5vTOMKxSOvPeJgRkSJw0Jgw9/ux84jO03jGcjAiju4sZwbFecVI6tPlmn8uX3P8a6A0gILgY17nrc+0nDutXO5sZyLTfkL860lzuk523UjRKmAhcCCv92PtmNtlm2W3rLUoWyoN6y4YwUG9htoGq8/UM+7Akp5LAQWpqy13ojs5pE3827A5TzZHhz48QHLgeMFm63PoyZyOxYCE74WH/548o+m8QxkYM30qE/cpCTkyfZg1l+an1T28qGXHcyGyHlxKQQiMllEDopIq4g8FCb+gIi8Yxxev1VERobEzonIG8YjaSZvz2mYYxnf4d3Bu4EUYtXFdx7nua6AUlrMhUBE+gB4AsB3AFwDYLaIXNOt2X8DKDIOr68HEHpk1AlVvc54JMVubf52P46fPm4aH9RvENcNpBhPtgeDMwebxqdvmM6xAkpZ8bgjGAegVVUPq+ppAOsBXHBqi6puU9WvjKe7EDykPmmVrbM+dGbtXWsdyoSc9Oy0Z01j5/U8FrzIsQJKTfEoBCMAhP6p1G5cM+MF8OuQ51ki0iwiu0RkmtmLROQ+o11zR0dHbBlb8Lf78fFX5ofOFA4v5DbTKaq0oBT5g83PK2hqbeLupJSSHB0sFpHvAigCUB1yeaRxhua9AFaKyOhwr1XVp1S1SFWLcnNzey3He+qt1w1YbVhG7rdhpvV5BdPWm/6tQuRa8SgERwCEjprmGdcuICKTACwBUKqqp7quq+oR4+thAP8J4Po45NQj/nY/2jrN1w0M6j+IA8QprjivGCWjS0zjH335EWr31jqYEVHvi0ch2A1grIhcKSL9AcwCcMEUCxG5HsC/I1gEPgm5PlREMo3vhwGYCOCdOOTUI3ariNdO59hAOlg9dbVl/Ecv/cihTIicEXMhUNWzABYCeAXAAQAbVHW/iPxMRLo606sBDALwfLdpolcDaBaRNwFsA/CYqiakEPhafJariCfkTeDYQJrwZHtQMsb8rsDqcCIiNxLV8FsrJ7OioiJtbm6O63sOfWwojp46GjYmEHxw/wfsFkojgc4A8leaDxxXTariQUTkOiKyxxiTvQBXFiP4j96sCADApvJNLAJpxpPtwY15N5rGK7dUonp7tWmcyE1YCBA8b8DM4MzB7BJKU+tnrMeAfgNM45VbKh3Mhqj3pH0h8LX4LM8bsFpkRKnNk+1By49bLNtw6wlKBWlfCOZummsay5AM3g2kObsuwdkvzHYoE6Lek/aF4NipY6axsTljHcyEktXwgcNNY1+d+Yqrjcn10r4QWFkzjdtME9A4q9EybrcanSjZpXUhCHQGTE+nGj5gOHcYJQDB1cZWdwVtnW3cmZRcLW0LQaAzgG+s/gZOnj0ZNt442/qvQEovdncFVdurLONEySxtC8Ejrz2CoyeP4pyeu+B6TlYOdnl38W6ALlCcV4wrBl1hGv9d2+8czIYovtKyEAQ6A3hu33NQXLyqekzOGBYBCuuF8hdMY/s+2cdBY3KttCwEj2x75KI7ASC4lcS4EeMSkBG5QXFeMRrLw3cRndfz+PYz3+ZYAblS2hWCQGcAG/ab7zlfOZGrRclcaUEpvjH8G2Fjp86dwgMvP+BwRkSxS6tCEOgM4K+e/CucOHsibDznkhzuKUS2vpn/TdNYfUs9u4jIddKqEDyy7RF0nuo0jU8ZO8XBbMitKidWIrNPpmm8vN587yqiZJRWhaCxxXwKYHZmNpbestTBbMitPNke/Gbeb0zjH3R+wLECcpW0KQS1e2tNt5rO6puFfT/cx24hilhxXjEEYhqvaKhwMBui2MSlEIjIZBE5KCKtIvJQmHimiNQZcb+IjAqJ/cS4flBE7ohHPt352/2Yv3m+abz8mnIWAYraVUOuMo1t+2AbdyaluAl0BrCoaRHG/b9xWNS0KO53nDGfUCYifQC8C+A2AO0InmE8O/TISRH5EYBrVXWBiMwCMF1Vy0XkGgDrAIwDcAWALQD+QjXM3M4Q0Z5QVrCqAAc/PWgab7u/jYWAouZv92N87XjT+JDMIfj8oc8dzIhSUdcuCMdPH8eZ82fQL6MfBvUfhDcXvBn151ZvnlA2DkCrqh5W1dMA1gMo69amDEDXDm71AG4VETGur1fVU6r6ewCtxvvF1aHPD5nGMvtksghQjxTnFVuebWx16h1RpKq2V+HYqWM4c/4MAODM+TP44tQXcd3WJB6FYASA0PuUduNa2DbGYfedAC6L8LUAABG5T0SaRaS5o6MjqgT7ZvQ1jU0dOzWq9yIKtXrKass4j7OkWNXtr7toAexZPYutv98at5/hmsFiVX1KVYtUtSg3Nzeq104ZE35aaB/0wYrJK+KRHqUpT7YHN4+82TReuaWSYwXUY9Xbq9HxVfg/fD8+/nHcfk48CsERAKF9K3nGtbBtRKQvgGwAn0b42pitmLwCl/a/9IJr/TL6Ybt3O7uFKGZrplufW3HvxnsdyoRSzYNbHjSNmS2M7Yl4FILdAMaKyJUi0h/ALADd/wTyAeiaTzcDwGsaHKX2AZhlzCq6EsBYAP8Vh5wu4Mn2YP+P9mPhDQsx7opxWHjDQhz6+0PcXI7iwpPtwdcu+5pp/MuzX3K1MUXN1+ILuzFmlzE5Y+L2s2KeNQQAIlICYCWAPgB+oarLRORnAJpV1SciWQCeBXA9gM8AzFLVw8ZrlwD4WwBnAdyvqr+2+3nRzhoi6m12M4hGDxmN1n9odTAjcrNAZwCjVo7CeZw3bdOT7fLNZg2Zj6JGQVWbADR1u/Z/Qr4/CWCmyWuXAVgWjzyIEsXuH+Sho4cQ6AywK5IiUrW9yrIIDM0cGtceDdcMFhMlu8H9B1vGudqYIvXbtt9axn/9XduOk6iwEBDFybPTn7WMc7UxRSLQGcCBTw6Yxm8eeXPcxzdZCIjipLSgFDVTayzbzGmY41A25Fblz5fjjJ4JGxvYb6DtLLWeYCEgiiNvoRd9pI9p/Pjp49yZlEz5WnzYeWRn2FgGMnDgxwd6ZZyJhYAozuym9fEUMzJjdZZFRkZGr002YCEgirM106xv3etb6nlXQBep3VuLk+dOmsZHDx3daz+bhYAozorzii23nQCCp+URhfrhiz+0jNv9gRELFgKiXmA3oPfcW8/xroD+JNAZMB0gBoDhA4f36k4ILAREvcCT7cGMq2eYxs/pubhuI0zuNqt+lmW8cZb5MbvxwEJA1EtW3HHxZoehXm592cFsKFn5WnzY0b7DNF44vLDX90VjISDqJV2bHQ7JHBI23vp5KzejI8x5wXptyabZm3o9BxYCol7kyfZg5JCRpnFuUZ3efC0+HD9z3DR+1ZCrHNmfioWAqJd9M/+bprHDRw9z0DhNBToDKKvrfqrvhX51968cyYWFgKiXVU6stIzbDRRSalqweYFl/Ma8Gx07M4WFgKiXebI9lofc72jfwc3o0lDToSbL+PoZ6x3KhIWAyBF2h9yX1ZVx4DiN1O6ttYwP6jfI0bMrYioEIpIjIq+KyHvG16Fh2lwnIjtFZL+IvCUi5SGxZ0Tk9yLyhvG4LpZ8iJKVJ9uDftLPsk3FJp5XkC4WvGjdLbT2rrUOZRIU6x3BQwC2qupYAFuN5919BeB7qvqXACYDWCkiofPpFqvqdcbjjRjzIUpaT0550jJ+8NODHDhOA/52P87qWdN4Vp8slBaUOphR7IWgDEDXWvo1AKZ1b6Cq76rqe8b3fwDwCYDcGH8uket4C72YMGKCZRur3ScpNdhNGa6bUedQJv8j1kIwXFU/NL7/CMBwq8YiMg5AfwCHQi4vM7qMfi4imRavvU9EmkWkuaOjI8a0iRKjbmYdBGIa39m+k3cFKSzQGcDho4dN418f9nXH7waACAqBiGwRkbfDPC6YAKuqCkAt3udyAM8C+L6qdp3K/BMABQBuAJAD4EGz16vqU6papKpFubm8oSB38mR78L1rv2fZhucVpK4HXrH+b9v0XeuZRL3FthCo6iRV/XqYRyOAj40P+K4P+k/CvYeIDAbwEoAlqror5L0/1KBTAJ4GMC4evxRRMlt6y1LLOM8rSE2BzgA2HthoGi8ZU+LoTKFQsXYN+QB0TXWoAHDRFnki0h9AA4Bfqmp9t1hXEREExxfejjEfoqTnyfagapL1zqPcmTT1VDRUQM07TWynGPemWAvBYwBuE5H3AEwynkNEikSk6xTvewB8C8C8MNNE14rIPgD7AAwD8C8x5kPkCosnLsbAfgNN4y+++6KD2VBvq91bi20fbDONzyiYkbC7AQCQYNe+uxQVFWlzc3Oi0yCKybyGeVjzlvkBNjVTa+At9DqYEfWGQGcA+SvzLdu03d/mSCEQkT2qWtT9OlcWEyXI0luWWp5X8IPNP3AwG+otdseSJvpuAGAhIEqYrvMKzJzDOVRvr3YwI+oNLxx4wTK+YvIKhzIxx0JAlECebA8y+5gun0HllkrOIHKx2r21+OL0F6bxAX0HJPxuAGAhIEq4J0qesIxPW3/Rgn1ygUBnAH+3+e8s26y7e51D2VhjISBKMG+hF32lr2l870d72UXkQo9se8RyuujNI29OyCricFgIiJKA3RxydhG5S6AzgDVvms8IA4A1063jTmIhIEoC3kIvhg+w3KoLFQ3cptot7E6dq5lakxRjA11YCIiSROPsixbmX2DbB9t4kpkL+Nv92NG+w7JNsq0PYSEgShLFecX46z//a8s2cxvmOpQN9ZTdAUM5WTkOZRI5FgKiJNIwq8Eyfuz0MR5pmeRaP2u1jD9d9rRDmUSOhYAoiXiyPRg9dLRlm7s33O1QNhQtf7sf5/Scafzhmx5OmplCoVgIiJKM3Xm1R744whlESSjQGcC3nv6WaXzCiAlYdusyBzOKHAsBUZIpzivGjIIZlm14eE3yWbB5AU6fPx02liEZqJvp/BGUkWIhIEpCdvvPNB60nmFEzvK1+NB0yPx0sbnXzk2q6aLdsRAQJSFPtgc3j7zZNH5Gz3C1cZIIdAYwvW66aVwgWHqz9al0iRZTIRCRHBF5VUTeM74ONWl3LuRQGl/I9StFxC8irSJSZ5xmRkSwX3lauaWS6wqSQEVDBc7jvGn87qvvTuq7ASD2O4KHAGxV1bEAthrPwzmhqtcZj9Ah838F8HNVHQPgcwDJtcqCKIE82R6UjCmxbDN742yHsqFwfC0+y5PHMpCBFXckfptpO7EWgjIAXX+2rEHw3OGIGOcU3wKg6xzjqF5PlA5WT1mNDDH/Z/rV2a94V5BAcxrmWMYbyhuS/m4AiL0QDFfVD43vPwJgtllKlog0i8guEen6sL8MwFFVPWs8bwcwwuwHich9xns0d3R0xJg2kTt4sj1ouMd6kdmcF6w/jKh3+Fp8OH76uGm8ZHRJUq4ZCMe2EIjIFhF5O8yjLLSdBg8/NttzdaRxTua9AFaKiPWKmTBU9SlVLVLVotzc3GhfTuRapQWluDHvRtP48TPHeVeQAOUbyy3jq6da7yibTGwLgapOUtWvh3k0AvhYRC4HAOPrJybvccT4ehjAfwK4HsCnAIaI/Gkj9jwAR2L+jYhS0PoZ6y3j0+qmcZGZg3wtPpw8e9I0PjJ7pCu6hLrE2jXkA9C1w1IFgIsmN4vIUBHJNL4fBmAigHeMO4htAGZYvZ6I7KeTKpTbVDuovN76bmDqX0x1KJP4iLUQPAbgNhF5D8Ak4zlEpEhEaow2VwNoFpE3Efzgf0xV3zFiDwJ4QERaERwzqI0xH6KUZTedlNtUO8PX4sPJc+Z3AwBQObHSoWziQ4J/mLtLUVGRNjc3JzoNIsf5WnwoqyszjWcgA+/f/76ruiXcJNAZQP7KfMs2jeWNSTtILCJ7jPHaC3BlMZGLlBaUIj/b/IPoPM5jwYsLHMwovdj9b3tJ30uStghYYSEgcpkNMzZYxptam3hmQS/wt/vR1Gq+nxAArL/belA/WbEQELlMcV4xaqbWWLbh2oL48rf7Mb52vGWbCSMmuPJuAGAhIHIlb6EXJaPNt5849Pkh3hXE0T3P32PbJpm3mbbDQkDkUqunroZATON31d3lYDapy9/uR9uxNss2NVNrXD1Az0JA5FKebA82lW8yjf/h+B94VxAHZevNZ2kBwVlC3kJ375fJQkDkYnZ90t965ltccRyD6u3V+PjLj03jM66e4dpxgVAsBEQuN7j/YNPY6XOnUbGJK457ItAZQOUW64VhbthiOhIsBEQu9+z0Zy3j297fxtPMesBuzUDJmBJXjwuEYiEgcrnSglLb6aQ8zSw6tXtrbdcMrJ7int1F7bAQEKUAb6EXMwpmWLYpqyvjeEEEAp0BzN8837LNhBETUuZuAGAhIEoZKybb91eXP2+9a7nGxFIAAAtJSURBVCbBdkwls0+mq9cMhMNCQJQi7LaqBoCdR3aidi83+TXjb/dj2/vmZxADwHuL3kupuwGAhYAopdhtVQ0AP9j8AwcycSe7NQP5g/NTrggALAREKcWT7UFjufX5TudwjrOIwpjXMM9yzQAAbJhpveGfW7EQEKWY0oJSlIwx34cI4Cyi7uY1zMOat6zvpmqm1qA4r9ihjJwVUyEQkRwReVVE3jO+Dg3T5mYReSPkcVJEphmxZ0Tk9yGx62LJh4iCVk9Zjcw+mZZtyurKuAUFglNF7YrAiEEjXL+NhJVY7wgeArBVVccC2Go8v4CqblPV61T1OgC3APgKwH+ENFncFVfVN2LMh4gQ7CJ6b9F7tu3uqbffVTOVRTJVFAA2lm90IJvEibUQlAHoKqVrAEyzaT8DwK9V9asYfy4R2YhkFlFbZ1tadxFFcppb1aSqlO0S6hJrIRiuqh8a338EYLhN+1kA1nW7tkxE3hKRn4uI6b2siNwnIs0i0tzR0RFDykTpI5JZRHMb5jqQSfLxtfhsVw9XXFuBxRMXO5RR4tgWAhHZIiJvh3lcMM9KVRWAWrzP5QD+CsArIZd/AqAAwA0AcgA8aPZ6VX1KVYtUtSg3N9cubSJC8K7g4Zsetmxz7PQxLGpa5FBGyaF6ezXK6qynivaX/nhm+jPOJJRgfe0aqOoks5iIfCwil6vqh8YH/ScWb3UPgAZVPRPy3l13E6dE5GkA/xhh3kQUoWW3LsOQrCGWO2mu2r0KgzMHY9mtyxzMLDF8LT7bXUUB4Pl7nncgm+QQa9eQD0DXeuwKAFYTmGejW7eQUTwgIoLg+MLbMeZDRGEsnrjYdn3B8teXp8Wq45kbZtq2qZpUlRLnDEQq1kLwGIDbROQ9AJOM5xCRIhH503aIIjIKgAfAb7q9fq2I7AOwD8AwAP8SYz5EZKK0oBT5g/Mt28zfPD+li8Gdz92J03rask1jeWNajAuEkmDXvrsUFRVpc3NzotMgch1/ux/ja8fbttvl3ZVyM2UWNS3Cqt2rLNuUjCnBS3Necigj54nIHlUt6n6dK4uJ0khxXjEW3rDQtt342vEpNa10ydYltkUASK0zBqLBQkCUZh4vedx2JhEQXHmcCsWgdm8tlr++3LZdY3ljSm4oFwkWAqI0tOzWZbanmgHu34bC3+6PaOVwxbUVaTU43B0LAVGa8hZ6bVceA+7tJqrdWxvReEjJ6JK0WS9ghoWAKI2tmb4Gl/a/1Lad27qJavfWRnQnkJOVg5e+m7qDw5FiISBKY55sD/b/aD8G9Rtk29YtZx5HupEcADTNsd5iIl2wEBClOU+2B1u+tyWitt98+ptJXQwCnQHc9uxtEbVN5fMFosVCQEQoziuOaPD4g84PMPr/jk7KAeTq7dXIX5mPg58etG3bWN6Y0ucLRIuFgIgABAePqyZV2bY7c/5M0g0gz2uYF9H+QUCwCKTzDKFwWAiI6E8WT1wcUTEAgmMGd669M6FdRb4WH7KWZtmeMAYAA/oNwC7vLhaBMFgIiOgCiycujqibCACaWpuQvzI/IfsT+Vp8KKsrw6nzp2zbZmdmo+XHLRwTMMFCQEQX8RZ6bXcrDTV/83xkPJrhSEHwt/tRsKrA9jyBLhXfqMC+H+5L21XDkWAhIKKwSgtKscu7C/0y+kXUXqGYv3k+qrdX90o+gc4A7lx7J8bXjo9oQBgIbif9zLRnWARscPdRIrIU6AzgpqdvQltnW1Svy8/Ox4YZG2Lujgl0BlCxqQLb3t8W1esqrq1I+xXD3XH3USLqEU+2B69//3UM7Dcwqte1dbZhfO34Hg8oV2+vhjwqyF+ZH3URWHjDQhaBKPCOgIgiEugMYMGLC2wPfLdjdqfga/Fh1sZZOHH2RI/fe1C/QVh711rODDJhdkcQUyEQkZkA/hnA1QDGqWrYT2cRmQzg3wD0AVCjql0nmV0JYD2AywDsATBX1eb4ILAQECVSpPv4OOnS/pdi/4/2cyzARm91Db0N4C4Av7X4wX0APAHgOwCuATBbRK4xwv8K4OeqOgbA5wC41I8oyXkLvdjl3YWcrJxEpwIgeKoYi0BsYioEqnpAVe2G78cBaFXVw8Zf++sBlBkH1t8CoN5otwbBA+yJKMkV5xXj0wc/RWN5I7L6ZCUsj8byRrw05yUWgRg5MVg8AkDoSFG7ce0yAEdV9Wy362GJyH0i0iwizR0dHb2WLBFFrrSgFCf+6QRqptYgw8G5J8MHDucq4Tiy/S8nIltE5O0wj8hWc8SJqj6lqkWqWpSbm+vkjyYiG95CL8799BxqptZEvO6gJ0YPGY1d3l346B8/4irhOOpr10BVJ8X4M44ACL1vyzOufQpgiIj0Ne4Kuq4TkUt5C73wFnoR6AygvL4cO9t3xvye/aQfnpzyJHcL7UW2hSAOdgMYa8wQOgJgFoB7VVVFZBuAGQiOG1QAiHxNOxElLU+2Bzu8O/70PNAZwKz6WdjRvsPiVf+jalIVFk9c3FvpUTexTh+dDuBxALkAjgJ4Q1XvEJErEJwmWmK0KwGwEsHpo79Q1WXG9asQLAI5AP4bwHdV1XYHKU4fJSKKXq+sI0gUFgIiouhxiwkiIgqLhYCIKM2xEBARpTkWAiKiNOfKwWIR6QDwQQ9fPgzAH+OYjtPcnj/g/t/B7fkD7v8d3J4/kJjfYaSqXrQi15WFIBYi0hxu1Nwt3J4/4P7fwe35A+7/HdyeP5BcvwO7hoiI0hwLARFRmkvHQvBUohOIkdvzB9z/O7g9f8D9v4Pb8weS6HdIuzECIiK6UDreERARUQgWAiKiNJc2hUBEJovIQRFpFZGHEp1PtETkFyLyiYi8nehcekJEPCKyTUTeEZH9IvIPic4pWiKSJSL/JSJvGr/Do4nOqSdEpI+I/LeIvJjoXHpCRN4XkX0i8oaIuG73SREZIiL1ItIiIgdEZELCc0qHMQIR6QPgXQC3IXgk5m4As1X1nYQmFgUR+RaA4wB+qapfT3Q+0RKRywFcrqp7ReRSAHsATHPZfwMBMFBVj4tIPwCvA/gHVd2V4NSiIiIPACgCMFhVpyQ6n2iJyPsAilTVlQvKRGQNgN+pao2I9AcwQFWPJjKndLkjGAegVVUPq+ppBM9AcPSozVip6m8BfJboPHpKVT9U1b3G918AOACLM6qTkQYdN572Mx6u+ktKRPIA3AmgJtG5pCMRyQbwLQC1AKCqpxNdBID0KQQjAARCnrfDZR9CqURERgG4HoA/sZlEz+hWeQPAJwBeVVW3/Q4rAVQCOJ/oRGKgAP5DRPaIyH2JTiZKVwLoAPC00T1XIyIDE51UuhQCShIiMgjARgD3q+qxROcTLVU9p6rXIXjG9jgRcU03nYhMAfCJqu5JdC4xuklVCwF8B8CPjW5Tt+gLoBDAk6p6PYAvASR8zDJdCsERAJ6Q53nGNXKQ0a++EcBaVX0h0fnEwrid3wZgcqJzicJEAKVGH/t6ALeIyHOJTSl6qnrE+PoJgAYEu37doh1Ae8idZD2ChSGh0qUQ7AYwVkSuNAZnZgHwJTintGIMtNYCOKCqKxKdT0+ISK6IDDG+vwTByQctic0qcqr6E1XNU9VRCP4beE1Vv5vgtKIiIgONyQYwulRuB+CamXSq+hGAgIh8zbh0K4CET5jom+gEnKCqZ0VkIYBXAPQB8AtV3Z/gtKIiIusA/A2AYSLSDuCnqlqb2KyiMhHAXAD7jD52AHhYVZsSmFO0LgewxpiFlgFgg6q6cgqmiw0H0BD8uwJ9AfxKVV9ObEpRWwRgrfFH6WEA309wPukxfZSIiMylS9cQERGZYCEgIkpzLARERGmOhYCIKM2xEBARpTkWAiKiNMdCQESU5v4/Tv3BDPXUCgQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rMwX3FMNQ7l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "fcfae11a-9c9d-4f9d-adfa-4e3acd4ea48e"
      },
      "source": [
        "#Q1(b)Plotting Dataset2********# \n",
        "plt.scatter(dataset_training2_arr[:,0],dataset_training2_arr[:,1],color = \"g\",marker = \"o\", s = 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f264f518410>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZa0lEQVR4nO3df5BV5Z3n8ff39g/ICHbMQOKA3RB/xzWY1bbbDDFZRnaiLD/8kYASJjDDCI0lVVtupScrNbPZpXQmTWK21mRCWrFCAkaCirQEY0SdaHrkGmIAiUNGJJHbaAwmsSMykYb+7h/dEsB7u2/3Pfec+9z7eVV1Vfc5557zPTZ8fHjO85zH3B0REQlXKukCRESkMApyEZHAKchFRAKnIBcRCZyCXEQkcNVJXHTMmDE+ceLEJC4tIhKsn/zkJ6+7+9iTtycS5BMnTmTbtm1JXFpEJFhm9nK27epaEREJnIJcRCRwCnIRkcApyEVEAqcgFxEJXCRBbmZXmtnPzWyPmX0+inOKiIQu051hwUMLqPvHOux/27GvCV+ZQLorHdl1Ch5+aGZVwNeA/wp0AT82sw53f6HQc4uIlJpljy/j9h/dXtA59v1+H5etuoytC7fSfEZzwTVFMY68Cdjj7nsBzOw+YBagIBeRIKx6bhUtm1o44kdive6ND9/IziU7Cz5PFEE+Hsgc93MX8K7/xZjZImARQENDQwSXFREZWKY7w5z1c3hm/zNJl5LV3t/tjeQ8sc3sdPd2oB2gsbFRq1mIyLBlujNc/Z2ree6155IupSBnnnZmJOeJIsj3A/XH/XxG/zYRkSHp2N3BvA3zePPwm0mXEou7ZtwVyXmiCPIfA+eY2QfpC/DrgbkRnFdEysiq51ax6OFF9NKbdCmJazi1ge9++ruRPOiECILc3Y+Y2c3Ao0AVcI+7/6zgykQkGB27O5hz/xz+cPQPSZdSkk6tPZVvX/NtZp4/syjnj6SP3N03A5ujOJeIlJZMd4aWTS08sucRHD3eekcNNdw/5/6ihfNQJPIaWxEpHSs6V9C6pTXpMkpCbaqWmefO5I4r76C+rn7wD5QIBblImct0Z2h5uIXNL1XuP5rPfO+Z3HvdvZH1SZcaBblI4Ep9rHQxGcYXp36Rz03+XNKlJEpBLhKAjt0dfObBz3Cw52DSpcRm/OjxPDD7gbJtRUdJQS5SIjp2dzD/ofm88fYbSZdSVGpFR09BLhKjdFeaWffN4rW3Xku6lKIYVTOKtdeuLYmRHJVEQS5SBOmuNHMfmMveN6J5l0apmHDqBNZ9ep26O0qMglxkmNJdaabfO53X/+P1pEuJRG2qln/+b//MwosXJl2KDJGCXCQPHbs7uOHBGzjUcyjpUoYlRYpz/vQcVl+9Wq3pMqQgFznOgg0LWL1zddJlDFu1VbNy+kq1qiuMglwqTqY7wy3fv4VNezZx+Ohh3D2oqedj3jOGTXM3qWUtxyjIpewltfpLIdqmtml4nuRNQS5lI6Rx2IZx1dlXsXL6yqDe6SGlSUEuQcp0Z5i/YT5Pvvxk0qUMSJNfJA4Kcil56a408x+az57f7uGoH026nKymnT1NrWtJjIJcSkopz3xMkaJ9RrtGhEjJUZBLYkq1eyTUd1JL5VKQS2yWPb6M2390e9JlnKDc31MtlaGgIDezTwNfAD4ENLn7tiiKkvKw6rlVtDzcwhFKY9jflAlTWH3NarWypewU2iLfBVwLfCOCWiRwKzpX8Pktn098lfSPjv8o6z69ToEtFaOgIHf3fwMws2iqkaB07O5g9vrZvN37dqJ13Hzpzdw57c5EaxBJUmx95Ga2CFgE0NDQENdlJWJJrlTzgVM+wMbrN6o/W+Qkgwa5mW0BTs+ya5m7b8z3Qu7eDrQDNDY2hvNiiwq3onMFf7fl7xJ5F8m40eN4cPaDCm6RQQwa5O4+NY5CpHR07O7gsw99lu63u2O7pl4EJTJ8Gn4oZLoztGxq4ft7vh/bg8pxo8bx4By1tkWiUOjww2uAO4GxwPfMbLu7fzKSyqSoVnSuoHVLa9GvkyJF3cg6Zp43k+VTlmskiUgRFDpqZQOwIaJapMjiCm+AD/zJB9h4gx5MisRBXStlLq7w1mQbkeQoyMtQHCu4j64dzZpr1jDz/JlFu4aI5EdBXiY6dncw98G5vNXzVtGucevHbuW2K24r2vlFZHgU5IFb9dwq/vbhv438vDVWw6zzZ3HHJ/UGQJFSpyAPULFa31onUiRMCvKApLvSzF4/m32/3xfpeRXgImFTkJe4dybrPLLnkcimyevtgCLlRUFeot4J8M17Nhd8rroRdTw671GN6RYpUwryEpLpznDL92/hod0PRbYYg0aaiJQ/BXkJSHeluXbdtbxy8JVIzje6djSP/dVjaoGLVAgFecKimnn5nur3cN9192mCjkgFUpAnIKoHmBPqJjDj3Bm0Tm7Vg0uRCqYgj1kUE3j0ClgROZ6CPCbLHl/G7T+6fdifr05Vc/V5V2umpYi8i4I8Bks3L+WrP/7qsD6bIkX7jHYWXrww4qpEpFwoyIukY3cHcx+Yy1tHhj+NXjMuRSQfCvIiKGQkSrVVs3L6SrXARSRvhS71tgKYARwGXgL+2t3fiKKwEGW6M8zfMJ8nX35yyJ/98Ps/zPfmfk/93yIyZKkCP/8YcKG7TwL+HfifhZcUplXPraLh/zYMOcQN4+4Zd7NzyU6FuIgMS6Frdv7guB+3Ap8qrJzwdOzu4IYHbuDQkUND+pweYopIVKLsI/8bYF2unWa2CFgE0NDQEOFlk5HpzjBn/Rye2f/MkD6ntS1FJGqDBrmZbQFOz7Jrmbtv7D9mGXAEWJvrPO7eDrQDNDY2RvM+1oSku9JMvmcyR/3okD6nF1iJSDEMGuTuPnWg/Wa2AJgOXOHuQQd0Pjp2dzBr3awhfUYzMUWkmAodtXIl0Ap8wt2H1kkcoKFOrx8/ajwPzHlAAS4iRVVoH/lXgRHAY2YGsNXdWwquqsRkujNMWzONXa/vyvszd8+4Ww8yRSQWhY5aOTuqQkpVuivNZasuG9Jn2qa2KcRFJDaa2TmATHdmSCGuWZkikgQFeQ7prjSf+OYn8j5+45yNWtRBRBKhIM9iKA81q6iic2GnHmiKSGIKnaJfdlZ0rsg7xC8ccyG/+O+/UIiLSKLUIj/OUN5a+KnzP8X6OeuLXJGIyODUIu+X7krnHeLzJ81XiItIyVCQ0xfil99zeV7H3vqxW/nmNd8sbkEiIkNQ8V0rQxknrpEpIlKKKj7I5z4wN6/jti7cqoeaIlKSKrprZdnjy9j7xt5Bj9s4Z6NCXERKVsUG+YrOFdz+o9sHPU7dKSJS6iqya6Vjd8egI1RqUjU8/ddPqyUuIiWv4oI83ZUe9H3ip444lV1LdmkVHxEJQsV1rUy/d/qgx/xg3g8U4iISjIoK8nRXmtf/4/UBj7nk9EvUnSIiQamYIM90Z/jzVX8+4DFVVsWG6zfEVJGISDQqJsjnb5hPL70DHtP5N53qUhGR4FREkGe6Mzz58pMDHnPrx25Vl4qIBKmgIDez5Wa208y2m9kPzGxcVIVFaf6G+QPuHzNyDLddcVtM1YiIRKvQFvkKd5/k7h8BNgH/EEFNkVrRuWLQ1vimz2yKqRoRkegVFOTu/vvjfjwF8MLKiVY+r6Ztm9qmLhURCVrBE4LM7Dbgs0A3MGWA4xYBiwAaGhoKvWxerl137YD7p0ycwucmfy6WWkREimXQFrmZbTGzXVm+ZgG4+zJ3rwfWAjfnOo+7t7t7o7s3jh07Nro7GMArB1/Juc8wVl+9OpY6RESKadAWubtPzfNca4HNwP8qqKKIdOzuGHD/XTPu0lBDESkLhY5aOee4H2cBuwsrJzrzH8o9UqXKqlh48cIYqxERKZ5C+8j/yczOA3qBl4GWwksqXKY7wxtvv5Fz/zemfyPGakREiqugIHf366IqJEq3PHpLzn2nVJ+i1riIlJWym9mZ7kpz/7/dn3P/vdfdG2M1IiLFV3ZBPnv97Jz7pp09Tav9iEjZKasgT3el2ff7fTn3r5y+MsZqRETiUVZBPtBIlZFVIzXcUETKUlkF+Z7f7sm5b/q5g68MJCISorIJ8kx3hqN+NOf+Oz55R4zViIjEp2yC/O+f+Puc++pG1KlbRUTKVlkEeaY7w7d2fivn/qvPuzrGakRE4lUWQX7Lo7fgOd6gaxjL/2J5zBWJiMSnLIJ804u5F4Y4f8z56lYRkbJWFkHec7Qn574rPnhFjJWIiMQv+CDPdGdwz96tkiJF6+SBVwgSEQld8EHe1tmGYVn3bZizQd0qIlL2gg/yJ37xBEd59/jxc047R+9VEZGKEHSQZ7oz7H49+1oWI2tGxlyNiEgygg7yts42eunNui9lQd+aiEjegk679P50zn2XN1weYyUiIsmJJMjN7H+YmZvZmCjOl6/m8c1U27sXORpRNUKjVUSkYhQc5GZWD/wlkPtF4EXSOrmV0SNGnxDmI6pG8MMFP9RoFRGpGFG0yL8CtEKOOfJFVF9Xz46WHbQ0ttA0rombL72ZF5e+SPMZzXGXIiKSmIIWXzazWcB+d99hln0s93HHLgIWATQ0NBRy2RPU19Vz57Q7IzufiEhoBm2Rm9kWM9uV5WsWcCvwD/lcyN3b3b3R3RvHjh1baN1A39Juk74+iVG3j2LS1yeR7sr98FNEpFxZruntg37Q7MPA48Ch/k1nAK8ATe7+q4E+29jY6Nu2bRvWdd+R7kpz2arL3rV968Kt6loRkbJkZj9x98aTtw+7j9zdn3f397v7RHefCHQBFw8W4lHJtT7nQOt2ioiUo2DHkb/4mxezbn/pdy/FXImISLIKeth5vP5WeSzSXemcMzqrU5HdkohIEIJskd/48I05900/e3qMlYiIJC/IIN/7u705991x5R0xViIikrwgg/yMU8/Iuv2s087SjE4RqThBBvlZ7z0r6/bz3ndezJWIiCQvyCDf9mr2Mei5touIlLMggzzHym65t4uIlLEgg/yqs68a0nYRkXIWZJAvaVxCbVXtsZ8No25EHcunLE+wKhGRZAQX5JnuDFetvYre3j9OCKqtquXReY9qxIqIVKTggryts42Dhw9yxI8c29brvazZuSbBqkREkhNckKf3p+np7TlhW09vD8/ufzahikREkhVckDePb6YmVXPCtppUDU3jmxKqSEQkWcEFeevkVkZWjzxh28jqkVpsWUQqVnBB/tNXf8qbh988Ydubh9/klTdfSagiEZFkBRXkme4M16y7Juu+gd6IKCJSzoIK8rbOtpzvIR/ojYgiIuUsqCBP78+9uPKZp50ZYyUiIqUjqCBvHt9MKkfJd824K+ZqRERKQ0FBbmZfMLP9Zra9/2taVIVlM2/SPBx/1/a7Z9xN8xnNxby0iEjJimKBy6+4+5ciOM+g1uxcQ1WqiiO9f5zVWZOqYfuvtsdxeRGRkhRU10p6f/qEEAfN6hQRiSLIbzaznWZ2j5mdlusgM1tkZtvMbNuBAweGdaHm8c1Up078R4RmdYpIpRs0yM1si5ntyvI1C/g6cBbwEeBV4Mu5zuPu7e7e6O6NY8eOHVax8ybNy9oinzdp3rDOJyJSDgbtI3f3qfmcyMzuAjYVXNEAvvSv2bviv/SvX2L97PXFvLSISMkqdNTKnx334zXArsLKGdimF7P/fyLXdhGRSlDoqJU2M/sI4MAvgcUFVzSAI0ePDGm7iEglKCjI3f2voiokH2e97yx+/pufZ90uIlKpghp+2Da1Lev21VevjrkSEZHSEUyQZ7ozLNi4gCqqjm1LkWLjnI2a1SkiFS2YIH9nrc6jHD22rSpVxWN7H0uwKhGR5AUT5FqrU0Qku2CCXGt1iohkF0yQt05uZVTtqGNhXpOqYVTtKK3VKSIVL5ggr6+rZ0fLDhZfspimcU0svmQxO1p2UF9Xn3RpIiKJiuI1trGpr6vnzml3Jl2GiEhJCaZFLiIi2SnIRUQCpyAXEQmcglxEJHBBBXmmO8PSzUtpuquJpZuXkunOJF2SiEjighm1kunOcNHKizh4+CA9vT1s/9V21j6/VkMQRaTiBdMif+ddK+9M0+/p7eHg4YO0dWZ/I6KISKUIJsj1rhURkeyCCfLm8c1Up07sCdK7VkREIghyM1tqZrvN7GdmVrR+jnmT5nG09+gJ2470HmHepHnFuqSISBAKXXx5CjALuMjd/xOQfZn7CKzZuYaUnVhulVWxZueaYl1SRCQIhbbIlwD/5O5vA7j7rwsvKbun9z3NUT+pRe5HeHrf08W6pIhIEAoN8nOBy80sbWY/NLNLcx1oZovMbJuZbTtw4MCQL9TrvUPaLiJSKQYdR25mW4DTs+xa1v/59wGXAZcC3zWzM93dTz7Y3duBdoDGxsZ37c+jjqzbT+5uERGpNIMGubtPzbXPzJYAD/YH97Nm1guMAYbe5B7Exxs+zgu/foEjfuTYtmqr5vKGy6O+lIhIUAptzj4ETAEws3OBWuD1QovKpnVyK6fUnoLR1zI3jFNqT9EKQSJS8Qqdon8PcI+Z7QIOA/OzdatEyTAcPxboIiKVrqAWubsfdvd57n6hu1/s7k9EVdjJ2jrbONRziF76Hm720suhnkOaoi8iFS+YJ4Waoi8ikl0wQd48vpmaVM0J2zRFX0QkoCBvndzKqNpRx8K8JlXDqNpRetgpIhUvmCCvr6tnR8sOFl+ymKZxTSy+ZLHeRS4iQkALS0BfmN857c6kyxARKSnBtMhFRCQ7BbmISOCCCXItvCwikl0QfeRaeFlEJLcgWuRaeFlEJLcgglyzOkVEcgsiyC8Ye0HW7R8a+6GYKxERKT1BBPlbb781pO0iIpUkiCB/at9TQ9ouIlJJggjynK8e1yvJRUTCCPKrzr5qSNtFRCpJEEG+fMpy6kbUkeovN0WKuhF1LJ+yPOHKRESSF0SQ19fV8/yS57np0ptoGtfETZfexPNLntdkIBERCpzZaWbrgPP6f3wv8Ia7f6TgqrLQmw9FRLIrKMjdfc4735vZl4HugisSEZEhieRdK2ZmwGzgL6I4n4iI5C+qPvLLgdfc/cVcB5jZIjPbZmbbDhw4ENFlRURk0Ba5mW0BTs+ya5m7b+z//gbgOwOdx93bgXaAxsZGH2KdIiKSw6BB7u5TB9pvZtXAtcAlURUlIiL5i6JrZSqw2927IjiXiIgMURRBfj2DdKuIiEjxFDxqxd0XRFCHiIgMUxAzO0VEJDcFuYhI4BTkIiKBCybIM90Zlm5eStNdTSzdvJRMdybpkkRESkIkU/SLLdOd4aKVF3Hw8EF6envY/qvtrH1+LTtadugNiCJS8YJokbd1th0LcYCe3h4OHj5IW2dbwpWJiCQviCBP708fC/F39PT28Oz+ZxOqSESkdAQR5M3jm6lJ1ZywrSZVQ9P4poQqEhEpHUEEeevkVkbVjjoW5jWpGkbVjqJ1cmvClYmIJC+IIK+vq2dHyw4WX7KYpnFNLL5ksR50ioj0C2LUCmipNxGRXIJokYuISG4KchGRwCnIRUQCpyAXEQmcglxEJHDmHv86yGZ2AHh5mB8fA7weYTkh0D1XBt1zZSjknie4+9iTNyYS5IUws23u3ph0HXHSPVcG3XNlKMY9q2tFRCRwCnIRkcCFGOTtSReQAN1zZdA9V4bI7zm4PnIRETlRiC1yERE5joJcRCRwJRvkZnalmf3czPaY2eez7B9hZuv696fNbGL8VUYrj3u+xcxeMLOdZva4mU1Ios4oDXbPxx13nZm5mQU/VC2fezaz2f2/65+Z2b1x1xi1PP5sN5jZk2b20/4/39OSqDMqZnaPmf3azHbl2G9m9v/6/3vsNLOLC7qgu5fcF1AFvAScCdQCO4ALTjrmJmBl//fXA+uSrjuGe54C/En/90sq4Z77jxsNPAVsBRqTrjuG3/M5wE+B0/p/fn/Sdcdwz+3Akv7vLwB+mXTdBd7zx4GLgV059k8DHgEMuAxIF3K9Um2RNwF73H2vux8G7gNmnXTMLGB1//f3A1eYmcVYY9QGvWd3f9LdD/X/uBU4I+Yao5bP7xlgOfBF4A9xFlck+dzzjcDX3P13AO7+65hrjFo+9+zAqf3f1wGvxFhf5Nz9KeC3AxwyC/iW99kKvNfM/my41yvVIB8PZI77uat/W9Zj3P0I0A38aSzVFUc+93y8hfT9Hz1kg95z/z856939e3EWVkT5/J7PBc41s04z22pmV8ZWXXHkc89fAOaZWRewGVgaT2mJGerf9wEFs0KQ/JGZzQMagU8kXUsxmVkKuANYkHApcaumr3vlv9D3r66nzOzD7v5GolUV1w3AN939y2b2UeDbZnahu/cmXVgISrVFvh84fkHOM/q3ZT3GzKrp++fYb2KprjjyuWfMbCqwDJjp7m/HVFuxDHbPo4ELgX8xs1/S15fYEfgDz3x+z11Ah7v3uPsvgH+nL9hDlc89LwS+C+DuzwAj6Xu5VLnK6+97vko1yH8MnGNmHzSzWvoeZnacdEwHML//+08BT3j/U4RADXrPZvafgW/QF+Kh95vCIPfs7t3uPsbdJ7r7RPqeC8x0923JlBuJfP5sP0RfaxwzG0NfV8veOIuMWD73vA+4AsDMPkRfkB+Itcp4dQCf7R+9chnQ7e6vDvtsST/dHeCp7zT6WiIvAcv6t/0f+v4iQ98vej2wB3gWODPpmmO45y3Aa8D2/q+OpGsu9j2fdOy/EPiolTx/z0Zfl9ILwPPA9UnXHMM9XwB00jeiZTvwl0nXXOD9fgd4Feih719YC4EWoOW43/HX+v97PF/on2tN0RcRCVypdq2IiEieFOQiIoFTkIuIBE5BLiISOAW5iEjgFOQiIoFTkIuIBO7/A13GJsdHckumAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjwSZTyvNQ7m"
      },
      "source": [
        "#Test data\n",
        "dataset_testing1 = pd.read_csv(str_path+'PRML/IITM/Question1/Test_Dataset1.csv',header = None)\n",
        "dataset_testing2 = pd.read_csv(str_path+'PRML/IITM/Question1/Test_Dataset2.csv',header = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD8H6pQmNQ7m"
      },
      "source": [
        "dataset_testing1_arr = dataset_testing1.to_numpy()\n",
        "dataset_testing2_arr = dataset_testing2.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPx1DJN_7NJt",
        "outputId": "c3d16fa3-ebf4-4aae-e7ea-4e4b0efa09d4"
      },
      "source": [
        "dataset_training2_arr.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmoOkRqANQ7q"
      },
      "source": [
        "def sigmoid(x):\n",
        "    s = 1/(1+np.exp(-x))\n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUnoe7vVNQ7q"
      },
      "source": [
        "#Initialize the model’s parameters\n",
        "def initialize_parameters(n_x, n_h, n_y):\n",
        "    np.random.seed(2) # we set up a seed so that output matches\n",
        "    #Weight and bias \n",
        "    W1 = np.random.randn(n_h,n_x) * 0.01\n",
        "    b1 = np.zeros((n_h,1))\n",
        "    W2 = np.random.randn(n_y,n_h)* 0.01\n",
        "    b2 = np.zeros((n_y,1))\n",
        "    #print(W1,b1,W2,b2)\n",
        "    parameters = {\"W1\": W1,\"b1\": b1,\"W2\": W2,\"b2\": b2}\n",
        "    return parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDcMGtvENQ7r"
      },
      "source": [
        "def forward_propagation(X, parameters): \n",
        "    # Retrieve each parameter from the dictionary \"parameters\" \n",
        "    W1 = parameters[\"W1\"]\n",
        "    b1 = parameters[\"b1\"]\n",
        "    W2 = parameters[\"W2\"]\n",
        "    b2 = parameters[\"b2\"]\n",
        "    # Implement Forward Propagation to calculate A2\n",
        "    Z1 = np.dot(W1,X)+b1\n",
        "    A1 = sigmoid(Z1)\n",
        "    Z2 = np.dot(W2,A1)+b2 \n",
        "    A2 = Z2\n",
        "    cache = {\"Z1\": Z1,\"A1\": A1,\"Z2\": Z2,\"A2\": A2}\n",
        "    return A2, cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeUl4PQaNQ7s"
      },
      "source": [
        "#implement mean squared error as output is real number\n",
        "def mean_squared_error(y_true,y_pred):\n",
        "    length = y_pred.shape[0]\n",
        "    sum_error = 0\n",
        "    for i in range(length):\n",
        "        sum_error = sum_error + ((y_pred[i] - y_true[i])**2)\n",
        "    return sum_error/length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4jfb_XdNQ7s"
      },
      "source": [
        "#Notation used meaning is as below\n",
        "#dW1 = ∂J/∂W1\n",
        "#db1 = ∂J/∂b1\n",
        "#dW2 = ∂J/∂W2\n",
        "#db2 = ∂J/∂b2\n",
        "#A1*(1 - A1) is differentiation of sigmoid function\n",
        "# Implementing backward_propagation\n",
        "def backward_propagation(parameters, cache, X, Y):\n",
        "   # m = 1 #one dimensional data\n",
        "    # First, retrieve W1 and W2 from the dictionary \"parameters\". \n",
        "    W1 = parameters[\"W1\"]\n",
        "    W2 = parameters[\"W2\"]\n",
        "    A1 = cache[\"A1\"]\n",
        "    A2 = cache[\"A2\"]\n",
        "    # Backward propagation: calculate dW1, db1, dW2, db2.\n",
        "    dZ2 = A2-Y\n",
        "    dW2 = np.dot(dZ2,A1.T)\n",
        "    db2 = np.sum(dZ2,axis=1,keepdims=True)\n",
        "    dZ1 = np.dot(W2.T,dZ2)*A1*(1 - A1) #sigmoid as activation function at hidden layer\n",
        "    dW1 = np.dot(dZ1,X.T)\n",
        "    db1 = np.sum(dZ1,axis=1,keepdims=True)\n",
        "    grads = {\"dW1\": dW1,\"db1\": db1,\"dW2\": dW2,\"db2\": db2}\n",
        "    return grads"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulawqQFK9ukM"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-rSOh2jNQ7s"
      },
      "source": [
        "def update_parameters(parameters, grads, learning_rate): \n",
        "    W1 = parameters[\"W1\"]\n",
        "    b1 = parameters[\"b1\"]\n",
        "    W2 = parameters[\"W2\"]\n",
        "    b2 = parameters[\"b2\"]\n",
        "    dW1 = grads[\"dW1\"]\n",
        "    db1 = grads[\"db1\"]\n",
        "    dW2 = grads[\"dW2\"] \n",
        "    db2 = grads[\"db2\"]\n",
        "    W1 = W1-learning_rate*dW1\n",
        "    b1 = b1-learning_rate*db1\n",
        "    W2 = W2-learning_rate*dW2\n",
        "    b2 = b2-learning_rate*db2\n",
        "    parameters = {\"W1\": W1,\"b1\": b1,\"W2\": W2,\"b2\": b2}\n",
        "    return parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RukkvmsNQ7t"
      },
      "source": [
        "#****Neural Network method***********#\n",
        "def nn_model(X, Y, n_h, num_iterations,learning_rate): \n",
        "    np.random.seed(3)\n",
        "    parameters = initialize_parameters(1, n_h, 1) \n",
        "    W1 = parameters[\"W1\"]\n",
        "    b1 = parameters[\"b1\"]\n",
        "    W2 = parameters[\"W2\"]\n",
        "    b2 = parameters[\"b2\"] \n",
        "    # Loop (gradient descent)\n",
        "    for i in range(0, num_iterations):\n",
        "        for x,y in zip(X,Y):\n",
        "            A2, cache = forward_propagation(x, parameters)\n",
        "            grads = backward_propagation(parameters, cache, x, y)\n",
        "            # Gradient descent parameter update.\n",
        "            parameters = update_parameters(parameters, grads,learning_rate) \n",
        "    return parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6xwdpiQNQ7u"
      },
      "source": [
        "def predict(parameters,X):\n",
        "    W1 = parameters[\"W1\"]\n",
        "    b1 = parameters[\"b1\"]\n",
        "    W2 = parameters[\"W2\"]\n",
        "    b2 = parameters[\"b2\"] \n",
        "    A2, cache = forward_propagation(X, parameters)\n",
        "    return A2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dq3PCUDUvOK",
        "outputId": "63cc1286-5172-47d3-d6e9-ea630e612226"
      },
      "source": [
        "#*****Commenting the code as it's running time is approx. 20 min after that it will give the best parameter for minimum loss\n",
        "#******Tuning Hidden layer and learning rate for Dataset1 ***********************#\n",
        "#hidden_layer_sizes = [x for x in range(1,50)]\n",
        "#learning_rate = [0.001,0.01,0.1,1.0]\n",
        "#best_result = []\n",
        "#min_loss = 10#Assuming minimum loss to start with\n",
        "#for i, n_h in enumerate(hidden_layer_sizes):\n",
        "  #for j,lr in enumerate(learning_rate):\n",
        "      #parameters = nn_model(dataset_training1_arr[:,0], dataset_training1_arr[:,1], n_h, 100,lr) \n",
        "      #length = dataset_training1_arr.shape[0]\n",
        "      #output_prediction_arr = np.zeros(length)\n",
        "      #for i in range(length):\n",
        "          #output_prediction_arr[i] = predict(parameters,dataset_training1_arr[i,0])\n",
        "      #loss = mean_squared_error(dataset_training1_arr[:,1],output_prediction_arr)\n",
        "      #if(loss<min_loss):\n",
        "        #min_loss = loss\n",
        "        #best_result.clear()\n",
        "        #best_result.append(\"Loss for {} hidden units {} learning rate: {} %\".format(n_h,lr,loss))\n",
        "      #print (\"Loss for {} hidden units {} learning rate: {} %\".format(n_h,lr,loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for 1 hidden units 0.001 learning rate: 0.1588531121822333 %\n",
            "Loss for 1 hidden units 0.01 learning rate: 0.07251820982537349 %\n",
            "Loss for 1 hidden units 0.1 learning rate: 0.06671285862166351 %\n",
            "Loss for 1 hidden units 1.0 learning rate: 0.3698348908112 %\n",
            "Loss for 2 hidden units 0.001 learning rate: 0.17624835389694843 %\n",
            "Loss for 2 hidden units 0.01 learning rate: 0.03872547441218037 %\n",
            "Loss for 2 hidden units 0.1 learning rate: 0.036100924545429784 %\n",
            "Loss for 2 hidden units 1.0 learning rate: 0.13041488649218916 %\n",
            "Loss for 3 hidden units 0.001 learning rate: 0.18407410882595457 %\n",
            "Loss for 3 hidden units 0.01 learning rate: 0.022029201187955507 %\n",
            "Loss for 3 hidden units 0.1 learning rate: 0.00024698152955478534 %\n",
            "Loss for 3 hidden units 1.0 learning rate: 0.4540550447814892 %\n",
            "Loss for 4 hidden units 0.001 learning rate: 0.1822856655932304 %\n",
            "Loss for 4 hidden units 0.01 learning rate: 0.022095689389607535 %\n",
            "Loss for 4 hidden units 0.1 learning rate: 0.0006372851591981716 %\n",
            "Loss for 4 hidden units 1.0 learning rate: 0.423629407423319 %\n",
            "Loss for 5 hidden units 0.001 learning rate: 0.18685872691282596 %\n",
            "Loss for 5 hidden units 0.01 learning rate: 0.02466548988473411 %\n",
            "Loss for 5 hidden units 0.1 learning rate: 0.00017106949826036343 %\n",
            "Loss for 5 hidden units 1.0 learning rate: 0.39833474591670526 %\n",
            "Loss for 6 hidden units 0.001 learning rate: 0.18820313530550148 %\n",
            "Loss for 6 hidden units 0.01 learning rate: 0.023427741109242235 %\n",
            "Loss for 6 hidden units 0.1 learning rate: 0.0010656859476847456 %\n",
            "Loss for 6 hidden units 1.0 learning rate: 0.37697854950752463 %\n",
            "Loss for 7 hidden units 0.001 learning rate: 0.18737882589686014 %\n",
            "Loss for 7 hidden units 0.01 learning rate: 0.016725254643645417 %\n",
            "Loss for 7 hidden units 0.1 learning rate: 0.0014976082672714594 %\n",
            "Loss for 7 hidden units 1.0 learning rate: 0.35876384411858253 %\n",
            "Loss for 8 hidden units 0.001 learning rate: 0.1882041187297197 %\n",
            "Loss for 8 hidden units 0.01 learning rate: 0.019809354836626634 %\n",
            "Loss for 8 hidden units 0.1 learning rate: 0.001052830198381297 %\n",
            "Loss for 8 hidden units 1.0 learning rate: 0.3430840796709249 %\n",
            "Loss for 9 hidden units 0.001 learning rate: 0.18886529100955116 %\n",
            "Loss for 9 hidden units 0.01 learning rate: 0.021330693369774546 %\n",
            "Loss for 9 hidden units 0.1 learning rate: 0.0016643446606156688 %\n",
            "Loss for 9 hidden units 1.0 learning rate: 0.32949257936127596 %\n",
            "Loss for 10 hidden units 0.001 learning rate: 0.18900718399447122 %\n",
            "Loss for 10 hidden units 0.01 learning rate: 0.027635129261374416 %\n",
            "Loss for 10 hidden units 0.1 learning rate: 0.005291991869950668 %\n",
            "Loss for 10 hidden units 1.0 learning rate: 0.3176510676656425 %\n",
            "Loss for 11 hidden units 0.001 learning rate: 0.18926822077274993 %\n",
            "Loss for 11 hidden units 0.01 learning rate: 0.02228683887475104 %\n",
            "Loss for 11 hidden units 0.1 learning rate: 0.002783175872103397 %\n",
            "Loss for 11 hidden units 1.0 learning rate: 0.30729375611461096 %\n",
            "Loss for 12 hidden units 0.001 learning rate: 0.18945559294928585 %\n",
            "Loss for 12 hidden units 0.01 learning rate: 0.1052614146077473 %\n",
            "Loss for 12 hidden units 0.1 learning rate: 0.0016721413574307615 %\n",
            "Loss for 12 hidden units 1.0 learning rate: 0.1274591411855757 %\n",
            "Loss for 13 hidden units 0.001 learning rate: 0.18943708749419025 %\n",
            "Loss for 13 hidden units 0.01 learning rate: 0.029225132686763265 %\n",
            "Loss for 13 hidden units 0.1 learning rate: 0.0019875225052429476 %\n",
            "Loss for 13 hidden units 1.0 learning rate: 0.12219179643413934 %\n",
            "Loss for 14 hidden units 0.001 learning rate: 0.18957897098526072 %\n",
            "Loss for 14 hidden units 0.01 learning rate: 0.07699884873455864 %\n",
            "Loss for 14 hidden units 0.1 learning rate: 0.0010767058748851765 %\n",
            "Loss for 14 hidden units 1.0 learning rate: 0.3121639915712664 %\n",
            "Loss for 15 hidden units 0.001 learning rate: 0.18934473413112057 %\n",
            "Loss for 15 hidden units 0.01 learning rate: 0.02465882268835732 %\n",
            "Loss for 15 hidden units 0.1 learning rate: 0.000770305544704545 %\n",
            "Loss for 15 hidden units 1.0 learning rate: 0.25723058641718716 %\n",
            "Loss for 16 hidden units 0.001 learning rate: 0.1898229970941729 %\n",
            "Loss for 16 hidden units 0.01 learning rate: 0.11462654746278886 %\n",
            "Loss for 16 hidden units 0.1 learning rate: 0.001980491493745554 %\n",
            "Loss for 16 hidden units 1.0 learning rate: 0.24847893174876265 %\n",
            "Loss for 17 hidden units 0.001 learning rate: 0.18994731123151845 %\n",
            "Loss for 17 hidden units 0.01 learning rate: 0.17036732994845788 %\n",
            "Loss for 17 hidden units 0.1 learning rate: 0.0025419564595868726 %\n",
            "Loss for 17 hidden units 1.0 learning rate: 0.07967268605799414 %\n",
            "Loss for 18 hidden units 0.001 learning rate: 0.18978784989821015 %\n",
            "Loss for 18 hidden units 0.01 learning rate: 0.062305851170758736 %\n",
            "Loss for 18 hidden units 0.1 learning rate: 0.001378773939425358 %\n",
            "Loss for 18 hidden units 1.0 learning rate: 0.07986649275254036 %\n",
            "Loss for 19 hidden units 0.001 learning rate: 0.189858819961532 %\n",
            "Loss for 19 hidden units 0.01 learning rate: 0.13446446703188195 %\n",
            "Loss for 19 hidden units 0.1 learning rate: 0.003117930181118054 %\n",
            "Loss for 19 hidden units 1.0 learning rate: 0.2428013525302213 %\n",
            "Loss for 20 hidden units 0.001 learning rate: 0.18993831752604137 %\n",
            "Loss for 20 hidden units 0.01 learning rate: 0.17377447279801225 %\n",
            "Loss for 20 hidden units 0.1 learning rate: 0.007408738447692176 %\n",
            "Loss for 20 hidden units 1.0 learning rate: 0.10219769206031935 %\n",
            "Loss for 21 hidden units 0.001 learning rate: 0.19001325790103113 %\n",
            "Loss for 21 hidden units 0.01 learning rate: 0.046832187682579435 %\n",
            "Loss for 21 hidden units 0.1 learning rate: 0.0009196107862997047 %\n",
            "Loss for 21 hidden units 1.0 learning rate: 0.13153290607492435 %\n",
            "Loss for 22 hidden units 0.001 learning rate: 0.1900612069667175 %\n",
            "Loss for 22 hidden units 0.01 learning rate: 0.16969866229382577 %\n",
            "Loss for 22 hidden units 0.1 learning rate: 0.00043382373860014004 %\n",
            "Loss for 22 hidden units 1.0 learning rate: 0.13524744477793654 %\n",
            "Loss for 23 hidden units 0.001 learning rate: 0.19011885331715078 %\n",
            "Loss for 23 hidden units 0.01 learning rate: 0.16750234306867623 %\n",
            "Loss for 23 hidden units 0.1 learning rate: 0.0015133309365530103 %\n",
            "Loss for 23 hidden units 1.0 learning rate: 0.13092448355396458 %\n",
            "Loss for 24 hidden units 0.001 learning rate: 0.19001979259402824 %\n",
            "Loss for 24 hidden units 0.01 learning rate: 0.08295996659921145 %\n",
            "Loss for 24 hidden units 0.1 learning rate: 0.0009318912999322728 %\n",
            "Loss for 24 hidden units 1.0 learning rate: 0.1308868023296024 %\n",
            "Loss for 25 hidden units 0.001 learning rate: 0.19020110733268025 %\n",
            "Loss for 25 hidden units 0.01 learning rate: 0.17884333524287876 %\n",
            "Loss for 25 hidden units 0.1 learning rate: 0.004334679610795536 %\n",
            "Loss for 25 hidden units 1.0 learning rate: 0.3146102250738141 %\n",
            "Loss for 26 hidden units 0.001 learning rate: 0.19023149099538664 %\n",
            "Loss for 26 hidden units 0.01 learning rate: 0.1833565546171698 %\n",
            "Loss for 26 hidden units 0.1 learning rate: 0.0006192710394874151 %\n",
            "Loss for 26 hidden units 1.0 learning rate: 0.8320666066309554 %\n",
            "Loss for 27 hidden units 0.001 learning rate: 0.1902351469883335 %\n",
            "Loss for 27 hidden units 0.01 learning rate: 0.13119102944893302 %\n",
            "Loss for 27 hidden units 0.1 learning rate: 0.0007034998683678849 %\n",
            "Loss for 27 hidden units 1.0 learning rate: 0.839670875797247 %\n",
            "Loss for 28 hidden units 0.001 learning rate: 0.19024192753799865 %\n",
            "Loss for 28 hidden units 0.01 learning rate: 0.1820783373352288 %\n",
            "Loss for 28 hidden units 0.1 learning rate: 0.0004331941647566766 %\n",
            "Loss for 28 hidden units 1.0 learning rate: 0.8219960885342839 %\n",
            "Loss for 29 hidden units 0.001 learning rate: 0.19023766038814927 %\n",
            "Loss for 29 hidden units 0.01 learning rate: 0.11724824123100722 %\n",
            "Loss for 29 hidden units 0.1 learning rate: 0.0007050325313421784 %\n",
            "Loss for 29 hidden units 1.0 learning rate: 0.3328889441726309 %\n",
            "Loss for 30 hidden units 0.001 learning rate: 0.1903486600378092 %\n",
            "Loss for 30 hidden units 0.01 learning rate: 0.18563275303990817 %\n",
            "Loss for 30 hidden units 0.1 learning rate: 0.04336443170485106 %\n",
            "Loss for 30 hidden units 1.0 learning rate: 0.842466722342009 %\n",
            "Loss for 31 hidden units 0.001 learning rate: 0.19039458815404034 %\n",
            "Loss for 31 hidden units 0.01 learning rate: 0.16973649482139877 %\n",
            "Loss for 31 hidden units 0.1 learning rate: 0.00027117007554663426 %\n",
            "Loss for 31 hidden units 1.0 learning rate: 0.8432528213072612 %\n",
            "Loss for 32 hidden units 0.001 learning rate: 0.19038893889705216 %\n",
            "Loss for 32 hidden units 0.01 learning rate: 0.18382874050002324 %\n",
            "Loss for 32 hidden units 0.1 learning rate: 0.01869949550139769 %\n",
            "Loss for 32 hidden units 1.0 learning rate: 0.8446165471518696 %\n",
            "Loss for 33 hidden units 0.001 learning rate: 0.19035026097322316 %\n",
            "Loss for 33 hidden units 0.01 learning rate: 0.06031095167990949 %\n",
            "Loss for 33 hidden units 0.1 learning rate: 0.00037963785054483427 %\n",
            "Loss for 33 hidden units 1.0 learning rate: 0.8444766792207653 %\n",
            "Loss for 34 hidden units 0.001 learning rate: 0.19064331520823002 %\n",
            "Loss for 34 hidden units 0.01 learning rate: 0.18766730819509553 %\n",
            "Loss for 34 hidden units 0.1 learning rate: 0.04573848752903055 %\n",
            "Loss for 34 hidden units 1.0 learning rate: 0.8452553081725084 %\n",
            "Loss for 35 hidden units 0.001 learning rate: 0.19048027945227478 %\n",
            "Loss for 35 hidden units 0.01 learning rate: 0.18509904936826357 %\n",
            "Loss for 35 hidden units 0.1 learning rate: 0.0005141904856897561 %\n",
            "Loss for 35 hidden units 1.0 learning rate: 0.8448683361623673 %\n",
            "Loss for 36 hidden units 0.001 learning rate: 0.1905081431785708 %\n",
            "Loss for 36 hidden units 0.01 learning rate: 0.179465916587732 %\n",
            "Loss for 36 hidden units 0.1 learning rate: 0.0003409363416306202 %\n",
            "Loss for 36 hidden units 1.0 learning rate: 0.8451033718065515 %\n",
            "Loss for 37 hidden units 0.001 learning rate: 0.19052196739799823 %\n",
            "Loss for 37 hidden units 0.01 learning rate: 0.1839821912946676 %\n",
            "Loss for 37 hidden units 0.1 learning rate: 0.0006364937631819298 %\n",
            "Loss for 37 hidden units 1.0 learning rate: 0.8452178545319885 %\n",
            "Loss for 38 hidden units 0.001 learning rate: 0.19076040950189296 %\n",
            "Loss for 38 hidden units 0.01 learning rate: 0.18688366524202274 %\n",
            "Loss for 38 hidden units 0.1 learning rate: 0.04097853331113228 %\n",
            "Loss for 38 hidden units 1.0 learning rate: 0.8445665221847284 %\n",
            "Loss for 39 hidden units 0.001 learning rate: 0.19059340600723448 %\n",
            "Loss for 39 hidden units 0.01 learning rate: 0.1840972535422245 %\n",
            "Loss for 39 hidden units 0.1 learning rate: 0.0006869707412702886 %\n",
            "Loss for 39 hidden units 1.0 learning rate: 0.8453447970867002 %\n",
            "Loss for 40 hidden units 0.001 learning rate: 0.19055858153261104 %\n",
            "Loss for 40 hidden units 0.01 learning rate: 0.18417890594247846 %\n",
            "Loss for 40 hidden units 0.1 learning rate: 0.0013260475223843035 %\n",
            "Loss for 40 hidden units 1.0 learning rate: 0.8455142940039913 %\n",
            "Loss for 41 hidden units 0.001 learning rate: 0.19062704535180364 %\n",
            "Loss for 41 hidden units 0.01 learning rate: 0.18229400104619162 %\n",
            "Loss for 41 hidden units 0.1 learning rate: 0.0003070912374103859 %\n",
            "Loss for 41 hidden units 1.0 learning rate: 0.8454782331309254 %\n",
            "Loss for 42 hidden units 0.001 learning rate: 0.1908048592729161 %\n",
            "Loss for 42 hidden units 0.01 learning rate: 0.18703842959741743 %\n",
            "Loss for 42 hidden units 0.1 learning rate: 0.03386961924102292 %\n",
            "Loss for 42 hidden units 1.0 learning rate: 0.8450573320891565 %\n",
            "Loss for 43 hidden units 0.001 learning rate: 0.19068868058082916 %\n",
            "Loss for 43 hidden units 0.01 learning rate: 0.18380690545290398 %\n",
            "Loss for 43 hidden units 0.1 learning rate: 0.0007626939564907242 %\n",
            "Loss for 43 hidden units 1.0 learning rate: 0.8448660250847999 %\n",
            "Loss for 44 hidden units 0.001 learning rate: 0.19075999269861751 %\n",
            "Loss for 44 hidden units 0.01 learning rate: 0.17777984751448755 %\n",
            "Loss for 44 hidden units 0.1 learning rate: 0.0007277981278485193 %\n",
            "Loss for 44 hidden units 1.0 learning rate: 0.8438637786293243 %\n",
            "Loss for 45 hidden units 0.001 learning rate: 0.19092251084906087 %\n",
            "Loss for 45 hidden units 0.01 learning rate: 0.1828146484916726 %\n",
            "Loss for 45 hidden units 0.1 learning rate: 0.00022824850770839314 %\n",
            "Loss for 45 hidden units 1.0 learning rate: 0.8446158248353707 %\n",
            "Loss for 46 hidden units 0.001 learning rate: 0.19085088862086083 %\n",
            "Loss for 46 hidden units 0.01 learning rate: 0.18726322595369413 %\n",
            "Loss for 46 hidden units 0.1 learning rate: 0.04666934887574858 %\n",
            "Loss for 46 hidden units 1.0 learning rate: 0.8431775844101458 %\n",
            "Loss for 47 hidden units 0.001 learning rate: 0.19083976655991453 %\n",
            "Loss for 47 hidden units 0.01 learning rate: 0.1858078198444786 %\n",
            "Loss for 47 hidden units 0.1 learning rate: 0.0019901343806692 %\n",
            "Loss for 47 hidden units 1.0 learning rate: 0.8409881860877253 %\n",
            "Loss for 48 hidden units 0.001 learning rate: 0.19076966091677702 %\n",
            "Loss for 48 hidden units 0.01 learning rate: 0.18445365806797107 %\n",
            "Loss for 48 hidden units 0.1 learning rate: 0.0010033493617848598 %\n",
            "Loss for 48 hidden units 1.0 learning rate: 0.8404877151249246 %\n",
            "Loss for 49 hidden units 0.001 learning rate: 0.19102004171546097 %\n",
            "Loss for 49 hidden units 0.01 learning rate: 0.189097010463566 %\n",
            "Loss for 49 hidden units 0.1 learning rate: 0.048558775657011034 %\n",
            "Loss for 49 hidden units 1.0 learning rate: 0.8393159677872298 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ngii1zLaVjF",
        "outputId": "1ad9efdb-64ee-4261-ec82-e0d83c2bbcaa"
      },
      "source": [
        "#best_result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Loss for 5 hidden units 0.1 learning rate: 0.00017106949826036343 %']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isVtEz_ENQ7u"
      },
      "source": [
        "#parameters1 = nn_model(dataset_training1_arr[:,0], dataset_training1_arr[:,1],41,100,0.1)\n",
        "parameters1 = nn_model(dataset_training1_arr[:,0], dataset_training1_arr[:,1],5,100,0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83_fC1FaNQ7u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39bde6ef-bcca-4d69-d89b-d64b7e36e175"
      },
      "source": [
        "#Q1(d)Training loss\n",
        "length = dataset_training1_arr.shape[0]\n",
        "output_prediction_train = np.zeros(length)\n",
        "for i in range(length):\n",
        "    output_prediction_train[i] = predict(parameters1,dataset_training1_arr[i,0])\n",
        "mean_squared_error(dataset_training1_arr[:,1],output_prediction_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00017106949826036343"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWj_vxU2NQ7v"
      },
      "source": [
        "length = dataset_testing1_arr.shape[0]\n",
        "output_prediction_arr1 = np.zeros(length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDHHLzB7NQ7v"
      },
      "source": [
        "for i in range(length):\n",
        "    output_prediction_arr1[i] = predict(parameters1,dataset_testing1_arr[i,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHpuhjTVNQ7w"
      },
      "source": [
        "#output_prediction_arr\n",
        "#output_prediction_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utX8DgiONQ7w"
      },
      "source": [
        "#Q1(d) Dataset1 Test loss\n",
        "loss1 = mean_squared_error(dataset_testing1_arr[:,1],output_prediction_arr1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voZuIfrDNQ7w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "933cc98a-2688-494a-f5ad-9cbd686da783"
      },
      "source": [
        "loss1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00016598034303931655"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "8jqH18vI2b07",
        "outputId": "09161005-aec0-4dea-ebef-ae538f41f5ed"
      },
      "source": [
        "  # Q1(b)plotting regression curve\n",
        "# plotting the actual points as scatter plot\n",
        "plt.scatter(dataset_testing1_arr[:,0], dataset_testing1_arr[:,1],marker = \"o\", s = 30)\n",
        "# plotting the regression line\n",
        "plt.scatter(dataset_testing1_arr[:,0], output_prediction_arr1)\n",
        "# putting labels\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y: actual output')\n",
        "# function to show plot\n",
        "plt.legend(['test_data','predicted_output'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgEP_i2lNQ7x"
      },
      "source": [
        "#output_prediction_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYBtuAihNQ7x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "778d9569-691e-4acd-d6bc-969bbd452837"
      },
      "source": [
        "#COmmenting the code as the runtime of this section is approx. 25 min, it is used for hyperparameter tuning\n",
        "#******Tuning Hidden layer and learning rate for Dataset2 ***********************#\n",
        "#plt.figure(figsize=(16, 32))\n",
        "#hidden_layer_sizes = [x for x in range(1,50)]\n",
        "#learning_rate = [(0.1*x) for x in range(1,10)]\n",
        "#best_result2 = []\n",
        "#min_loss2 = 10\n",
        "#for i, n_h in enumerate(hidden_layer_sizes):\n",
        "    #for j,lr in enumerate(learning_rate):\n",
        "        #parameters = nn_model(dataset_training2_arr[:,0], dataset_training2_arr[:,1], n_h, 100,lr) \n",
        "        #length = dataset_training2_arr.shape[0]\n",
        "        #output_prediction_arr = np.zeros(length)\n",
        "        #for i in range(length):\n",
        "            #output_prediction_arr[i] = predict(parameters,dataset_training2_arr[i,0])\n",
        "        #loss = mean_squared_error(output_prediction_arr,dataset_training2_arr[:,1])\n",
        "       # if(loss<min_loss2):\n",
        "          # min_loss2 = loss\n",
        "           #best_result2.clear()\n",
        "          # best_result2.append(\"Loss for {} hidden units {} learning rate: {} %\".format(n_h,lr,loss))\n",
        "       # print (\"Loss for {} hidden units {} learning rate: {} %\".format(n_h,lr,loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for 1 hidden units 0.1 learning rate: 0.10177648067413682 %\n",
            "Loss for 1 hidden units 0.2 learning rate: 0.11408144280250901 %\n",
            "Loss for 1 hidden units 0.30000000000000004 learning rate: 0.12376470907296219 %\n",
            "Loss for 1 hidden units 0.4 learning rate: 0.13314243810219964 %\n",
            "Loss for 1 hidden units 0.5 learning rate: 0.14694012790519537 %\n",
            "Loss for 1 hidden units 0.6000000000000001 learning rate: 0.1749776272172159 %\n",
            "Loss for 1 hidden units 0.7000000000000001 learning rate: 0.24178689540826065 %\n",
            "Loss for 1 hidden units 0.8 learning rate: 0.3411600549189607 %\n",
            "Loss for 1 hidden units 0.9 learning rate: 0.5104988116066785 %\n",
            "Loss for 2 hidden units 0.1 learning rate: 0.027905875023281495 %\n",
            "Loss for 2 hidden units 0.2 learning rate: 0.019602901375063552 %\n",
            "Loss for 2 hidden units 0.30000000000000004 learning rate: 0.01755291500102019 %\n",
            "Loss for 2 hidden units 0.4 learning rate: 0.01959630927966033 %\n",
            "Loss for 2 hidden units 0.5 learning rate: 0.02420354510564637 %\n",
            "Loss for 2 hidden units 0.6000000000000001 learning rate: 0.13884639792873132 %\n",
            "Loss for 2 hidden units 0.7000000000000001 learning rate: 0.17702297225694896 %\n",
            "Loss for 2 hidden units 0.8 learning rate: 0.23443569990876298 %\n",
            "Loss for 2 hidden units 0.9 learning rate: 1.4365412284095707 %\n",
            "Loss for 3 hidden units 0.1 learning rate: 0.03326882622013678 %\n",
            "Loss for 3 hidden units 0.2 learning rate: 0.02384453371517087 %\n",
            "Loss for 3 hidden units 0.30000000000000004 learning rate: 0.019368825222170018 %\n",
            "Loss for 3 hidden units 0.4 learning rate: 0.01752015512886133 %\n",
            "Loss for 3 hidden units 0.5 learning rate: 0.019150440097298153 %\n",
            "Loss for 3 hidden units 0.6000000000000001 learning rate: 0.024721651930468914 %\n",
            "Loss for 3 hidden units 0.7000000000000001 learning rate: 0.034293084926774235 %\n",
            "Loss for 3 hidden units 0.8 learning rate: 0.34107994678894193 %\n",
            "Loss for 3 hidden units 0.9 learning rate: 1.4365844259952971 %\n",
            "Loss for 4 hidden units 0.1 learning rate: 0.037752224068287814 %\n",
            "Loss for 4 hidden units 0.2 learning rate: 0.027141718772246966 %\n",
            "Loss for 4 hidden units 0.30000000000000004 learning rate: 0.0222739479047666 %\n",
            "Loss for 4 hidden units 0.4 learning rate: 0.019077695964172605 %\n",
            "Loss for 4 hidden units 0.5 learning rate: 0.017641238950230335 %\n",
            "Loss for 4 hidden units 0.6000000000000001 learning rate: 0.019839099026728233 %\n",
            "Loss for 4 hidden units 0.7000000000000001 learning rate: 0.027908017517331733 %\n",
            "Loss for 4 hidden units 0.8 learning rate: 0.34050819304237456 %\n",
            "Loss for 4 hidden units 0.9 learning rate: 1.4366120524222872 %\n",
            "Loss for 5 hidden units 0.1 learning rate: 0.03648061829251433 %\n",
            "Loss for 5 hidden units 0.2 learning rate: 0.026790910409022543 %\n",
            "Loss for 5 hidden units 0.30000000000000004 learning rate: 0.02245953973163448 %\n",
            "Loss for 5 hidden units 0.4 learning rate: 0.019871310007246568 %\n",
            "Loss for 5 hidden units 0.5 learning rate: 0.018285412110538506 %\n",
            "Loss for 5 hidden units 0.6000000000000001 learning rate: 0.018806245192580468 %\n",
            "Loss for 5 hidden units 0.7000000000000001 learning rate: 0.021483338400477125 %\n",
            "Loss for 5 hidden units 0.8 learning rate: 0.093457785295959 %\n",
            "Loss for 5 hidden units 0.9 learning rate: 1.4366299009563919 %\n",
            "Loss for 6 hidden units 0.1 learning rate: 0.03418128650146732 %\n",
            "Loss for 6 hidden units 0.2 learning rate: 0.025921146030354437 %\n",
            "Loss for 6 hidden units 0.30000000000000004 learning rate: 0.022788189350426407 %\n",
            "Loss for 6 hidden units 0.4 learning rate: 0.0208316163795854 %\n",
            "Loss for 6 hidden units 0.5 learning rate: 0.019254902005604816 %\n",
            "Loss for 6 hidden units 0.6000000000000001 learning rate: 0.018900895601674524 %\n",
            "Loss for 6 hidden units 0.7000000000000001 learning rate: 0.018083186874999015 %\n",
            "Loss for 6 hidden units 0.8 learning rate: 0.0335054491309854 %\n",
            "Loss for 6 hidden units 0.9 learning rate: 1.4365927927255289 %\n",
            "Loss for 7 hidden units 0.1 learning rate: 0.034659571017532094 %\n",
            "Loss for 7 hidden units 0.2 learning rate: 0.02682320503270043 %\n",
            "Loss for 7 hidden units 0.30000000000000004 learning rate: 0.024278725217806225 %\n",
            "Loss for 7 hidden units 0.4 learning rate: 0.022928571220204044 %\n",
            "Loss for 7 hidden units 0.5 learning rate: 0.02180275499796815 %\n",
            "Loss for 7 hidden units 0.6000000000000001 learning rate: 0.01991807323418358 %\n",
            "Loss for 7 hidden units 0.7000000000000001 learning rate: 0.020735545451928374 %\n",
            "Loss for 7 hidden units 0.8 learning rate: 0.020969374184504116 %\n",
            "Loss for 7 hidden units 0.9 learning rate: 0.13264757211417935 %\n",
            "Loss for 8 hidden units 0.1 learning rate: 0.044207304510282805 %\n",
            "Loss for 8 hidden units 0.2 learning rate: 0.0334875145530841 %\n",
            "Loss for 8 hidden units 0.30000000000000004 learning rate: 0.028809738620955185 %\n",
            "Loss for 8 hidden units 0.4 learning rate: 0.025893519993032056 %\n",
            "Loss for 8 hidden units 0.5 learning rate: 0.023916922176943665 %\n",
            "Loss for 8 hidden units 0.6000000000000001 learning rate: 0.02415885125008627 %\n",
            "Loss for 8 hidden units 0.7000000000000001 learning rate: 0.018319557884212113 %\n",
            "Loss for 8 hidden units 0.8 learning rate: 0.019750054775744458 %\n",
            "Loss for 8 hidden units 0.9 learning rate: 0.027785927936725612 %\n",
            "Loss for 9 hidden units 0.1 learning rate: 0.03213657763674174 %\n",
            "Loss for 9 hidden units 0.2 learning rate: 0.025374390316458363 %\n",
            "Loss for 9 hidden units 0.30000000000000004 learning rate: 0.023526705978356297 %\n",
            "Loss for 9 hidden units 0.4 learning rate: 0.023027933735181822 %\n",
            "Loss for 9 hidden units 0.5 learning rate: 0.022932411083267153 %\n",
            "Loss for 9 hidden units 0.6000000000000001 learning rate: 0.03618963941682238 %\n",
            "Loss for 9 hidden units 0.7000000000000001 learning rate: 0.026377853712503504 %\n",
            "Loss for 9 hidden units 0.8 learning rate: 0.019012278029447056 %\n",
            "Loss for 9 hidden units 0.9 learning rate: 0.026760405173501693 %\n",
            "Loss for 10 hidden units 0.1 learning rate: 0.038884341752282454 %\n",
            "Loss for 10 hidden units 0.2 learning rate: 0.03075230418081686 %\n",
            "Loss for 10 hidden units 0.30000000000000004 learning rate: 0.027834341051639372 %\n",
            "Loss for 10 hidden units 0.4 learning rate: 0.026093919208103965 %\n",
            "Loss for 10 hidden units 0.5 learning rate: 0.024954035676163815 %\n",
            "Loss for 10 hidden units 0.6000000000000001 learning rate: 0.029192463663978263 %\n",
            "Loss for 10 hidden units 0.7000000000000001 learning rate: 0.02514636563130962 %\n",
            "Loss for 10 hidden units 0.8 learning rate: 0.022893896575534985 %\n",
            "Loss for 10 hidden units 0.9 learning rate: 0.02526642620468699 %\n",
            "Loss for 11 hidden units 0.1 learning rate: 0.03357274502748948 %\n",
            "Loss for 11 hidden units 0.2 learning rate: 0.026489496708506626 %\n",
            "Loss for 11 hidden units 0.30000000000000004 learning rate: 0.02488279974459456 %\n",
            "Loss for 11 hidden units 0.4 learning rate: 0.02472927784359925 %\n",
            "Loss for 11 hidden units 0.5 learning rate: 0.02510758522156543 %\n",
            "Loss for 11 hidden units 0.6000000000000001 learning rate: 0.031043254871105083 %\n",
            "Loss for 11 hidden units 0.7000000000000001 learning rate: 0.02601945461020297 %\n",
            "Loss for 11 hidden units 0.8 learning rate: 0.025066854868923225 %\n",
            "Loss for 11 hidden units 0.9 learning rate: 0.0244311617845184 %\n",
            "Loss for 12 hidden units 0.1 learning rate: 0.041766764890782154 %\n",
            "Loss for 12 hidden units 0.2 learning rate: 0.033133332071070554 %\n",
            "Loss for 12 hidden units 0.30000000000000004 learning rate: 0.03009918007229973 %\n",
            "Loss for 12 hidden units 0.4 learning rate: 0.028529950849121233 %\n",
            "Loss for 12 hidden units 0.5 learning rate: 0.028298183912913125 %\n",
            "Loss for 12 hidden units 0.6000000000000001 learning rate: 0.03132501163673328 %\n",
            "Loss for 12 hidden units 0.7000000000000001 learning rate: 0.02999555563303825 %\n",
            "Loss for 12 hidden units 0.8 learning rate: 0.029014881525803133 %\n",
            "Loss for 12 hidden units 0.9 learning rate: 0.02744659685638684 %\n",
            "Loss for 13 hidden units 0.1 learning rate: 0.03322095032210771 %\n",
            "Loss for 13 hidden units 0.2 learning rate: 0.026471676625740265 %\n",
            "Loss for 13 hidden units 0.30000000000000004 learning rate: 0.025337270298126414 %\n",
            "Loss for 13 hidden units 0.4 learning rate: 0.025970964480743583 %\n",
            "Loss for 13 hidden units 0.5 learning rate: 0.027529200030253522 %\n",
            "Loss for 13 hidden units 0.6000000000000001 learning rate: 0.03530552130537219 %\n",
            "Loss for 13 hidden units 0.7000000000000001 learning rate: 0.030321375458287742 %\n",
            "Loss for 13 hidden units 0.8 learning rate: 0.03281929508382007 %\n",
            "Loss for 13 hidden units 0.9 learning rate: 0.02568407045910569 %\n",
            "Loss for 14 hidden units 0.1 learning rate: 0.03858783699525445 %\n",
            "Loss for 14 hidden units 0.2 learning rate: 0.030721019628889356 %\n",
            "Loss for 14 hidden units 0.30000000000000004 learning rate: 0.028725214518348096 %\n",
            "Loss for 14 hidden units 0.4 learning rate: 0.02846589931021002 %\n",
            "Loss for 14 hidden units 0.5 learning rate: 0.02961708396990276 %\n",
            "Loss for 14 hidden units 0.6000000000000001 learning rate: 0.0374306372599497 %\n",
            "Loss for 14 hidden units 0.7000000000000001 learning rate: 0.04441436435010054 %\n",
            "Loss for 14 hidden units 0.8 learning rate: 0.03582324343489208 %\n",
            "Loss for 14 hidden units 0.9 learning rate: 0.05834537142804622 %\n",
            "Loss for 15 hidden units 0.1 learning rate: 0.03405640663759915 %\n",
            "Loss for 15 hidden units 0.2 learning rate: 0.028011569126266185 %\n",
            "Loss for 15 hidden units 0.30000000000000004 learning rate: 0.027888151431466373 %\n",
            "Loss for 15 hidden units 0.4 learning rate: 0.02969574087584788 %\n",
            "Loss for 15 hidden units 0.5 learning rate: 0.032395891400124166 %\n",
            "Loss for 15 hidden units 0.6000000000000001 learning rate: 0.0365695165200138 %\n",
            "Loss for 15 hidden units 0.7000000000000001 learning rate: 0.030598720673030485 %\n",
            "Loss for 15 hidden units 0.8 learning rate: 0.038121297595795196 %\n",
            "Loss for 15 hidden units 0.9 learning rate: 0.02232029845361922 %\n",
            "Loss for 16 hidden units 0.1 learning rate: 0.03540657649205866 %\n",
            "Loss for 16 hidden units 0.2 learning rate: 0.028266373143308 %\n",
            "Loss for 16 hidden units 0.30000000000000004 learning rate: 0.027140590961402544 %\n",
            "Loss for 16 hidden units 0.4 learning rate: 0.02898270769818741 %\n",
            "Loss for 16 hidden units 0.5 learning rate: 0.03375962795564557 %\n",
            "Loss for 16 hidden units 0.6000000000000001 learning rate: 0.03463208190377929 %\n",
            "Loss for 16 hidden units 0.7000000000000001 learning rate: 0.027811268006168188 %\n",
            "Loss for 16 hidden units 0.8 learning rate: 0.037150190795380365 %\n",
            "Loss for 16 hidden units 0.9 learning rate: 0.25092580838073836 %\n",
            "Loss for 17 hidden units 0.1 learning rate: 0.030750556678446502 %\n",
            "Loss for 17 hidden units 0.2 learning rate: 0.025170541648839032 %\n",
            "Loss for 17 hidden units 0.30000000000000004 learning rate: 0.0253703620151257 %\n",
            "Loss for 17 hidden units 0.4 learning rate: 0.030296012978781935 %\n",
            "Loss for 17 hidden units 0.5 learning rate: 0.03819365041181569 %\n",
            "Loss for 17 hidden units 0.6000000000000001 learning rate: 0.0442077684362672 %\n",
            "Loss for 17 hidden units 0.7000000000000001 learning rate: 0.0348617154031966 %\n",
            "Loss for 17 hidden units 0.8 learning rate: 0.03251344616580027 %\n",
            "Loss for 17 hidden units 0.9 learning rate: 0.018785154105626423 %\n",
            "Loss for 18 hidden units 0.1 learning rate: 0.03068374593924304 %\n",
            "Loss for 18 hidden units 0.2 learning rate: 0.024354579982824396 %\n",
            "Loss for 18 hidden units 0.30000000000000004 learning rate: 0.024239436515833653 %\n",
            "Loss for 18 hidden units 0.4 learning rate: 0.02939692051181414 %\n",
            "Loss for 18 hidden units 0.5 learning rate: 0.03951825137255871 %\n",
            "Loss for 18 hidden units 0.6000000000000001 learning rate: 0.036459338123378204 %\n",
            "Loss for 18 hidden units 0.7000000000000001 learning rate: 0.04347425896425233 %\n",
            "Loss for 18 hidden units 0.8 learning rate: 0.021385622473520625 %\n",
            "Loss for 18 hidden units 0.9 learning rate: 0.024598487333449028 %\n",
            "Loss for 19 hidden units 0.1 learning rate: 0.031415039372265065 %\n",
            "Loss for 19 hidden units 0.2 learning rate: 0.024881190483086704 %\n",
            "Loss for 19 hidden units 0.30000000000000004 learning rate: 0.025412590774616106 %\n",
            "Loss for 19 hidden units 0.4 learning rate: 0.03274467416223279 %\n",
            "Loss for 19 hidden units 0.5 learning rate: 0.038746101687626336 %\n",
            "Loss for 19 hidden units 0.6000000000000001 learning rate: 0.022543175989555964 %\n",
            "Loss for 19 hidden units 0.7000000000000001 learning rate: 0.03666854912408456 %\n",
            "Loss for 19 hidden units 0.8 learning rate: 0.5016991719271552 %\n",
            "Loss for 19 hidden units 0.9 learning rate: 0.023160773515044617 %\n",
            "Loss for 20 hidden units 0.1 learning rate: 0.0413052461563219 %\n",
            "Loss for 20 hidden units 0.2 learning rate: 0.033355765154842204 %\n",
            "Loss for 20 hidden units 0.30000000000000004 learning rate: 0.031190099972751965 %\n",
            "Loss for 20 hidden units 0.4 learning rate: 0.03351280351208471 %\n",
            "Loss for 20 hidden units 0.5 learning rate: 0.03966480612214624 %\n",
            "Loss for 20 hidden units 0.6000000000000001 learning rate: 0.02497222304924469 %\n",
            "Loss for 20 hidden units 0.7000000000000001 learning rate: 0.03140569776942094 %\n",
            "Loss for 20 hidden units 0.8 learning rate: 0.49779278813803784 %\n",
            "Loss for 20 hidden units 0.9 learning rate: 0.020187836498988573 %\n",
            "Loss for 21 hidden units 0.1 learning rate: 0.030992628511921794 %\n",
            "Loss for 21 hidden units 0.2 learning rate: 0.024253059499781498 %\n",
            "Loss for 21 hidden units 0.30000000000000004 learning rate: 0.024218836680859765 %\n",
            "Loss for 21 hidden units 0.4 learning rate: 0.032088544366107655 %\n",
            "Loss for 21 hidden units 0.5 learning rate: 0.043681765246712224 %\n",
            "Loss for 21 hidden units 0.6000000000000001 learning rate: 0.04501571981504354 %\n",
            "Loss for 21 hidden units 0.7000000000000001 learning rate: 0.025305988797138572 %\n",
            "Loss for 21 hidden units 0.8 learning rate: 0.022282369053261943 %\n",
            "Loss for 21 hidden units 0.9 learning rate: 0.02173393877854989 %\n",
            "Loss for 22 hidden units 0.1 learning rate: 0.03655985206183406 %\n",
            "Loss for 22 hidden units 0.2 learning rate: 0.030611024901182126 %\n",
            "Loss for 22 hidden units 0.30000000000000004 learning rate: 0.030871241613083793 %\n",
            "Loss for 22 hidden units 0.4 learning rate: 0.03843852934061637 %\n",
            "Loss for 22 hidden units 0.5 learning rate: 0.0481148449617183 %\n",
            "Loss for 22 hidden units 0.6000000000000001 learning rate: 0.04782848157318465 %\n",
            "Loss for 22 hidden units 0.7000000000000001 learning rate: 0.029307105544491084 %\n",
            "Loss for 22 hidden units 0.8 learning rate: 0.04094586868796084 %\n",
            "Loss for 22 hidden units 0.9 learning rate: 0.019238701093080957 %\n",
            "Loss for 23 hidden units 0.1 learning rate: 0.03290968480593356 %\n",
            "Loss for 23 hidden units 0.2 learning rate: 0.026327737487727692 %\n",
            "Loss for 23 hidden units 0.30000000000000004 learning rate: 0.02756752616965049 %\n",
            "Loss for 23 hidden units 0.4 learning rate: 0.03584682744551728 %\n",
            "Loss for 23 hidden units 0.5 learning rate: 0.028470542925762406 %\n",
            "Loss for 23 hidden units 0.6000000000000001 learning rate: 0.04306053402495519 %\n",
            "Loss for 23 hidden units 0.7000000000000001 learning rate: 0.3913475855740339 %\n",
            "Loss for 23 hidden units 0.8 learning rate: 0.02613212565675604 %\n",
            "Loss for 23 hidden units 0.9 learning rate: 0.024434847533811015 %\n",
            "Loss for 24 hidden units 0.1 learning rate: 0.034254679008050196 %\n",
            "Loss for 24 hidden units 0.2 learning rate: 0.02730414974014675 %\n",
            "Loss for 24 hidden units 0.30000000000000004 learning rate: 0.02856326433955236 %\n",
            "Loss for 24 hidden units 0.4 learning rate: 0.03365732043607756 %\n",
            "Loss for 24 hidden units 0.5 learning rate: 0.023227532032509542 %\n",
            "Loss for 24 hidden units 0.6000000000000001 learning rate: 0.032016207171656264 %\n",
            "Loss for 24 hidden units 0.7000000000000001 learning rate: 0.02977027938813688 %\n",
            "Loss for 24 hidden units 0.8 learning rate: 0.019831693606131164 %\n",
            "Loss for 24 hidden units 0.9 learning rate: 0.024927407850886554 %\n",
            "Loss for 25 hidden units 0.1 learning rate: 0.03173946729541126 %\n",
            "Loss for 25 hidden units 0.2 learning rate: 0.025316261826348708 %\n",
            "Loss for 25 hidden units 0.30000000000000004 learning rate: 0.026058340480243063 %\n",
            "Loss for 25 hidden units 0.4 learning rate: 0.038295377729121415 %\n",
            "Loss for 25 hidden units 0.5 learning rate: 0.03365180933509223 %\n",
            "Loss for 25 hidden units 0.6000000000000001 learning rate: 0.024056142383658122 %\n",
            "Loss for 25 hidden units 0.7000000000000001 learning rate: 0.20899982293145544 %\n",
            "Loss for 25 hidden units 0.8 learning rate: 0.017812638369438243 %\n",
            "Loss for 25 hidden units 0.9 learning rate: 0.03641937951263155 %\n",
            "Loss for 26 hidden units 0.1 learning rate: 0.027933854609069785 %\n",
            "Loss for 26 hidden units 0.2 learning rate: 0.021452389157553087 %\n",
            "Loss for 26 hidden units 0.30000000000000004 learning rate: 0.02224499180945159 %\n",
            "Loss for 26 hidden units 0.4 learning rate: 0.031630859295319884 %\n",
            "Loss for 26 hidden units 0.5 learning rate: 0.05181278235528222 %\n",
            "Loss for 26 hidden units 0.6000000000000001 learning rate: 0.01761075395222504 %\n",
            "Loss for 26 hidden units 0.7000000000000001 learning rate: 1.2334607218999984 %\n",
            "Loss for 26 hidden units 0.8 learning rate: 0.01735167907887393 %\n",
            "Loss for 26 hidden units 0.9 learning rate: 0.04106631094410687 %\n",
            "Loss for 27 hidden units 0.1 learning rate: 0.02934683017208243 %\n",
            "Loss for 27 hidden units 0.2 learning rate: 0.023055370117744292 %\n",
            "Loss for 27 hidden units 0.30000000000000004 learning rate: 0.02870869943943092 %\n",
            "Loss for 27 hidden units 0.4 learning rate: 0.04636887526728207 %\n",
            "Loss for 27 hidden units 0.5 learning rate: 0.05850333310525622 %\n",
            "Loss for 27 hidden units 0.6000000000000001 learning rate: 0.04342306978376643 %\n",
            "Loss for 27 hidden units 0.7000000000000001 learning rate: 1.2341630379239767 %\n",
            "Loss for 27 hidden units 0.8 learning rate: 0.017430094630748072 %\n",
            "Loss for 27 hidden units 0.9 learning rate: 0.04594186339392757 %\n",
            "Loss for 28 hidden units 0.1 learning rate: 0.027537049937084224 %\n",
            "Loss for 28 hidden units 0.2 learning rate: 0.020992507483497302 %\n",
            "Loss for 28 hidden units 0.30000000000000004 learning rate: 0.022528200649974902 %\n",
            "Loss for 28 hidden units 0.4 learning rate: 0.056280205409433806 %\n",
            "Loss for 28 hidden units 0.5 learning rate: 0.053854185781627886 %\n",
            "Loss for 28 hidden units 0.6000000000000001 learning rate: 0.236950499143584 %\n",
            "Loss for 28 hidden units 0.7000000000000001 learning rate: 0.06787220542554505 %\n",
            "Loss for 28 hidden units 0.8 learning rate: 0.023222967480418102 %\n",
            "Loss for 28 hidden units 0.9 learning rate: 0.05865453042146094 %\n",
            "Loss for 29 hidden units 0.1 learning rate: 0.028409260073998233 %\n",
            "Loss for 29 hidden units 0.2 learning rate: 0.022473816637280233 %\n",
            "Loss for 29 hidden units 0.30000000000000004 learning rate: 0.02977239989485596 %\n",
            "Loss for 29 hidden units 0.4 learning rate: 0.051950500185649874 %\n",
            "Loss for 29 hidden units 0.5 learning rate: 0.051511686010367 %\n",
            "Loss for 29 hidden units 0.6000000000000001 learning rate: 0.23369798287292023 %\n",
            "Loss for 29 hidden units 0.7000000000000001 learning rate: 0.0237046108243993 %\n",
            "Loss for 29 hidden units 0.8 learning rate: 0.02871486631835236 %\n",
            "Loss for 29 hidden units 0.9 learning rate: 0.05260696046213215 %\n",
            "Loss for 30 hidden units 0.1 learning rate: 0.027162392487263286 %\n",
            "Loss for 30 hidden units 0.2 learning rate: 0.020644729226119252 %\n",
            "Loss for 30 hidden units 0.30000000000000004 learning rate: 0.02229244193023392 %\n",
            "Loss for 30 hidden units 0.4 learning rate: 0.02856536432339849 %\n",
            "Loss for 30 hidden units 0.5 learning rate: 0.029822844051387375 %\n",
            "Loss for 30 hidden units 0.6000000000000001 learning rate: 0.03766039142421075 %\n",
            "Loss for 30 hidden units 0.7000000000000001 learning rate: 0.02046985101479914 %\n",
            "Loss for 30 hidden units 0.8 learning rate: 0.037861420378592234 %\n",
            "Loss for 30 hidden units 0.9 learning rate: 0.043874539920170104 %\n",
            "Loss for 31 hidden units 0.1 learning rate: 0.02858734517379685 %\n",
            "Loss for 31 hidden units 0.2 learning rate: 0.02207137628013541 %\n",
            "Loss for 31 hidden units 0.30000000000000004 learning rate: 0.030083766741054074 %\n",
            "Loss for 31 hidden units 0.4 learning rate: 0.024016891717425572 %\n",
            "Loss for 31 hidden units 0.5 learning rate: 0.026189348362598463 %\n",
            "Loss for 31 hidden units 0.6000000000000001 learning rate: 1.1634987513243031 %\n",
            "Loss for 31 hidden units 0.7000000000000001 learning rate: 0.017949069442827325 %\n",
            "Loss for 31 hidden units 0.8 learning rate: 0.04881366553438501 %\n",
            "Loss for 31 hidden units 0.9 learning rate: 0.04036042100578308 %\n",
            "Loss for 32 hidden units 0.1 learning rate: 0.03207269793996083 %\n",
            "Loss for 32 hidden units 0.2 learning rate: 0.024985149803184666 %\n",
            "Loss for 32 hidden units 0.30000000000000004 learning rate: 0.04041660654769804 %\n",
            "Loss for 32 hidden units 0.4 learning rate: 0.022238970762284593 %\n",
            "Loss for 32 hidden units 0.5 learning rate: 0.02010763260320866 %\n",
            "Loss for 32 hidden units 0.6000000000000001 learning rate: 1.163790703726628 %\n",
            "Loss for 32 hidden units 0.7000000000000001 learning rate: 0.016828776762951785 %\n",
            "Loss for 32 hidden units 0.8 learning rate: 0.05751205651615686 %\n",
            "Loss for 32 hidden units 0.9 learning rate: 0.03515277585337451 %\n",
            "Loss for 33 hidden units 0.1 learning rate: 0.03696778096073994 %\n",
            "Loss for 33 hidden units 0.2 learning rate: 0.03217512167168966 %\n",
            "Loss for 33 hidden units 0.30000000000000004 learning rate: 0.03761629325106026 %\n",
            "Loss for 33 hidden units 0.4 learning rate: 0.02544234348018198 %\n",
            "Loss for 33 hidden units 0.5 learning rate: 0.016064252569915092 %\n",
            "Loss for 33 hidden units 0.6000000000000001 learning rate: 1.1638836712377094 %\n",
            "Loss for 33 hidden units 0.7000000000000001 learning rate: 0.01582702140122677 %\n",
            "Loss for 33 hidden units 0.8 learning rate: 0.06497943946137791 %\n",
            "Loss for 33 hidden units 0.9 learning rate: 0.02723533588460981 %\n",
            "Loss for 34 hidden units 0.1 learning rate: 0.032066357054107604 %\n",
            "Loss for 34 hidden units 0.2 learning rate: 0.023878612017620864 %\n",
            "Loss for 34 hidden units 0.30000000000000004 learning rate: 0.027900272773322403 %\n",
            "Loss for 34 hidden units 0.4 learning rate: 0.047755609660019016 %\n",
            "Loss for 34 hidden units 0.5 learning rate: 0.015616073633121995 %\n",
            "Loss for 34 hidden units 0.6000000000000001 learning rate: 1.1639647550049936 %\n",
            "Loss for 34 hidden units 0.7000000000000001 learning rate: 0.01583726829116733 %\n",
            "Loss for 34 hidden units 0.8 learning rate: 0.0622564851241246 %\n",
            "Loss for 34 hidden units 0.9 learning rate: 0.022809637163876496 %\n",
            "Loss for 35 hidden units 0.1 learning rate: 0.02957388439621207 %\n",
            "Loss for 35 hidden units 0.2 learning rate: 0.02249040947475153 %\n",
            "Loss for 35 hidden units 0.30000000000000004 learning rate: 0.03034095828655507 %\n",
            "Loss for 35 hidden units 0.4 learning rate: 0.06795731806912615 %\n",
            "Loss for 35 hidden units 0.5 learning rate: 0.13482423607223826 %\n",
            "Loss for 35 hidden units 0.6000000000000001 learning rate: 1.1639284853747585 %\n",
            "Loss for 35 hidden units 0.7000000000000001 learning rate: 0.01934929476385665 %\n",
            "Loss for 35 hidden units 0.8 learning rate: 0.06850105843448358 %\n",
            "Loss for 35 hidden units 0.9 learning rate: 0.029341371894268248 %\n",
            "Loss for 36 hidden units 0.1 learning rate: 0.0292755078085322 %\n",
            "Loss for 36 hidden units 0.2 learning rate: 0.023245691742481714 %\n",
            "Loss for 36 hidden units 0.30000000000000004 learning rate: 0.04773489049483098 %\n",
            "Loss for 36 hidden units 0.4 learning rate: 0.0725994457328103 %\n",
            "Loss for 36 hidden units 0.5 learning rate: 0.13355151088904935 %\n",
            "Loss for 36 hidden units 0.6000000000000001 learning rate: 1.1638920199231109 %\n",
            "Loss for 36 hidden units 0.7000000000000001 learning rate: 0.017817772207458903 %\n",
            "Loss for 36 hidden units 0.8 learning rate: 0.06762440981247864 %\n",
            "Loss for 36 hidden units 0.9 learning rate: 0.023552133021770054 %\n",
            "Loss for 37 hidden units 0.1 learning rate: 0.0292744106404448 %\n",
            "Loss for 37 hidden units 0.2 learning rate: 0.023593336765696672 %\n",
            "Loss for 37 hidden units 0.30000000000000004 learning rate: 0.036591005424349454 %\n",
            "Loss for 37 hidden units 0.4 learning rate: 0.0708395454009114 %\n",
            "Loss for 37 hidden units 0.5 learning rate: 0.13245898742946793 %\n",
            "Loss for 37 hidden units 0.6000000000000001 learning rate: 1.16379066617258 %\n",
            "Loss for 37 hidden units 0.7000000000000001 learning rate: 0.024242072699772153 %\n",
            "Loss for 37 hidden units 0.8 learning rate: 0.06578662455488585 %\n",
            "Loss for 37 hidden units 0.9 learning rate: 0.01921665829006485 %\n",
            "Loss for 38 hidden units 0.1 learning rate: 0.03007893835345366 %\n",
            "Loss for 38 hidden units 0.2 learning rate: 0.025008111320963342 %\n",
            "Loss for 38 hidden units 0.30000000000000004 learning rate: 0.03681349687597718 %\n",
            "Loss for 38 hidden units 0.4 learning rate: 0.0634080028128731 %\n",
            "Loss for 38 hidden units 0.5 learning rate: 0.027961728212837825 %\n",
            "Loss for 38 hidden units 0.6000000000000001 learning rate: 1.1634758773169898 %\n",
            "Loss for 38 hidden units 0.7000000000000001 learning rate: 0.04150739996340525 %\n",
            "Loss for 38 hidden units 0.8 learning rate: 0.04994315672209061 %\n",
            "Loss for 38 hidden units 0.9 learning rate: 0.25234175286825355 %\n",
            "Loss for 39 hidden units 0.1 learning rate: 0.029841618575826546 %\n",
            "Loss for 39 hidden units 0.2 learning rate: 0.025074553022134245 %\n",
            "Loss for 39 hidden units 0.30000000000000004 learning rate: 0.061580744843586485 %\n",
            "Loss for 39 hidden units 0.4 learning rate: 0.06608141761600707 %\n",
            "Loss for 39 hidden units 0.5 learning rate: 0.02977191363013808 %\n",
            "Loss for 39 hidden units 0.6000000000000001 learning rate: 1.1634211639467107 %\n",
            "Loss for 39 hidden units 0.7000000000000001 learning rate: 0.043375291097886313 %\n",
            "Loss for 39 hidden units 0.8 learning rate: 0.049439564835823194 %\n",
            "Loss for 39 hidden units 0.9 learning rate: 0.07004306778576412 %\n",
            "Loss for 40 hidden units 0.1 learning rate: 0.028064962964822502 %\n",
            "Loss for 40 hidden units 0.2 learning rate: 0.02249865548665636 %\n",
            "Loss for 40 hidden units 0.30000000000000004 learning rate: 0.06643423031699522 %\n",
            "Loss for 40 hidden units 0.4 learning rate: 0.044492145527509123 %\n",
            "Loss for 40 hidden units 0.5 learning rate: 0.02784195174755426 %\n",
            "Loss for 40 hidden units 0.6000000000000001 learning rate: 1.163267643432306 %\n",
            "Loss for 40 hidden units 0.7000000000000001 learning rate: 0.053908212200538624 %\n",
            "Loss for 40 hidden units 0.8 learning rate: 0.04299634851777085 %\n",
            "Loss for 40 hidden units 0.9 learning rate: 0.055536002042678376 %\n",
            "Loss for 41 hidden units 0.1 learning rate: 0.030834457974400254 %\n",
            "Loss for 41 hidden units 0.2 learning rate: 0.0309902645237595 %\n",
            "Loss for 41 hidden units 0.30000000000000004 learning rate: 0.07479078864332867 %\n",
            "Loss for 41 hidden units 0.4 learning rate: 0.04370317097485794 %\n",
            "Loss for 41 hidden units 0.5 learning rate: 1.1177085741628447 %\n",
            "Loss for 41 hidden units 0.6000000000000001 learning rate: 1.1626379335126442 %\n",
            "Loss for 41 hidden units 0.7000000000000001 learning rate: 0.06210772638845385 %\n",
            "Loss for 41 hidden units 0.8 learning rate: 0.03616003877013005 %\n",
            "Loss for 41 hidden units 0.9 learning rate: 1.4140325803977376 %\n",
            "Loss for 42 hidden units 0.1 learning rate: 0.028749673633632452 %\n",
            "Loss for 42 hidden units 0.2 learning rate: 0.022663558640355262 %\n",
            "Loss for 42 hidden units 0.30000000000000004 learning rate: 0.05805245986322395 %\n",
            "Loss for 42 hidden units 0.4 learning rate: 0.02055073686289543 %\n",
            "Loss for 42 hidden units 0.5 learning rate: 1.1178552129228334 %\n",
            "Loss for 42 hidden units 0.6000000000000001 learning rate: 0.03461502430591318 %\n",
            "Loss for 42 hidden units 0.7000000000000001 learning rate: 0.06959811556695249 %\n",
            "Loss for 42 hidden units 0.8 learning rate: 0.022612102884036853 %\n",
            "Loss for 42 hidden units 0.9 learning rate: 1.4361479906505332 %\n",
            "Loss for 43 hidden units 0.1 learning rate: 0.02903066849239988 %\n",
            "Loss for 43 hidden units 0.2 learning rate: 0.024917910291117455 %\n",
            "Loss for 43 hidden units 0.30000000000000004 learning rate: 0.035140219125067776 %\n",
            "Loss for 43 hidden units 0.4 learning rate: 0.021505349048517152 %\n",
            "Loss for 43 hidden units 0.5 learning rate: 1.1179072721911805 %\n",
            "Loss for 43 hidden units 0.6000000000000001 learning rate: 0.019269867181438763 %\n",
            "Loss for 43 hidden units 0.7000000000000001 learning rate: 0.07361238214031075 %\n",
            "Loss for 43 hidden units 0.8 learning rate: 0.021447829972429035 %\n",
            "Loss for 43 hidden units 0.9 learning rate: 1.4363966749526034 %\n",
            "Loss for 44 hidden units 0.1 learning rate: 0.027229021711276707 %\n",
            "Loss for 44 hidden units 0.2 learning rate: 0.02168847140907508 %\n",
            "Loss for 44 hidden units 0.30000000000000004 learning rate: 0.028230910048663613 %\n",
            "Loss for 44 hidden units 0.4 learning rate: 0.01724001097547608 %\n",
            "Loss for 44 hidden units 0.5 learning rate: 1.1179127441158263 %\n",
            "Loss for 44 hidden units 0.6000000000000001 learning rate: 0.016431723071272348 %\n",
            "Loss for 44 hidden units 0.7000000000000001 learning rate: 0.07910552781497965 %\n",
            "Loss for 44 hidden units 0.8 learning rate: 0.023459579517854042 %\n",
            "Loss for 44 hidden units 0.9 learning rate: 1.4364700330775058 %\n",
            "Loss for 45 hidden units 0.1 learning rate: 0.02982007722930236 %\n",
            "Loss for 45 hidden units 0.2 learning rate: 0.02589352957757082 %\n",
            "Loss for 45 hidden units 0.30000000000000004 learning rate: 0.023012519518536317 %\n",
            "Loss for 45 hidden units 0.4 learning rate: 0.017508602094585008 %\n",
            "Loss for 45 hidden units 0.5 learning rate: 1.117904194817837 %\n",
            "Loss for 45 hidden units 0.6000000000000001 learning rate: 0.01676464158912946 %\n",
            "Loss for 45 hidden units 0.7000000000000001 learning rate: 0.07855746287257925 %\n",
            "Loss for 45 hidden units 0.8 learning rate: 0.02870555713054342 %\n",
            "Loss for 45 hidden units 0.9 learning rate: 1.4364811663062362 %\n",
            "Loss for 46 hidden units 0.1 learning rate: 0.039626743706835506 %\n",
            "Loss for 46 hidden units 0.2 learning rate: 0.028073101824442982 %\n",
            "Loss for 46 hidden units 0.30000000000000004 learning rate: 0.02016103932607537 %\n",
            "Loss for 46 hidden units 0.4 learning rate: 0.01595985433232717 %\n",
            "Loss for 46 hidden units 0.5 learning rate: 1.1177715381110263 %\n",
            "Loss for 46 hidden units 0.6000000000000001 learning rate: 0.017363847706419473 %\n",
            "Loss for 46 hidden units 0.7000000000000001 learning rate: 0.07826459540343483 %\n",
            "Loss for 46 hidden units 0.8 learning rate: 0.02075006641181042 %\n",
            "Loss for 46 hidden units 0.9 learning rate: 1.4364898250180334 %\n",
            "Loss for 47 hidden units 0.1 learning rate: 0.027389833191924434 %\n",
            "Loss for 47 hidden units 0.2 learning rate: 0.022921472553004897 %\n",
            "Loss for 47 hidden units 0.30000000000000004 learning rate: 0.030194209941886707 %\n",
            "Loss for 47 hidden units 0.4 learning rate: 0.018528576936650446 %\n",
            "Loss for 47 hidden units 0.5 learning rate: 1.1175389239467388 %\n",
            "Loss for 47 hidden units 0.6000000000000001 learning rate: 0.01805879740611611 %\n",
            "Loss for 47 hidden units 0.7000000000000001 learning rate: 0.07292478405968764 %\n",
            "Loss for 47 hidden units 0.8 learning rate: 0.02836442741158357 %\n",
            "Loss for 47 hidden units 0.9 learning rate: 1.4364914412967116 %\n",
            "Loss for 48 hidden units 0.1 learning rate: 0.027615213065612522 %\n",
            "Loss for 48 hidden units 0.2 learning rate: 0.02728192946477577 %\n",
            "Loss for 48 hidden units 0.30000000000000004 learning rate: 0.035534624341632785 %\n",
            "Loss for 48 hidden units 0.4 learning rate: 0.0776296250154261 %\n",
            "Loss for 48 hidden units 0.5 learning rate: 1.11729984052656 %\n",
            "Loss for 48 hidden units 0.6000000000000001 learning rate: 0.02388477151794946 %\n",
            "Loss for 48 hidden units 0.7000000000000001 learning rate: 0.06882712862697937 %\n",
            "Loss for 48 hidden units 0.8 learning rate: 0.22271321715483888 %\n",
            "Loss for 48 hidden units 0.9 learning rate: 1.4364916911808234 %\n",
            "Loss for 49 hidden units 0.1 learning rate: 0.02829857717766109 %\n",
            "Loss for 49 hidden units 0.2 learning rate: 0.03603201609411466 %\n",
            "Loss for 49 hidden units 0.30000000000000004 learning rate: 0.07564207161021065 %\n",
            "Loss for 49 hidden units 0.4 learning rate: 0.42807471587496027 %\n",
            "Loss for 49 hidden units 0.5 learning rate: 1.1170171509160864 %\n",
            "Loss for 49 hidden units 0.6000000000000001 learning rate: 0.04889062170516637 %\n",
            "Loss for 49 hidden units 0.7000000000000001 learning rate: 0.05150572041423335 %\n",
            "Loss for 49 hidden units 0.8 learning rate: 1.3252322430751273 %\n",
            "Loss for 49 hidden units 0.9 learning rate: 1.436491796111337 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAUUKWgLc-WC",
        "outputId": "9a7adaf0-1ca4-489c-c9ca-12b04d7c7987"
      },
      "source": [
        "#best_result2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Loss for 34 hidden units 0.5 learning rate: 0.015616073633121995 %']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6ir7W_Hwlro"
      },
      "source": [
        "#From tuning of parameters got number of hidden layers as 6, learning rate as 0.2\n",
        "parameters2 = nn_model(dataset_training2_arr[:,0], dataset_training2_arr[:,1], 34, 100,0.5) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UB-sXRaeXP_h",
        "outputId": "332187f0-2ae9-4659-d46d-ccf09c6b6b08"
      },
      "source": [
        "#Q1(d)Training loss for Dataset2\n",
        "length = dataset_training2_arr.shape[0]\n",
        "output_prediction_train2 = np.zeros(length)\n",
        "for i in range(length):\n",
        "    output_prediction_train2[i] = predict(parameters2,dataset_training2_arr[i,0])\n",
        "mean_squared_error(dataset_training2_arr[:,1],output_prediction_train2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.015616073633121995"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04xMVOd7xIhP"
      },
      "source": [
        "length = dataset_testing2_arr.shape[0]\n",
        "output_prediction_arr2 = np.zeros(length)\n",
        "#plot_decision_boundary(lambda x: predict(parameters, x.T), X, Y) \n",
        "for i in range(length):\n",
        "    output_prediction_arr2[i] = predict(parameters2,dataset_testing2_arr[i,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaScd-Il3JOv",
        "outputId": "d459f33e-1b73-4372-9a2d-7c6b9f29a07f"
      },
      "source": [
        "#Q1(d) Test loss for dataset2\n",
        "mean_squared_error(dataset_testing2_arr[:,1],output_prediction_arr2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0007775946848879148"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1-gJZsKNQ7x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "288127af-0064-49db-9a6d-39302a67fed9"
      },
      "source": [
        "  #Q1(C)plotting regression curve\n",
        "# plotting the actual points as scatter plot\n",
        "plt.scatter(dataset_testing2_arr[:,0], dataset_testing2_arr[:,1],marker = \"o\", s = 30)\n",
        "# plotting the regression line\n",
        "plt.scatter(dataset_testing2_arr[:,0], output_prediction_arr2)\n",
        "# putting labels\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y: actual output')\n",
        "plt.legend(['test_data','predicted_output'])\n",
        "# function to show plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}